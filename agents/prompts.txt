



def _llm_dataset_selection(self, search_results: List[Dict], state: AgentState) -> Dict:
        """LLM selection with direct actual table name handling"""
        
        user_question = state.get('current_question', state.get('original_question', ''))

        selection_prompt = f"""
        You are a decisive dataset router. Follow this decision process strictly:

        USER QUESTION: "{user_question}"

        AVAILABLE DATASETS:
        {json.dumps(search_results, indent=2)}

        DECISION PROCESS:
        1. **Keyword-Based Primary Routing**
        - If question contains "claim", "claims", "claim revenue", "claim data" → STRONGLY favor claim_transaction table
        - If question contains "budget", "forecast", "actuals vs forecast", "planning" → STRONGLY favor actuals_vs_forecast table
        - If question contains "ledger" → favor actuals_vs_forecast table
        - IMPORTANT: "Claim revenue" means revenue FROM individual claim transactions, not ledger summaries

        2. **Match Attributes and Metrics**
        - Check if the dataset contains the attributes and metrics mentioned or implied in the user question
        - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue')
        - Consider synonyms and related terms (e.g., 'scripts' relates to prescription volume)

        3. **Check Time Granularity**
        - Ensure the dataset supports the required time grain (e.g., monthly, daily)
        - claim_transaction supports daily granularity via submit_date
        - actuals_vs_forecast supports monthly/quarterly/yearly via transaction_date

        4. **Evaluate Purpose and Suitability**
        - Match the question's analytical purpose with dataset purpose
        - If dataset is marked as 'not_suitable_for' the type of analysis requested, exclude it ONLY if no keyword match from step 1
        - If dataset is marked in 'query_patterns' or 'core_capabilities' for the analysis type, increase relevance

        5. **Multi-Table Analysis Detection**
        - Detect if query requires joining data across tables (e.g., claim amounts from different tables)
        - Identify queries that benefit from complementary data perspectives (volumes + financials from different sources)
        - Recognize queries needing separate analysis on related datasets (demographics + transactions)

        6. **Dataset Selection Strategy**
        - Choose the single best dataset that satisfies the above criteria
        - Select multiple datasets only when analysis inherently requires multiple tables
        - When in doubt between tables and no clear keyword match, prefer the table with better attribute coverage

        WHEN TO ASK FOLLOW-UP:

        **Scenario 1: Keyword Ambiguity**
        - When both tables have the requested metrics AND user didn't specify distinguishing keywords
        - Examples: "revenue trends", "pharmacy performance" without claim/forecast context
        - Ask: "Do you need claim-level transaction data or ledger-level financial summaries?"

        **Scenario 2: Multi-Table Analysis Confirmation**
        - When query explicitly requires data from different table types
        - Example: "Compare individual claim patterns with overall budget performance"

        DO NOT ASK FOLLOW-UP FOR THESE (BE DECISIVE):
        - Time period vagueness with clear keywords (e.g., "claim trends" without LOB) → Use appropriate table based on keywords
        - Metric questions with dataset indicators (e.g., "GDR analysis", "therapy class performance") → Route directly

        KEY EXAMPLES:
        CLARIFICATION NEEDED: "revenue trends", "pharmacy performance data"
        NO CLARIFICATION: "claim revenue July 2025" → claims, "budget vs actuals" → forecast, "GDR trends" → claims
        
        RESPONSE FORMAT :
        The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```
        {{
            "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
            "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
            "requires_clarification": false,
            "clarification_question": null,
            "candidate_actual_tables": [],
            "selection_reasoning": "Brief explanation of selection based on attribute/metric match"
        }}
        
        CRITICAL RULES:
        - When LLM decides on right dataset(s), ALWAYS set requires_clarification: false and clarification_question: null
        - Only set requires_clarification: true for the 2 specific scenarios mentioned above
        - Keep clarification_question short and direct when needed (max 20 words)
        - candidate_actual_tables should be populated only when requires_clarification: true
        - NEVER ask for clarification on time periods, aggregation levels, or general scope - make reasonable assumptions
        - Trust keyword analysis over complex reasoning about aggregation levels
        """
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                llm_response = self.db_client.call_claude_api_endpoint([
                    {"role": "user", "content": selection_prompt}
                ])
                selection_result = json.loads(llm_response)
                
                print(f"✅ Dataset selection complete: {selection_result.get('functional_names')}")
                return selection_result
                    
            except Exception as e:
                retry_count += 1
                print(f"❌ Dataset selection attempt {retry_count} failed: {str(e)}")
                
                if retry_count < max_retries:
                    print(f"🔄 Retrying... ({retry_count}/{max_retries})")
                    import time
                    time.sleep(2 ** retry_count)
                    continue
                else:
                    return {
                        'final_actual_tables': [],
                        'functional_names': [],
                        'requires_clarification': False,
                        'selection_reasoning': 'Dataset selection failed',
                        'error': True,
                        'error_message': f"Model serving endpoint failed after {max_retries} attempts: {str(e)}"
                    }

    def _fix_router_llm_call(self, state: AgentState) -> Dict:


selection_prompt = f"""
You are a decisive dataset router. Follow this decision process strictly:

USER QUESTION: "{user_question}"

AVAILABLE DATASETS:
{json.dumps(search_results[:5], indent=2)}

DECISION PROCESS:
1. **Keyword-Based Primary Routing**
   - If question contains "claim", "claims", "claim revenue", "claim data" → STRONGLY favor claim_transaction table
   - If question contains "budget", "forecast", "actuals vs forecast", "planning" → STRONGLY favor actuals_vs_forecast table
   - If question contains "ledger" → favor actuals_vs_forecast table
   - IMPORTANT: "Claim revenue" means revenue FROM individual claim transactions, not ledger summaries

2. **Match Attributes and Metrics**
   - Check if the dataset contains the attributes and metrics mentioned or implied in the user question
   - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue')
   - Consider synonyms and related terms (e.g., 'scripts' relates to prescription volume)

3. **Check Time Granularity**
   - Ensure the dataset supports the required time grain (e.g., monthly, daily)
   - claim_transaction supports daily granularity via submit_date
   - actuals_vs_forecast supports monthly/quarterly/yearly via transaction_date

4. **Evaluate Purpose and Suitability**
   - Match the question's analytical purpose with dataset purpose
   - If dataset is marked as 'not_suitable_for' the type of analysis requested, exclude it ONLY if no keyword match from step 1
   - If dataset is marked in 'query_patterns' or 'core_capabilities' for the analysis type, increase relevance

5. **Multi-Table Analysis Detection**
   - Detect if query requires joining data across tables (e.g., claim amounts from different tables)
   - Identify queries that benefit from complementary data perspectives (volumes + financials from different sources)
   - Recognize queries needing separate analysis on related datasets (demographics + transactions)

6. **Dataset Selection Strategy**
   - Choose the single best dataset that satisfies the above criteria
   - Select multiple datasets only when analysis inherently requires multiple tables
   - When in doubt between tables and no clear keyword match, prefer the table with better attribute coverage

WHEN TO ASK FOLLOW-UP:

**Scenario 1: Keyword Ambiguity**
- When both tables have the requested metrics AND user didn't specify distinguishing keywords
- When the question could legitimately use either table based on available attributes
- Examples: "revenue trends", "revenue analysis", "show revenue data", "pharmacy performance" without claim/forecast context
- Ask: "Do you need claim-level transaction data or ledger-level financial summaries?"

**Scenario 2: True Data Type Ambiguity** 
- When question contains general business terms that both tables can satisfy
- When no clear analytical context points to one table over another
- Example: "revenue by product category" (both tables have revenue and product category)
- Ask: "Which dataset: detailed claim transactions or aggregated financial ledger data?"

**Scenario 3: Multi-Table Analysis Confirmation**
- When query explicitly requires data from different table types (e.g., "claim details with billing reconciliation")
- When query needs to join claim-level data with ledger-level data for comprehensive analysis
- When query benefits from combining transactional data with financial planning data
- Example: "Compare individual claim patterns with overall budget performance" → Claims + Ledger analysis

DO NOT ASK FOLLOW-UP FOR THESE AMBIGUITIES (BE DECISIVE):
- Time period vagueness (e.g., "show pharmacy sales July 2024" without claim/forecast keywords) → If no keywords, ask for clarification between claim vs ledger
- Aggregation level uncertainty (e.g., "revenue data monthly" without context) → If no distinguishing keywords, ask for clarification  
- Scope ambiguity with clear keywords (e.g., "claim trends" without LOB specified) → Use claims table, don't ask about table choice
- Metric questions with clear dataset indicators (e.g., "GDR analysis", "therapy class performance") → Route to claims table directly

EXAMPLES REQUIRING CLARIFICATION:
- "What are the revenue trends?" → Both tables have revenue, no distinguishing keywords
- "Show me pharmacy performance data" → Could be claim-level or ledger-level analysis
- "Revenue analysis by product category" → Both tables support this, need clarification

EXAMPLES NOT REQUIRING CLARIFICATION:
- "What is the claim revenue for July 2025?" → claim_transaction (keyword: "claim")
- "Show me budget vs actuals" → actuals_vs_forecast (keywords: "budget", "actuals") 
- "What is the variance between actual costs and forecasted costs?" → actuals_vs_forecast (actuals vs forecast analysis)
- "Generic dispensing ratio trends" → claim_transaction (GDR in core_capabilities)
- "Revenue per script analysis" → claim_transaction (explicitly in core_capabilities)
- "Forecast analysis for Q3" → actuals_vs_forecast (keyword: "forecast")
- "Therapy class performance last month" → claim_transaction (therapy class only in claims)
- "Client-level claim analysis" → claim_transaction (client analysis in query_patterns)

RESPONSE FORMAT (valid JSON only, no markdown):
{{
    "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
    "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
    "requires_clarification": false,
    "clarification_question": null,
    "candidate_actual_tables": [],
    "selection_reasoning": "Brief explanation referencing keyword match, attribute coverage, and why this dataset best serves the user's question"
}}

CRITICAL RULES:
- When LLM decides on right dataset(s), ALWAYS set requires_clarification: false and clarification_question: null
- Only set requires_clarification: true for the 2 specific scenarios mentioned above
- Keep clarification_question short and direct when needed (max 15 words)
- candidate_actual_tables should be populated only when requires_clarification: true
- NEVER ask for clarification on time periods, aggregation levels, or general scope - make reasonable assumptions
- Trust keyword analysis over complex reasoning about aggregation levels
"""




selection_prompt = f"""
                    You are a meticulous dataset router. Choose EXACTLY ONE dataset.

                    USER QUESTION: "{user_question}"

                    DATASETS (JSON array). Each dataset has:
                    - name,description,metrics,attributes,columns,hints,time_grains

                    DATA:
                    {json.dumps(dataset_options, indent=2)}

                    GOAL
                    Map the user question to required columns using ONLY the dataset metadata and order of meta data is random. Evaluate BOTH datasets. Prefer a table that can satisfy ALL required columns and the requested time grain. If no table can fully satisfy, return the closest table by coverage.

                    Follow this decision process strictly:

                    1. **Match Attributes and Metrics First**
                    - Check if the dataset contains the attributes and metrics mentioned or implied in the user question.
                    - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue').

                    2. **Check Time Granularity**
                    - Ensure the dataset supports the required time grain (e.g., monthly, daily).

                    3. **Evaluate Usefulness Tags**
                    - If the dataset is marked as 'useful_for' the type of analysis requested, that increases its relevance.
                    - If the dataset is marked as 'not_useful_for' the type of analysis requested, it should be excluded.

                    4. **Select Only One Dataset**
                    - Choose the single best dataset that satisfies the above criteria.

                    RESPONSE FORMAT:
                    The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```.

                    {{ "clear_selection": true, "selected_dataset": "<one of the dataset 'table_name' values>", "selection_reasoning": "One concise sentence referencing why the dataset is best match (e.g., therapy_class_name + month required; only claims has therapy_class_name and supports month/day)." }}

                    """


selection_prompt = f"""
        You are a decisive dataset router. Follow this decision process strictly:

        USER QUESTION: "{user_question}"

        AVAILABLE DATASETS:
        {json.dumps(search_results[:5], indent=2)}

        DECISION PROCESS:
        1. **Match Attributes and Metrics First**
        - Check if the dataset contains the attributes and metrics mentioned or implied in the user question
        - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue')
        
        2. **Check Time Granularity**
        - Ensure the dataset supports the required time grain (e.g., monthly, daily)
        
        3. **Evaluate Usefulness Tags**
        - If dataset is marked as 'useful_for' the type of analysis requested, increase relevance
        - If dataset is marked as 'not_useful_for' the type of analysis requested, exclude it
        
        4. **Multi-Table Analysis Detection**
        - Detect if query requires joining data across tables (e.g., claim amounts from different tables)
        - Identify queries that benefit from complementary data perspectives (volumes + financials)
        - Recognize queries needing separate analysis on related datasets (demographics + transactions)
        
        5. **Dataset Selection Strategy**
        - Choose the single best dataset that satisfies the above criteria
        - Select multiple datasets only when analysis inherently requires multiple tables
        
        WHEN TO ASK FOLLOW-UP (RARE CASES ONLY):
        
        **Scenario 1: Data Type Ambiguity**
        - ONLY when both tables have same LOB and user didn't specify "ledger" vs "claims" keywords
        - Example: "Which dataset: claims transactions or financial ledger data?"
        
        **Scenario 2: Multi-Table Analysis Confirmation**
        - When query requires joining data across tables (e.g., billed amount from Table A + paid amount from Table B)
        - When query benefits from complementary perspectives (transaction volumes + financial metrics)
        - When query needs separate analysis on related datasets then combining insights
        - Example: "This analysis requires both Claims Details and Payment Records tables. Proceed with both?"
        
        DO NOT ASK FOLLOW-UP FOR GENERAL AMBIGUITIES:
        - Time period vagueness (e.g., "show pharmacy sales" without specifying when) → Pick most recent complete period
        - Aggregation level uncertainty (e.g., "revenue data" without daily/monthly) → Use most appropriate grain available
        - Scope ambiguity (e.g., "claim trends" without LOB specified) → Use broadest/most complete dataset
        - Metric preference vagueness (e.g., "pharmacy performance" unclear on volume vs financial) → Pick best match based on context
        - BE DECISIVE: Make reasonable choices for these ambiguities rather than asking clarification
        
        MULTI-TABLE EXAMPLES:
        - "What is the claim paid and billed amount?" → Need claims table + payments table (JOIN required)
        - "Show pharmacy performance trends" → Transaction data + Financial metrics (Complementary analysis)
        - "Compare member demographics with claim patterns" → Demographics table + Claims table (Separate analysis)
        
        RESPONSE FORMAT (valid JSON only, no markdown):
        {{
            "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
            "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
            "requires_clarification": false,
            "clarification_question": null,
            "candidate_actual_tables": [],
            "selection_reasoning": "Brief explanation of selection based on attribute/metric match"
        }}
        
        IMPORTANT: 
        - When LLM decides on right dataset(s), ALWAYS set requires_clarification: false and clarification_question: null
        - Only set requires_clarification: true and populate clarification_question for the 2 scenarios mentioned above
        - Keep clarification_question short and direct when needed
        - candidate_actual_tables should be populated only when requires_clarification: true
        """

llm response router {
    "final_actual_tables": ["prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis"],
    "functional_names": ["Actuals vs Forecast Analysis"],
    "requires_clarification": false,
    "clarification_question": null,
    "candidate_actual_tables": [],
    "selection_reasoning": "Query asks for claim revenue by month and product category PBM. The actuals_vs_forecast_analysis table has exact matches for 'revenue', 'month', and 'product category' dimensions with monthly temporal granularity. The claim_transaction table, while having revenue data, is designed for claim-level analysis and marked as 'not suitable for ledger-level summaries', whereas this query appears to need aggregated revenue metrics by time period and product category."
}

      [
  {
    "llm_context": "{\"table_name\":\"prd_optumrx_orxfdmprdsa.rag.claim_transaction_for_pharmacy_pbm\",\"purpose\":\"Claim-level pharmacy transactions with detailed drug, client, and pharmacy attributes. Individual claim records with payment status for utilization and financial analysis.\",\"core_capabilities\":\"revenue per script analysis, drug utilization trending, therapy class performance (GLP-1, SGLT-2, Oncology), generic dispense rate (GDR), pharmacy network analysis, client-level metrics, brand vs generic mix, claim status tracking\",\"key_measures\":[\"revenue\",\"expense\",\"WAC\",\"AWP\",\"unadjusted scripts\",\"adjusted scripts\",\"30-day scripts\",\"90-day scripts\",\"revenue per script\",\"volume\",\"Generic dispensing ratio/GDR\"],\"key_dimensions\":[\"claim identifiers\",\"claim status\",\"client id/Client name/Client type\",\"carrier/account/group/CAG\",\"pharmacy name/NPI/Pharmacy type\",\"drug name/ NDC Code\",\"therapy class\",\"GPI\",\"line of business\",\"brand vs generic\",\"product category\",\"state code\",\"member date of birth\",\"member sex\",\"submit date\",\"year\",\"month\",\"quarter\"],\"query_patterns\":[\"claim-level financial analysis\",\"client-level analysis\",\"drug and therapy class performance\",\"manufacturer-level insights\",\"revenue per script and GDR metrics\",\"line-of-business tracking\",\"daily and monthly trend analysis\",\"rate analysis\",\"pharmacy performance\",\"member usage analysis\"],\"not_suitable_for\":[\"budget planning\",\"forecast generation\",\"ledger-level summaries\"],\"grain\":\"claim_transaction\",\"temporal\":\"daily via submit_date\"}"
  },
  {
    "llm_context": "{\"table_name\":\"prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis\",\"purpose\":\"Ledger-level financial data for actuals, forecast, and budget analysis. Aggregated financial metrics for forecast analysis and planning at LOB level.\",\"key_measures\":[\"revenue\",\"IOI\",\"total membership\",\"unadjusted scripts\",\"adjusted scripts\",\"30-day scripts\",\"90-day scripts\",\"amount or count\",\"expense\",\"volume\"],\"key_dimensions\":[\"ledger type\",\"line of business\",\"product category\",\"product subcategory level 1\",\"product subcategory level 2\",\"transaction date\",\"year\",\"month\",\"quarter\"],\"query_patterns\":[\"actuals vs forecast\",\"budget comparison\"],\"not_suitable_for\":[\"claim-level analysis\",\"daily granularity\",\"client-specific analysis\"],\"grain\":\"aggregated_metrics\",\"temporal\":\"monthly/quarterly/yearly via transaction_date\"}"
  }
]
