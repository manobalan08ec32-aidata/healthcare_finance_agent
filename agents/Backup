async def _generate_sql_with_followup_async(self, context: Dict, sql_followup_question: str, sql_followup_answer: str, state: Dict) -> Dict[str, Any]:
        """Generate SQL using original question + follow-up Q&A with relevance validation in single call"""
        
        current_question = context.get('current_question', '')
        dataset_metadata = context.get('dataset_metadata', '')
        join_clause = state.get('join_clause', '')
        selected_filter_context = context.get('selected_filter_context')
        if state.get('requires_dataset_clarification', False):
            followup_reasoning = state.get('followup_reasoning', '')
        else:
            followup_reasoning = state.get('selection_reasoning','')
        
        # üÜï RETRIEVE history_section from state
        history_section = state.get('sql_history_section', '')
        if history_section:
            print(f"üìñ Retrieved sql_history_section from state")
        else:
            print(f"‚ö†Ô∏è No sql_history_section found in state - proceeding without history context")
            history_section = """
=== HISTORICAL SQL ===
Not available

"""
        
        # Check if we have multiple tables
        selected_datasets = state.get('selected_dataset', [])
        
        # Define mandatory column mapping
        mandatory_column_mapping = {
            "prd_optumrx_orxfdmprdsa.rag.ledger_actual_vs_forecast": [
                "Ledger"
            ]
        }
        
        # Extract mandatory columns based on selected datasets
        mandatory_columns_info = []
        if isinstance(selected_datasets, list):
            for dataset in selected_datasets:
                if dataset in mandatory_column_mapping:
                    mandatory_columns = mandatory_column_mapping[dataset]
                    for col in mandatory_columns:
                        mandatory_columns_info.append(f"Table {dataset}: {col} (MANDATORY)")
                else:
                    mandatory_columns_info.append(f"Table {dataset}: Not Applicable")
        
        # Format mandatory columns for prompt
        mandatory_columns_text = "\n".join(mandatory_columns_info) if mandatory_columns_info else "Not Applicable"
        
        # Format selected filter context for prompt
        filter_context_text = ""
        if selected_filter_context:
            filter_context_text = f"""
    SELECTED FILTER CONTEXT Available for SQL generation based on user follow up answer:
        final selection : {selected_filter_context}
    """
        
        has_multiple_tables = len(selected_datasets) > 1 if isinstance(selected_datasets, list) else False

        followup_sql_prompt = f"""
‚ö†Ô∏è IMPORTANT CONTEXT - READ THIS FIRST ‚ö†Ô∏è

You are a Databricks SQL code generator processing follow-up clarifications. Your task is to generate SQL queries that incorporate both the original question and the user's clarification.

When users request calculations like "revenue per script" or "cost breakdown" - they are asking you to generate SQL code that performs these calculations. You generate the SQL that will be executed by the database.

You are a Healthcare Finance SQL specialist working on PHASE 2 of a two-phase process.

ORIGINAL USER QUESTION: {current_question}
**AVAILABLE METADATA**: {dataset_metadata}
MULTIPLE TABLES AVAILABLE: {has_multiple_tables}
JOIN INFORMATION: {join_clause if join_clause else "No join clause provided"}
MANDATORY FILTER COLUMNS: {mandatory_columns_text}

{history_section}

FILTER VALUES EXTRACTED:
{filter_context_text}

====================================
STEP 1: VALIDATE FOLLOW-UP RESPONSE
====================================

YOUR PREVIOUS QUESTION: {sql_followup_question}
USER'S RESPONSE: {sql_followup_answer}

**FIRST, analyze if the user's response is relevant:**

1. **RELEVANT**: User directly answered or provided clarification ‚Üí PROCEED to SQL generation
2. **NEW_QUESTION**: User asked a completely new question instead of answering ‚Üí STOP, return new_question flag
3. **TOPIC_DRIFT**: User's response is completely unrelated/off-topic ‚Üí STOP, return topic_drift flag

**If NOT RELEVANT (categories 2 or 3), immediately return the appropriate XML response below and STOP.**
**If RELEVANT (category 1), proceed to STEP 2 for SQL generation.**

=========================================
STEP 2: SQL GENERATION (Only if RELEVANT)
=========================================

Generate a high-quality Databricks SQL query using:
1. The ORIGINAL user question as the primary requirement
2. The USER'S CLARIFICATION to resolve any ambiguities
3. Available metadata for column mapping
4. Multi-table strategy assessment (single vs multiple queries)
5. Historical SQL Patterns(if available)-Follow structured approach from history_section - inherit if aligned, learn patterns if not.
6. All SQL generation best practices

**MULTI-QUERY DECISION LOGIC**:
- **SINGLE QUERY WITH JOIN**: Simple analysis requiring related data from multiple tables
- **MULTIPLE QUERIES - MULTI-TABLE**: Complementary analysis from different tables OR no join exists
- **MULTIPLE QUERIES - COMPLEX SINGLE-TABLE**: Multiple analytical dimensions (trends + rankings)
- **SINGLE QUERY**: Simple, focused questions with one analytical dimension

========================================
CRITICAL DATABRICKS SQL GENERATION RULES
=========================================


**PRIORITY 0: MANDATORY REQUIREMENTS** (Violation = Query Failure)

M1. **Mandatory Filters** ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è CRITICAL
MUST include EVERY mandatory filter in WHERE clause:
```sql
-- Example: If ledger is MANDATORY:
WHERE ledger = 'GAAP'
  AND [other conditions]
```

M2. **Validated Filter Values**
Use ONLY filters marked ‚úìValid in CHECK 3:
```sql
WHERE UPPER(carrier_id) = UPPER('MPDOVA')  -- Only if validated
```

M3. **CALCULATED FORMULAS HANDLING (CRITICAL)-Metric Type Grouping Rule for Calculations**
When calculating derived metrics (Gross Margin, Cost %, Margin %), DO NOT group by metric_type:
```sql
-- ‚úì CORRECT (for calculations):
SELECT 
    ledger, year, month,  -- Business dimensions only
    SUM(CASE WHEN UPPER(metric_type) = UPPER('Revenues') THEN amount ELSE 0 END) AS revenues,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('COGS') THEN amount ELSE 0 END) AS cogs,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('Revenues') THEN amount ELSE 0 END) - 
    SUM(CASE WHEN UPPER(metric_type) = UPPER('COGS') THEN amount ELSE 0 END) AS gross_margin
FROM table
WHERE UPPER(metric_type) IN (UPPER('Revenues'), UPPER('COGS'))
GROUP BY ledger, year, month  -- NOT metric_type

-- ‚úó WRONG (breaks calculations):
GROUP BY ledger, metric_type  -- Creates separate rows per metric_type
```
**Only group by metric_type when user explicitly asks to see individual metric types as separate rows.**

**PRIORITY 1: STRUCTURAL PATTERNS**

S1. **Historical SQL Patterns** (if available)
Follow structured approach from history_section - inherit if aligned, learn patterns if not.

S2. **Aggregation Requirements**
Always aggregate metrics unless "line items" explicitly requested.

S3. **Component Display Rule**
ALWAYS show source components for ANY calculation:
```sql
-- For "cost per member by state":
SELECT 
  state_name,
  SUM(total_cost) as total_cost,      -- Component 1
  COUNT(member_id) as member_count,   -- Component 2  
  ROUND(SUM(total_cost) / NULLIF(COUNT(member_id), 0), 2) as cost_per_member  -- Result
FROM table
GROUP BY state_name
```

**PRIORITY 2: QUERY PATTERNS**

P1. **Top N Pattern**
```sql
-- "Top 5 carriers"
SELECT carrier_id, 
       SUM(amount) as amount,
       (SELECT SUM(amount) FROM table) as total,
       ROUND(SUM(amount)/(SELECT SUM(amount) FROM table)*100, 3) as pct
FROM table
WHERE [mandatory filters]
GROUP BY carrier_id
ORDER BY amount DESC LIMIT 5
```

P2. **Time Comparison Pattern**
```sql
-- "Compare Q3 months"
SELECT product,
       SUM(CASE WHEN month = 7 THEN revenue END) as jul_revenue,
       SUM(CASE WHEN month = 8 THEN revenue END) as aug_revenue,
       SUM(CASE WHEN month = 9 THEN revenue END) as sep_revenue
FROM table
WHERE quarter = 3 AND [mandatory filters]
GROUP BY product
```

P3. **Multi-Table Pattern**
```sql
-- When JOIN needed
SELECT t1.dim, SUM(t1.metric) as m1, SUM(t2.metric) as m2
FROM table1 t1
{join_clause}  -- Use provided join
WHERE t1.mandatory_col = value
GROUP BY t1.dim
```

**PRIORITY 3: FORMATTING STANDARDS**

F1. **String Comparison** - Always case-insensitive:
```sql
WHERE UPPER(column) = UPPER('value')
```

F2. **Numeric Formatting**:
- Amounts: ROUND(x, 0) AS name_amount
- Percentages: ROUND(x, 3) AS name_percent
- Division safety: NULLIF(denominator, 0)

PHASE 3: OUTPUT GENERATION & VALIDATION

**PRE-OUTPUT CHECKLIST:** ‚ö†Ô∏è MUST VERIFY
‚ñ° All mandatory filters present in WHERE clause?
‚ñ° All validated filters applied with UPPER()?
‚ñ° Source components shown for calculations?

==============================
INTEGRATION INSTRUCTIONS
==============================

- Integrate the user's clarification naturally into the SQL logic
- If clarification provided specific formulas, implement them precisely
- If clarification resolved time periods, use exact dates/ranges specified  
- If clarification defined metrics, use the exact business definitions provided
- Maintain all original SQL quality standards while incorporating clarifications

==============================
OUTPUT FORMATS
==============================
IMPORTANT: You can use proper SQL formatting with line breaks and indentation inside the XML tags
return ONLY the SQL query wrapped in XML tags. No other text, explanations, or formatting

**OPTION 1: If user's response is a NEW QUESTION**
<new_question>
<detected>true</detected>
<reasoning>[Brief 1-sentence why this is a new question]</reasoning>
</new_question>

**OPTION 2: If user's response is TOPIC DRIFT (unrelated)**
<topic_drift>
<detected>true</detected>
<reasoning>[Brief 1-sentence why this is off-topic]</reasoning>
</topic_drift>

**OPTION 3: If RELEVANT - Single SQL Query**
<sql>
[Your complete SQL query incorporating both original question and clarifications]
</sql>
<sql_story>
[2-3 lines explaining in business-friendly language: what table(s) you're using, what filters are applied, and what metric/calculation you're providing to answer the question. Make it simple for non-technical business users to understand.]
</sql_story>
<history_sql_used>[true/false - Did you use the historical SQL pattern/structure? true if you inherited dimensions, JOINs, or structural patterns from history_section; false if you generated SQL from scratch]</history_sql_used>

**OPTION 4: If RELEVANT - Multiple SQL Queries**
<multiple_sql>
<query1_title>[Brief descriptive title - max 8 words]</query1_title>
<query1>[First SQL query]</query1>
<query2_title>[Brief descriptive title - max 8 words]</query2_title>
<query2>[Second SQL query]</query2>
</multiple_sql>
<sql_story>
[2-3 lines explaining in business-friendly language: what tables you're using, what filters are applied, and what metrics/calculations you're providing to answer the question. Make it simple for non-technical business users to understand.]
</sql_story>
<history_sql_used>[true/false - Did you use the historical SQL pattern/structure? true if you inherited dimensions, JOINs, or structural patterns from history_section; false if you generated SQL from scratch]</history_sql_used>

**SQL_STORY REQUIREMENTS:**
- Write 2-3 concise lines in plain business English
- Explain: (1) Which table(s) are being queried, (2) What filters/constraints are applied, (3) What metric or calculation is being retrieved
- Avoid technical jargon - use business-friendly terms
- Example: "I'm querying the Claims Transaction table to find revenue by therapy class. I've filtered the data to show only PBM claims for August 2025. The results will show total revenue grouped by each therapy class."

Reminder: Must preserve the mandatory filter value in the SQL generation

    """

        for attempt in range(self.max_retries):
            try:
                # print('follow up sql prompt',followup_sql_prompt)
                llm_response = await self.db_client.call_claude_api_endpoint_async(
                    messages=[{"role": "user", "content": followup_sql_prompt}],
                    max_tokens=3000,
                    temperature=0.0,  # Deterministic for SQL generation
                    top_p=0.1,
                    system_prompt="You are a Databricks SQL code generator processing follow-up clarifications. Your role is to generate SQL queries that incorporate both the original user question and their clarification answers. When users request calculations like 'cost per member' or 'margin per script', you generate SQL code to compute these - you do not perform the calculations yourself. You output SQL code wrapped in XML tags."
                )
                print('follow up sql response',llm_response)
                
                # Log LLM output - actual response truncated to 500 chars
                self._log('info', "LLM response received from SQL followup handler", state,
                         llm_response=llm_response,
                         attempt=attempt + 1)
                
                # Check for new_question flag first
                new_question_match = re.search(r'<new_question>.*?<detected>(.*?)</detected>.*?<reasoning>(.*?)</reasoning>.*?</new_question>', llm_response, re.DOTALL)
                if new_question_match:
                    detected = new_question_match.group(1).strip().lower() == 'true'
                    reasoning = new_question_match.group(2).strip()
                    if detected:
                        return {
                            'success': False,
                            'topic_drift': False,
                            'new_question': True,
                            'message': f"You've asked a new question instead of providing clarification. {reasoning}",
                            'original_followup_question': sql_followup_question,
                            'detected_new_question': sql_followup_answer
                        }

                # Check for topic_drift flag
                topic_drift_match = re.search(r'<topic_drift>.*?<detected>(.*?)</detected>.*?<reasoning>(.*?)</reasoning>.*?</topic_drift>', llm_response, re.DOTALL)
                if topic_drift_match:
                    detected = topic_drift_match.group(1).strip().lower() == 'true'
                    reasoning = topic_drift_match.group(2).strip()
                    if detected:
                        return {
                            'success': False,
                            'topic_drift': True,
                            'new_question': False,
                            'message': f"Your response seems unrelated to the clarification requested. {reasoning}",
                            'original_followup_question': sql_followup_question
                        }

                # Extract sql_story tag
                sql_story = ""
                story_match = re.search(r'<sql_story>(.*?)</sql_story>', llm_response, re.DOTALL)
                if story_match:
                    sql_story = story_match.group(1).strip()
                    print(f"üìñ Captured SQL generation story from followup ({len(sql_story)} chars)")

                # Check for multiple SQL queries
                multiple_sql_match = re.search(r'<multiple_sql>(.*?)</multiple_sql>', llm_response, re.DOTALL)
                if multiple_sql_match:
                    multiple_content = multiple_sql_match.group(1).strip()
                    
                    # Extract individual queries with titles
                    query_matches = re.findall(r'<query(\d+)_title>(.*?)</query\1_title>.*?<query\1>(.*?)</query\1>', multiple_content, re.DOTALL)
                    if query_matches:
                        sql_queries = []
                        query_titles = []
                        for i, (query_num, title, query) in enumerate(query_matches):
                            cleaned_query = query.strip().replace('`', '')
                            cleaned_title = title.strip()
                            if cleaned_query and cleaned_title:
                                sql_queries.append(cleaned_query)
                                query_titles.append(cleaned_title)
                        
                        if sql_queries:
                            # üÜï Extract history_sql_used flag
                            history_sql_used = False
                            history_match = re.search(r'<history_sql_used>\s*(true|false)\s*</history_sql_used>', llm_response, re.IGNORECASE)
                            if history_match:
                                history_sql_used = history_match.group(1).lower() == 'true'
                                print(f"üìä history_sql_used flag from LLM: {history_sql_used}")
                            
                            return {
                                'success': True,
                                'multiple_sql': True,
                                'topic_drift': False,
                                'new_question': False,
                                'sql_queries': sql_queries,
                                'query_titles': query_titles,
                                'query_count': len(sql_queries),
                                'history_sql_used': history_sql_used,  # üÜï NEW FIELD
                                'sql_story': sql_story  # NEW: Business-friendly explanation
                            }
                    
                    raise ValueError("Empty or invalid multiple SQL queries in XML response")
                
                # Check for single SQL query
                match = re.search(r'<sql>(.*?)</sql>', llm_response, re.DOTALL)
                if match:
                    sql_query = match.group(1).strip()
                    sql_query = sql_query.replace('`', '')  # Remove backticks
                    
                    if not sql_query:
                        raise ValueError("Empty SQL query in XML response")
                    
                    # üÜï Extract history_sql_used flag
                    history_sql_used = False
                    history_match = re.search(r'<history_sql_used>\s*(true|false)\s*</history_sql_used>', llm_response, re.IGNORECASE)
                    if history_match:
                        history_sql_used = history_match.group(1).lower() == 'true'
                        print(f"üìä history_sql_used flag from LLM: {history_sql_used}")
                    
                    return {
                        'success': True,
                        'multiple_sql': False,
                        'topic_drift': False,
                        'new_question': False,
                        'sql_query': sql_query,
                        'history_sql_used': history_sql_used,  # üÜï NEW FIELD
                        'sql_story': sql_story  # NEW: Business-friendly explanation
                    }
                else:
                    raise ValueError("No valid XML response found (expected sql, multiple_sql, new_question, or topic_drift)")
            
            except Exception as e:
                print(f"‚ùå SQL generation with follow-up attempt {attempt + 1} failed: {str(e)}")
                
                if attempt < self.max_retries - 1:
                    print(f"üîÑ Retrying SQL generation with follow-up... (Attempt {attempt + 1}/{self.max_retries})")
                    await asyncio.sleep(2 ** attempt)
        
        return {
            'success': False,
            'topic_drift': False,
            'new_question': False,
            'history_sql_used': False,  # üÜï NEW FIELD
            'error': f"SQL generation with follow-up failed after {self.max_retries} attempts due to Model errors"
    }
