 
        followup_prompt = f"""
               You are generating intelligent follow-up questions for healthcare finance analysis to help users drill down deeper into their data.

            CURRENT CONTEXT:
            Current Question: "{current_question}"

            Last 3 questions summary: "{narrative_response_hist}"

            USER QUESTION HISTORY (Last 15):
            {recent_user_questions}

            DOMAIN SELECTION CONTEXT: {domain_selection}
            
            PRODUCT CATEGORY FILTERING RULES:
            - If domain selection contains "PBM Network": Only suggest PBM-related product categories in follow-up questions
            - If domain selection contains "Optum Pharmacy": Only suggest Home Delivery (HDP) and/or Specialty (SP) product categories in follow-up questions
            - Never suggest product categories that don't align with the user's domain selection
            - When suggesting breakdowns by product category, respect these domain boundaries

            DATASET METADATA:
            {metadata}

            ==============================
            CRITICAL RULES - FOLLOW EXACTLY
            ==============================

            # Question Generation Requirements

            ## Format
            - Use action verbs: "Show", "What", "Break down", "Compare", "List", "Calculate"
            - Be specific and executable - NOT vague like "dig deeper" or "analyze further"
            - Each question should be a clear, runnable query

            ## Natural Language for Metrics
            - Use functional/business names instead of exact technical metric names
            - Examples:
            - Instead of "revenue_amt", use "revenue"
            - Instead of "expense_amt", use "cost" or "expenses"
            - Instead of "revenue_per_script", use "revenue per script" or "rate"
            - Instead of "brand_vs_generic_ind", use "brand vs generic"
            - Questions should still be interpretable for SQL generation - use clear business terminology that maps to the underlying metrics

            ## Time Period Preservation
            - Carefully read `last_user_question` to identify the time period being analyzed (e.g., "Q3 2024", "last two months", "September 2024", "YTD")
            - Maintain the SAME time period context in all follow-up questions unless there's a specific reason to change it (like YoY comparison)
            - Examples:
            - If user asked about "Q3 2024", follow-ups should reference "Q3 2024"
            - If user asked about "last two months", follow-ups should reference "last two months" or the specific months
            - If user asked about "September 2024", follow-ups should reference "September 2024"
            - When suggesting time comparisons (YoY, MoM, QoQ), make the comparison explicit: "Compare Q3 2024 vs Q3 2023" or "Show September 2024 vs August 2024"

            ## Investigation Flow
            - Read the `playbook` from `table_context` to understand recommended investigation sequences
            - Follow the `investigation_flow`, `investigation_priority`, or `recommended_investigation_flow` if present
            - Apply `pattern_recognition` or `pattern_signals` guidance based on patterns detected in `last_query_answer`
            - Progress through the investigation logically (don't jump levels randomly)

            ## Context Awareness
            - Analyze `last_query_answer` to understand:
            - What was discovered (patterns, concentration, variance drivers)
            - What metrics moved and how (rate up/down, volume up/down, etc.)
            - Whether results show concentration (top N = X%) or dispersed patterns
            - Use the playbook's analysis sections (revenue_analysis, cost_analysis, volume_analysis, etc.) as guidance
            - Adapt questions based on what the user is investigating (their focus area from history)

            ## Reference Strategy for Follow-up Questions
            
            **Use Specific Names (ONLY when extractable with clear attribute context)**:
            - Extract actual values from narrative history ONLY if they include the attribute name (column context)
              - **GOOD**: "Break down the revenue per script for Client MDOVA in July 2025" (narrative mentions "Client MDOVA" - clear column context)
              - **GOOD**: "What is the performance for Drug MOUNJARO and ELIQUIS in July 2025?" (narrative mentions "Drug MOUNJARO" - clear column context)
              - **BAD**: "Show me more about MDOVA" (narrative only mentions "MDOVA" without "Client" - unclear which column)
              - **CRITICAL**: If narrative only contains raw values (like "MDOVA", "Commercial") without attribute prefixes (like "Client MDOVA", "Line of Business Commercial"), DO NOT use them in follow-up questions

            **COLUMN MAPPING REQUIREMENTS**:
            - Always reference metadata to ensure column names exist: drug_name, client_name, therapy_class_name, line_of_business, etc.
            - Use business-friendly terms that map to actual columns: "drugs" → drug_name, "clients" → client_name, "therapy classes" → therapy_class_name
            - Include appropriate filter context: "for [metric] in [timeframe]" or "by [dimension] for [timeframe]"
            
            **STRICT AVOIDANCE RULES**:
            - Vague references: "these top 10 drugs", "those clients", "the previous results"  
            - Unmappable terms: Don't suggest dimensions/metrics not available in metadata
            - Context-dependent references that require memory of specific previous query results
            - **Isolated values without attribute context**: If narrative says "MDOVA has high revenue" instead of "Client MDOVA has high revenue", don't reference MDOVA in follow-ups
            - **Ambiguous values**: If you cannot determine which column a value belongs to, exclude it from follow-up questions

            ## Leverage Available Fields
            - Reference `dimensions` from meta data to suggest valid grouping/filtering options
            - Reference `metrics` from meta data to suggest valid measures and derived calculations
            - Use business-friendly dimension names where appropriate (e.g., "client" instead of "client_name", "therapy class" instead of "therapy_class_name", "line of business" instead of "line_of_business")
            - Questions should be natural but still map clearly to the available dimensions and metrics

            ## Constraints
            - Check `questions_history` - do NOT suggest questions that have already been asked, answered, or are semantically similar
            - Preserve scope: maintain time periods, filters, and dimensional focus from `last_user_question`
            - Use "top 20" or "bottom 20" for ranking questions (not top 5 or top 10)
            - If playbook suggests pivoting to complementary table, frame the question for that table's context
            - **DOMAIN-SPECIFIC PRODUCT CATEGORY FILTERING**:
              - If domain = "PBM Network": ONLY suggest PBM-related categories, NEVER Home Delivery or Specialty
              - If domain = "Optum Pharmacy": ONLY suggest Home Delivery and/or Specialty categories, NEVER PBM
              - When suggesting "break down by product category" or similar, respect domain boundaries
              - Example: For PBM Network users, suggest "Break down by PBM product category" not "Break down by Home Delivery and Specialty"

            ## Quality Standards
            - Questions should advance the investigation, not just restate what was asked
            - Suggest the "next logical step" based on investigation flow and what was discovered
            - If concentration found (top few entities = high %), drill into those entities
            - If dispersed pattern found, suggest segment-level or aggregated views
            - Balance between staying in current analysis depth vs advancing to next level
            - Ensure questions are business-friendly and natural-sounding while remaining precise enough for SQL generation

            ==============================
            RESPONSE FORMAT
            ==============================
            -Generate only 3 follow up questions strictly
            The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```.

            {{
            "followup_questions": ["What is the [metric] by [attribute] for [context]?", "Break down is the [metric] by [attribute] for [context]?", "show me the [metric] by [attribute] for [context]?"]
            }}

        """
