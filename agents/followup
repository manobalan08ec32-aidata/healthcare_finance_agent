from typing import Dict, List, Optional
import json
import asyncio
from core.state_schema import AgentState
from core.databricks_client import DatabricksClient

class FollowupQuestionAgent:
    """Smart follow-up question generator: creates intelligent drill-down questions based on context and metadata"""
    
    def __init__(self, databricks_client: DatabricksClient):
        self.db_client = databricks_client
    
    async def generate_followup_question(self, state: AgentState) -> Dict[str, any]:
        """Generate intelligent follow-up questions based on current context and history"""
        current_question = state.get('current_question', '')
        user_question_history = state.get('user_question_history', [])
        followup_questions_history = state.get('follow_up_questions_history', [])
        selected_dataset = state.get('selected_dataset', [])
        narrative_response = state.get('narrative_history', '')
        domain_selection = state.get('domain_selection', [])

        print(f"ðŸ” Generating follow-up questions for: {current_question}")
        print(f"ðŸ“ Previous follow-ups: {len(followup_questions_history)}")
        print(f"ðŸŽ¯ Domain selection: {domain_selection}")
        print(f"ðŸ“‚ Selected dataset(s): {selected_dataset}")

        # Resolve selected dataset list
        if isinstance(selected_dataset, str):
            selected_list = [selected_dataset]
        elif isinstance(selected_dataset, list):
            selected_list = selected_dataset
        else:
            selected_list = []

        # Attempt to load consolidated_flow.json from preferred then fallback path
        metadata = {}
        flow_paths = [
            'config/followup/consolidated_flow.json',  # preferred (as requested)
            'followup/consolidated_flow.json'          # fallback (existing location)
        ]
        full_flow = None
        load_error = None
        for path in flow_paths:
            try:
                with open(path, 'r') as f:
                    full_flow = json.load(f)
                    print(f"âœ… Loaded consolidated flow from {path}")
                    break
            except Exception as e:
                load_error = e
                continue

        if full_flow is None:
            print(f"âŒ Could not load consolidated_flow.json from any path: {load_error}")
            full_flow = {}

        # Filter metadata by selected dataset list
        if isinstance(full_flow, dict) and selected_list:
            filtered = {}
            for ds in selected_list:
                if ds in full_flow:
                    filtered[ds] = full_flow[ds]
            if filtered:
                metadata = filtered
            else:
                metadata = full_flow  # fallback to entire structure if no exact match
        else:
            metadata = full_flow if isinstance(full_flow, dict) else {}

        followup_result = await self._generate_smart_followup(
            current_question=current_question,
            user_history=user_question_history,
            followup_history=followup_questions_history,
            metadata=metadata,
            narrative_response=narrative_response,
            domain_selection=domain_selection
        )

        print('coming out of follow up question')
        return followup_result
    
    async def _generate_smart_followup(self, current_question: str, user_history: List[str], 
                    followup_history: List[str], metadata: Dict,
                    narrative_response: str, domain_selection: List[str]) -> Dict[str, any]:
        """Generate smart follow-up questions using LLM with retry logic"""
        
        # Prepare context strings
        recent_user_questions = "\n".join(user_history[-15:]) if user_history else "No previous questions"
        narrative_response_hist = "\n".join(narrative_response[-1:]) if narrative_response else "No previous questions"
        
        # Convert metadata to string for LLM
        # metadata_str = json.dumps(metadata, indent=2) if metadata else "No metadata available"
        
        followup_prompt = f"""
You are generating intelligent follow-up questions for healthcare finance analysis to help users drill down deeper into their data.

CURRENT CONTEXT:
Current Question: "{current_question}"

Last 3 questions summary: "{narrative_response_hist}"

USER QUESTION HISTORY (Last 15):
{recent_user_questions}

DOMAIN SELECTION CONTEXT: {domain_selection}

PRODUCT CATEGORY FILTERING RULES:
- **IMPORTANT**: These rules apply ONLY if the metadata contains product_category dimension with actual values
- Before applying these rules, check the metadata's dimensions section to confirm product_category field exists
- If product_category dimension does NOT exist in the metadata, do NOT suggest product category breakdowns in follow-up questions
- If product_category dimension EXISTS in metadata:
  - If domain selection contains "PBM Network": Only suggest PBM-related product categories in follow-up questions
  - If domain selection contains "Optum Pharmacy": Only suggest Home Delivery (HDP) and/or Specialty (SP) product categories in follow-up questions
  - Never suggest product categories that don't align with the user's domain selection
  - When suggesting breakdowns by product category, respect these domain boundaries

FORECAST CYCLE CONTEXT RULES:
- When user asks forecast-related questions (forecast, projection, projected, future, plan), always include the appropriate forecast cycle
- **If user already mentioned a specific cycle** (e.g., forecast 8+4, forecast 5+7, forecast 2+10):
  - Use the SAME cycle mentioned by the user in all forecast-related follow-up questions
  - Example: If user asked "show forecast for cycle 8+4", all follow-ups should reference "forecast 8+4"
- **If user did NOT mention a specific cycle**:
  - Calculate the appropriate forecast cycle based on current month using this logic:
    - Month 1 (Jan): Use forecast 8+4  [pattern: 0+12]
    - Months 2-4 (Feb-Apr): Use forecast 8+4  [pattern: 2+10]
    - Months 5-7 (May-Jul): Use forecast 5+7  [pattern: 5+7]
    - Months 8-12 (Aug-Dec): Use forecast 8+4  [pattern: 8+4]
  - Include this calculated cycle in ALL forecast-related follow-up questions
  - Example: If current month is July and user asks "what is forecast revenue", follow-ups should include "forecast 5+7"
  - Example: If current month is September and user asks "what is forecast revenue", follow-ups should include "forecast 8+4"
- **MANDATORY**: Every forecast-related follow-up question MUST include the appropriate cycle (either user-specified or calculated)

DATASET METADATA:
{metadata}

==============================
CRITICAL RULES - FOLLOW EXACTLY
==============================

# Question Generation Requirements

## Format
- Use action verbs: "Show", "What", "Break down", "Compare", "List", "Calculate"
- Be specific and executable - NOT vague like "dig deeper" or "analyze further"
- Each question should be a clear, runnable query

## Natural Language for Metrics
- Use functional/business names instead of exact technical metric names
- Examples:
  - Instead of "revenue_amt", use "revenue"
  - Instead of "expense_amt", use "cost" or "expenses"
  - Instead of "revenue_per_script", use "revenue per script" or "rate"
  - Instead of "brand_vs_generic_ind", use "brand vs generic"
- Questions should still be interpretable for SQL generation - use clear business terminology that maps to the underlying metrics

## Time Period Preservation
- Carefully read `current_question` to identify the time period being analyzed (e.g., "Q3 2024", "last two months", "September 2024", "YTD")
- Maintain the SAME time period context in all follow-up questions unless there's a specific reason to change it (like YoY comparison)
- Examples:
  - If user asked about "Q3 2024", follow-ups should reference "Q3 2024"
  - If user asked about "last two months", follow-ups should reference "last two months" or the specific months
  - If user asked about "September 2024", follow-ups should reference "September 2024"
- When suggesting time comparisons (YoY, MoM, QoQ), make the comparison explicit: "Compare Q3 2024 vs Q3 2023" or "Show September 2024 vs August 2024"

## Forecast Cycle Handling (CRITICAL - ALWAYS APPLY)
- **Step 1**: Check if current_question contains forecast-related keywords (forecast, projection, projected, future, plan)
- **Step 2**: If yes, check if user specified a cycle in their question
  - Look for: "forecast 8+4", "forecast 5+7", "forecast 2+10", "8+4", "cycle 5+7", "cycle 3", "fc1", "fc2", "fc3"
- **Step 3**: Determine which cycle to use:
  - If user specified cycle â†’ Use that exact cycle in all follow-ups
  - If user did NOT specify cycle â†’ Calculate cycle based on current month:
    - Current month 1 (Jan) â†’ forecast 0+12 [pattern: 0+12]
    - Current month 2-4 (Feb-Apr) â†’ forecast 2+10 [pattern: 2+10]
    - Current month 5-7 (May-Jul) â†’ forecast 5+7 [pattern: 5+7]
    - Current month 8-12 (Aug-Dec) â†’ forecast 8+4 [pattern: 8+4]
- **Step 4**: Include the determined cycle in EVERY forecast-related follow-up question
  - âœ“ CORRECT: "Show forecast revenue by lob for forecast 8+4 in July 2025"
  - âœ“ CORRECT: "Break down forecast expenses for forecast 5+7 in September 2025"
  - âœ— WRONG: "Show forecast revenue by client" (missing cycle)
  - âœ— WRONG: "What is the forecast for next quarter" (missing cycle)

## Investigation Flow
- Read the `playbook` from metadata's `table_context` to understand recommended investigation sequences
- Follow the `investigation_flow`, `investigation_priority`, or `recommended_investigation_flow` if present
- Apply `pattern_recognition` or `pattern_signals` guidance based on patterns detected in `narrative_response_hist`
- Progress through the investigation logically (don't jump levels randomly)

## Context Awareness
- Analyze `narrative_response_hist` to understand:
  - What was discovered (patterns, concentration, variance drivers)
  - What metrics moved and how (rate up/down, volume up/down, etc.)
  - Whether results show concentration (top N = X%) or dispersed patterns
- Use the playbook's analysis sections (revenue_analysis, cost_analysis, volume_analysis, etc.) as guidance
- Adapt questions based on what the user is investigating (their focus area from history)

## Reference Strategy for Follow-up Questions

**Use Specific Names (ONLY when extractable with clear attribute context)**:
- Extract actual values from narrative history ONLY if they include the attribute name (column context)
  - **GOOD**: "Break down the revenue per script for Client MDOVA in July 2025" (narrative mentions "Client MDOVA" - clear column context)
  - **GOOD**: "What is the performance for Drug MOUNJARO and ELIQUIS in July 2025?" (narrative mentions "Drug MOUNJARO" - clear column context)
  - **BAD**: "Show me more about MDOVA" (narrative only mentions "MDOVA" without "Client" - unclear which column)
  - **CRITICAL**: If narrative only contains raw values (like "MDOVA", "Commercial") without attribute prefixes (like "Client MDOVA", "Line of Business Commercial"), DO NOT use them in follow-up questions

**COLUMN MAPPING REQUIREMENTS**:
- Always reference metadata to ensure column names exist: drug_name, client_name, therapy_class_name, line_of_business, etc.
- Use business-friendly terms that map to actual columns: "drugs" â†’ drug_name, "clients" â†’ client_name, "therapy classes" â†’ therapy_class_name
- Include appropriate filter context: "for [metric] in [timeframe]" or "by [dimension] for [timeframe]"

**STRICT AVOIDANCE RULES**:
- Vague references: "these top 10 drugs", "those clients", "the previous results"
- Unmappable terms: Don't suggest dimensions/metrics not available in metadata
- Context-dependent references that require memory of specific previous query results
- **Isolated values without attribute context**: If narrative says "MDOVA has high revenue" instead of "Client MDOVA has high revenue", don't reference MDOVA in follow-ups
- **Ambiguous values**: If you cannot determine which column a value belongs to, exclude it from follow-up questions

## Leverage Available Fields
- Reference `dimensions` from metadata to suggest valid grouping/filtering options
- Reference `metrics` from metadata to suggest valid measures and derived calculations
- Use business-friendly dimension names where appropriate (e.g., "client" instead of "client_name", "therapy class" instead of "therapy_class_name", "line of business" instead of "line_of_business")
- Questions should be natural but still map clearly to the available dimensions and metrics

## Constraints
- Check `questions_history` - do NOT suggest questions that have already been asked, answered, or are semantically similar
- Preserve scope: maintain time periods, filters, and dimensional focus from `current_question`
- Use "top 20" or "bottom 20" for ranking questions (not top 5 or top 10)
- If playbook suggests pivoting to complementary table, frame the question for that table's context
- **PRODUCT CATEGORY FILTERING** (only if product_category dimension exists in metadata):
  - If domain = "PBM Network": ONLY suggest PBM-related categories, NEVER Home Delivery or Specialty
  - If domain = "Optum Pharmacy": ONLY suggest Home Delivery and/or Specialty categories, NEVER PBM
  - When suggesting "break down by product category" or similar, respect domain boundaries
  - Example: For PBM Network users, suggest "Break down by PBM product category" not "Break down by Home Delivery and Specialty"
- **If product_category dimension does NOT exist in metadata**: Do NOT suggest product category breakdowns at all

## Quality Standards
- Questions should advance the investigation, not just restate what was asked
- Suggest the "next logical step" based on investigation flow and what was discovered
- If concentration found (top few entities = high %), drill into those entities
- If dispersed pattern found, suggest segment-level or aggregated views
- Balance between staying in current analysis depth vs advancing to next level
- Ensure questions are business-friendly and natural-sounding while remaining precise enough for SQL generation

==============================
RESPONSE FORMAT
==============================
- Generate only 3 follow up questions strictly
- The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. 
- The response MUST not start with ```json and end with ```.

{{
  "followup_questions": [
    "What is the [metric] by [attribute] for [context]?", 
    "Break down the [metric] by [attribute] for [context]?", 
    "Show me the [metric] by [attribute] for [context]?"
  ]
}}



"""
        
        max_retries = 3
        retry_count = 0
        backoff_time = 1  # Start with 1 second backoff
        while retry_count < max_retries:
            try:
                # print('follow up prompt',followup_prompt)
                
                llm_response = await self.db_client.call_claude_api_endpoint_async([
                    {"role": "user", "content": followup_prompt}
                ])
                
                response_json = json.loads(llm_response)
                followup_questions = response_json.get('followup_questions', [])
                
                # Accept LLM response directly without validation
                if isinstance(followup_questions, list) and followup_questions:
                    print(f"âœ… Generated {len(followup_questions)} follow-up questions")
                    return {
                        'followup_questions': followup_questions,
                        'success': True
                    }
                
                print(f"âš ï¸ No follow-up questions found in response, retrying...")
                retry_count += 1
                import asyncio
                await asyncio.sleep(backoff_time)
                backoff_time *= 2  # Exponential backoff

            except Exception as e:
                print(f"âŒ Follow-up question generation attempt {retry_count} failed: {str(e)}")
                retry_count += 1
                import asyncio
                await asyncio.sleep(backoff_time)
                backoff_time *= 2  # Exponential backoff

        # If all retries fail, return an error message
        return {
            'success': False,
            'error_message': f"Model serving endpoint failed after {max_retries} attempts."
        }
