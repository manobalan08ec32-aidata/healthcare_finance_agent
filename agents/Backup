import json
import re
import asyncio
from datetime import datetime
from typing import Dict, Any


class SQLGenerator:
    """Two-stage SQL generation with reasoning and pattern learning"""
    
    def __init__(self, db_client, max_retries: int = 3):
        self.db_client = db_client
        self.max_retries = max_retries
    
    def _log(self, level: str, message: str, state: Dict, **kwargs):
        """Logging helper"""
        print(f"[{level.upper()}] {message}")
        for key, value in kwargs.items():
            print(f"  {key}: {str(value)[:500]}")
    
    def _build_reasoning_prompt(self, context: Dict, state: Dict) -> str:
        """Build the reasoning and validation prompt (Call 1)
        
        This prompt handles:
        - Filter validation against metadata
        - Semantic mapping with confidence levels
        - Ambiguity detection
        - User hints/corrections
        - Intent detection for multiple values
        - Filter resolution with priority hierarchy
        """
        
        current_question = context.get('current_question', '')
        dataset_metadata = context.get('dataset_metadata', '')
        filter_metadata_results = state.get('filter_metadata_results', [])
        mandatory_columns_text = state.get('mandatory_columns_text', '')
        history_question_match = state.get('history_question_match', '')
        matched_sql = state.get('matched_sql', '')
        selected_datasets = state.get('selected_dataset', [])
        
        # Get table name for output
        table_name = selected_datasets[0] if selected_datasets else "unknown_table"
        
        # Light history reference for filter resolution hints only
        history_hint = ""
        if matched_sql and history_question_match:
            history_hint = f"""
HISTORY REFERENCE (for filter column resolution hints only - NOT for time filters):
Previous question: {history_question_match}
If current question has a filter value that appears in multiple columns, check which column history used for similar filter.
âš ï¸ EXCEPTION: Do NOT use history for year/month/quarter/date - always use current question's time.
"""

        prompt = f"""You are a SQL planning assistant for DANA. Analyze the question, validate all mappings, and output a structured context for SQL generation.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INPUTS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CURRENT QUESTION: {current_question}

AVAILABLE METADATA:
{dataset_metadata}

MANDATORY FILTERS:
{mandatory_columns_text}

EXTRACTED FILTER VALUES (from cross-table search - may contain columns not in this table):
{filter_metadata_results}
{history_hint}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 1: SEMANTIC ANALYSIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

STEP 1.0: EXTRACT USER HINTS/CORRECTIONS (check FIRST)
If user explicitly provides guidance, treat as HIGH CONFIDENCE override:
- Column specification: "use carrier_id", "based on drug_cost" â†’ Use that exact column
- Clarification: "I mean X not Y", "specifically the net_revenue" â†’ Use specified column
- Exclusion: "ignore therapy class", "don't group by month" â†’ Exclude from query
- Correction: "not carrier_name, use carrier_id" â†’ Apply correction directly
These hints override any ambiguity - skip follow-up for clarified terms.

STEP 1.1: IDENTIFY MEANINGFUL TERMS
- EXTRACT: Metrics (revenue, cost, margin, amount, count)
- EXTRACT: Dimensions (carrier, product, category, month, year)
- EXTRACT: Filter values (MPDOVA, HDP, August, 2025)
- SKIP: Generic words (show, get, give, data, analysis, performance, please)

STEP 1.2: SEMANTIC COLUMN MAPPING
For each term, find semantically related columns in METADATA:

HIGH CONFIDENCE (proceed without asking):
- ONE column semantically matches, even if wording differs
- Standard date parsing (August 2025 â†’ month=8, year=2025)

LOW CONFIDENCE - AMBIGUOUS (must ask follow-up):
- Multiple columns in SAME semantic category
- Generic term with multiple interpretations

NO MATCH (explain limitation, never invent):
- Business term has zero related columns â†’ not available
- NEVER invent columns or calculations

STEP 1.3: INTENT DETECTION FOR MULTIPLE VALUES
When user mentions multiple specific values or time periods:

DEFAULT - Show breakdown (GROUP BY):
- "revenue for HDP, SP" â†’ GROUP BY product_category
- "revenue Jan to March" â†’ GROUP BY month

EXCEPTION - Aggregate only if explicit:
- "total revenue for HDP and SP combined" â†’ No GROUP BY
- "sum of Jan through March" â†’ No GROUP BY

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 2: FILTER VALIDATION & RESOLUTION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MANDATORY FIRST: VALIDATE FILTER COLUMNS EXIST IN METADATA
EXTRACTED FILTERS may contain columns from OTHER tables.

For EACH filter in EXTRACTED FILTER VALUES:
1. Extract column name and value
2. Check: Does this column exist in AVAILABLE METADATA?
3. Decision:
   - EXISTS â†’ Mark as VALID
   - NOT EXISTS â†’ CANNOT use this column:
     a. Check if value exists in another metadata column â†’ Use alternative
     b. No alternative + user mentioned it â†’ FOLLOWUP_REQUIRED
     c. No alternative + user didn't mention â†’ Silently ignore

STRICT: Never output a filter column that doesn't exist in AVAILABLE METADATA.

FILTER RESOLUTION PRIORITY (check in order, stop at first success):

PRIORITY 1: History hint (if available)
- If value appears in multiple columns AND history used one â†’ Use history's column
- âš ï¸ EXCEPT time filters - always use current question's time

PRIORITY 2: Question has ATTRIBUTE + VALUE
- "revenue by carrier for MPDOVA" â†’ Find which carrier column has MPDOVA

PRIORITY 3: Value only (no attribute hint)
- Single column match â†’ Use it
- Multiple exact matches + attribute hint â†’ Use hinted column
- Multiple exact matches + no hint â†’ AMBIGUOUS â†’ follow-up
- One exact + others partial â†’ Use exact match

PRIORITY 4: Value not in extracted filters
- Standard value (month name, year) â†’ Parse directly
- Can't resolve â†’ follow-up

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 3: DECISION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IF any of these:
- AMBIGUOUS metric (multiple columns could match)
- AMBIGUOUS filter (value in multiple columns, no hint)
- Invalid filter column + user mentioned it + no alternative
- Vague time reference ("recently", "a while ago")
â†’ decision = FOLLOWUP_REQUIRED

IF all mappings HIGH CONFIDENCE:
â†’ decision = SQL_READY

DO NOT ask follow-up for:
- Single semantic match (even if wording differs)
- Filter resolved to single valid column
- Standard date parsing
- User provided explicit hint

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
OUTPUT FORMAT (JSON only, no other text)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{{
  "decision": "SQL_READY | FOLLOWUP_REQUIRED",
  "followup_question": "specific question or null",
  
  "table": "{table_name}",
  
  "metric": {{
    "requested_term": "what user asked for",
    "column": "amount_or_count",
    "metric_type_filter": "Revenues | COGS Post Reclass | Adjusted Scripts | etc",
    "additional_metric_types": ["other metric_types if calculation needed"],
    "aggregation": "SUM | COUNT | AVG"
  }},
  
  "filters": [
    {{"column": "column_name", "operator": "= | IN | > | <", "value": "value or [list]", "source": "MANDATORY | QUESTION | EXTRACTED"}}
  ],
  
  "grouping": {{
    "explicit_columns": ["columns user explicitly asked to group by"],
    "from_multiple_values": ["columns to group by due to multiple values mentioned"],
    "intent": "simple_aggregate | breakdown | comparison | top_n | trend"
  }},
  
  "user_hints_applied": ["list of user hints/corrections applied, or empty"]
}}

OUTPUT ONLY VALID JSON. No explanations, no markdown, no extra text.
"""
        return prompt
    
    def _build_sql_writer_prompt(self, context_json: Dict, state: Dict) -> str:
        """Build the SQL generation prompt with history pattern learning (Call 2)
        
        This prompt handles:
        - History pattern detection (GROUPING SETS, UNION, SIMPLE)
        - Enhancement decision (inherit breakdown from history)
        - metric_type handling (CASE WHEN pivot vs GROUP BY)
        - Component display rule
        - Query patterns (TOP N, TIME COMPARISON, etc.)
        - All SQL formatting rules
        """
        
        history_question_match = state.get('history_question_match', '')
        matched_sql = state.get('matched_sql', '')
        has_history = bool(matched_sql and history_question_match)
        
        # Build history section for pattern learning
        if has_history:
            history_section = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HISTORICAL SQL FOR PATTERN LEARNING
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
PREVIOUS QUESTION: {history_question_match}

<historical_sql>
{matched_sql}
</historical_sql>

PURPOSE: History represents LEARNED DETAIL PREFERENCES. Your goal is to ENHANCE simple questions with historical detail patterns - not just copy SQL.
PRINCIPLE: If history shows breakdown + totals, provide that detail level even if user asks a simple question.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 1: PATTERN ANALYSIS (do this FIRST before any SQL)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Analyze HISTORICAL SQL structure:

DETECT PATTERN TYPE:
- Contains "GROUPING SETS" + "GROUPING(" function â†’ GROUPING_SETS_TOTAL
- Contains "UNION ALL" + 'Total'/'OVERALL' literal â†’ UNION_TOTAL
- Neither â†’ SIMPLE

IF GROUPING_SETS_TOTAL detected, extract:
- breakdown_column: column inside GROUPING() function
- parent_dimension: the parent filter column (e.g., product_category)
- grouping_sets_structure: the exact GROUPING SETS clause
- total_label: label used (OVERALL_TOTAL, Total, etc.)
- order_position: total first (0) or last (1) in ORDER BY

IF UNION_TOTAL detected, extract:
- How the total row is constructed
- What literal is used for the total label

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 2: ENHANCEMENT DECISION
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ENHANCE with history pattern = YES when ALL true:
âœ“ Pattern is GROUPING_SETS_TOTAL or UNION_TOTAL
âœ“ Same/similar metric (both ask for revenue, both ask for cost, etc.)
âœ“ Current question filters on PARENT dimension of history's breakdown
  (e.g., history breaks down product_sub_category_lvl_2, current filters product_category)
âœ“ User did NOT say "total only", "just sum", "single number", "aggregate only"

ENHANCE = NO when ANY true:
âœ— Pattern is SIMPLE (nothing to inherit)
âœ— Different metric type entirely
âœ— User explicitly wants only aggregate total
âœ— Current already has different explicit grouping

WHEN TO APPLY PATTERN (if ENHANCE = YES):
- User explicitly asks for breakdown â†’ Apply
- History has breakdown on sub-dimension + current filters parent + same metric â†’ Apply
- User asks comparison across time periods â†’ Apply

ONLY SKIP PATTERN WHEN:
- User explicitly says "total only", "just the sum", "single number"
"""
        else:
            history_section = """
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
HISTORICAL SQL
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
No historical SQL available. Generate fresh SQL based on context.
Set pattern_detected = NONE and history_sql_used = false
"""

        # Convert context to string for prompt
        context_str = json.dumps(context_json, indent=2)

        prompt = f"""You are a Databricks SQL generator for DANA. Generate SQL using the validated context and learn patterns from historical SQL.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
VALIDATED CONTEXT (all filters pre-validated, use exactly as provided)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{context_str}
{history_section}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 3: SQL GENERATION RULES
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

PRIORITY 0: MANDATORY REQUIREMENTS (violation = query failure)

M1. MANDATORY FILTERS - All filters with source="MANDATORY" MUST be in WHERE clause

M2. CASE-INSENSITIVE STRING COMPARISON
- Always use: WHERE UPPER(column) = UPPER('value')
- Never use: WHERE column = 'value'

M3. SAFE DIVISION
- Always use: NULLIF(denominator, 0)
- Never use: bare division

M4. NUMERIC FORMATTING
- Amounts: ROUND(value, 0) AS column_name
- Percentages: ROUND(value, 3) AS column_pct

PRIORITY 1: METRIC TYPE HANDLING (critical for calculations)

When table has metric_type column:

FOR CALCULATIONS (margin, ratios, per-script metrics):
Pivot metric_type into CASE WHEN columns, do NOT group by metric_type:

CORRECT:
SELECT 
    dimension,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('Revenues') THEN amount_or_count ELSE 0 END) AS revenues,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('COGS Post Reclass') THEN amount_or_count ELSE 0 END) AS cogs,
    ROUND(SUM(CASE WHEN UPPER(metric_type) = UPPER('Revenues') THEN amount_or_count ELSE 0 END) - 
          SUM(CASE WHEN UPPER(metric_type) = UPPER('COGS Post Reclass') THEN amount_or_count ELSE 0 END), 0) AS gross_margin
FROM table
WHERE UPPER(metric_type) IN (UPPER('Revenues'), UPPER('COGS Post Reclass'))
GROUP BY dimension

WRONG (breaks calculations):
GROUP BY dimension, metric_type  -- Creates separate rows, can't calculate across

FOR SINGLE METRIC (no calculation):
Filter metric_type in WHERE, don't GROUP BY it.

PRIORITY 2: COMPONENT DISPLAY RULE

For ANY calculated metric, show source components:
- cost per script â†’ show total_cost, script_count, then cost_per_script
- margin â†’ show revenue, cost, then margin
- percentage â†’ show numerator, denominator, then percentage

PRIORITY 3: QUERY PATTERNS

PATTERN - TOP N:
SELECT column, SUM(metric) AS metric
FROM table WHERE [filters] GROUP BY column
ORDER BY metric DESC LIMIT N

PATTERN - TIME COMPARISON (side-by-side periods):
SELECT dimension,
       SUM(CASE WHEN month = 7 THEN metric END) AS jul_value,
       SUM(CASE WHEN month = 8 THEN metric END) AS aug_value
FROM table WHERE [filters] AND month IN (7, 8)
GROUP BY dimension

PATTERN - PERCENTAGE OF TOTAL:
SELECT column, SUM(metric) AS value,
       ROUND(SUM(metric) * 100.0 / (SELECT SUM(metric) FROM table WHERE [same filters]), 3) AS pct
FROM table WHERE [filters] GROUP BY column

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
STAGE 4: APPLY HISTORY PATTERN (if ENHANCE = YES)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

IF ENHANCE = YES AND pattern = GROUPING_SETS_TOTAL:

Your SQL MUST follow this structure:
```sql
SELECT
    parent_dimension,
    CASE WHEN GROUPING(breakdown_column) = 1 
         THEN 'OVERALL_TOTAL' 
         ELSE breakdown_column END AS breakdown_column,
    ROUND(SUM(CASE WHEN UPPER(metric_type) = UPPER('MetricName') THEN amount_or_count ELSE 0 END), 0) AS metric_alias
FROM table
WHERE [all filters from context]
    AND UPPER(metric_type) = UPPER('MetricName')
GROUP BY GROUPING SETS (
    (parent_dimension, breakdown_column),
    (parent_dimension)
)
ORDER BY 
    CASE WHEN breakdown_column = 'OVERALL_TOTAL' THEN 0 ELSE 1 END,
    breakdown_column
```

Use HISTORY SQL as template - replicate its structure exactly, replace only:
- Filter values (dates, entities) with values from CONTEXT
- Column names if different in current table

IF ENHANCE = YES AND pattern = UNION_TOTAL:
Your SQL MUST include: Detail query UNION ALL total query with 'OVERALL_TOTAL' literal

IF ENHANCE = NO or no history:
Generate straightforward SQL:
- simple_aggregate â†’ SELECT SUM() without sub-grouping
- breakdown â†’ GROUP BY as specified in context
- Apply all context filters

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
OUTPUT FORMAT
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
<pattern_analysis>
pattern_detected: GROUPING_SETS_TOTAL | UNION_TOTAL | SIMPLE | NONE
breakdown_column: column_name or null
parent_dimension: column_name or null
enhance_decision: YES | NO
enhance_reason: brief explanation of why enhancing or not
</pattern_analysis>

<sql>
[Complete Databricks SQL - properly formatted with line breaks]
</sql>

<sql_story>
[2-3 sentences in business-friendly language explaining:
 - What table/data is being queried
 - What filters are applied
 - What metric/calculation is returned
 - Whether breakdown with totals is included]
</sql_story>

<history_sql_used>true | false</history_sql_used>
"""
        return prompt

    async def _assess_and_generate_sql_async(self, context: Dict, state: Dict) -> Dict[str, Any]:
        """SQL generation with two-stage approach: Reasoning + SQL Writing
        
        Stage 1 (Call 1): Reasoning & Context Builder
        - Validates filters against metadata
        - Resolves ambiguities
        - Builds structured context
        - Returns follow-up if needed
        
        Stage 2 (Call 2): SQL Generation with Pattern Learning
        - Analyzes history SQL for patterns
        - Decides enhancement strategy
        - Generates SQL with mandatory rules
        """
        
        current_question = context.get('current_question', '')
        dataset_metadata = context.get('dataset_metadata', '')
        selected_datasets = state.get('selected_dataset', [])
        filter_metadata_results = state.get('filter_metadata_results', [])
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1: Search for historical SQL feedback
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print(f"ğŸ” Searching feedback SQL embeddings for selected dataset(s): {selected_datasets}")
        feedback_results = await self.db_client.sp_vector_search_feedback_sql(
            current_question, table_names=selected_datasets
        )
        
        matched_sql = ''
        history_question_match = ''
        matched_table_name = ''
        
        if feedback_results:
            print(f"ğŸ¤– Analyzing {len(feedback_results)} feedback SQL candidates from selected dataset(s)...")
            feedback_selection_result = await self.db_client._llm_feedback_selection(feedback_results, state)
            
            if feedback_selection_result.get('status') == 'match_found':
                matched_seq_id = feedback_selection_result.get('seq_id')
                
                # Find matching record
                matched_record = None
                for result in feedback_results:
                    if result.get('seq_id') == matched_seq_id:
                        matched_record = result
                        break
                
                if matched_record:
                    history_question_match = matched_record.get('user_question', '')
                    matched_sql = matched_record.get('sql_query', '')
                    matched_table_name = matched_record.get('table_name', '')
                    
                    # Store in state
                    state['history_question_match'] = history_question_match
                    state['matched_sql'] = matched_sql
                    state['matched_table_name'] = matched_table_name
                    
                    print(f"âœ… Feedback match found from {matched_table_name}")
                    print(f"   Matched question: {history_question_match[:100]}...")
                else:
                    print(f"âš ï¸ Matched seq_id {matched_seq_id} not found in results")
            else:
                print(f"â„¹ï¸ No suitable feedback SQL match found (status: {feedback_selection_result.get('status')})")
        else:
            print(f"â„¹ï¸ No feedback SQL embeddings found for selected dataset(s)")
        
        has_history = bool(matched_sql and history_question_match and matched_table_name)
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 2: Build mandatory columns text
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        mandatory_column_mapping = {
            "prd_optumrx_orxfdmprdsa.rag.ledger_actual_vs_forecast": ["Ledger"],
            "prd_optumrx_orxfdmprdsa.rag.pbm_claims": ["product_category='PBM'"]
        }
        
        mandatory_columns_info = []
        if isinstance(selected_datasets, list):
            for dataset in selected_datasets:
                if dataset in mandatory_column_mapping:
                    mandatory_columns = mandatory_column_mapping[dataset]
                    for col in mandatory_columns:
                        mandatory_columns_info.append(f"Table {dataset}: {col} (MANDATORY)")
                else:
                    mandatory_columns_info.append(f"Table {dataset}: Not Applicable")
        
        mandatory_columns_text = "\n".join(mandatory_columns_info) if mandatory_columns_info else "No mandatory columns required"
        state['mandatory_columns_text'] = mandatory_columns_text
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # CALL 1: Reasoning & Context Builder
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("=" * 70)
        print("ğŸ“‹ CALL 1: Running reasoning and validation...")
        print("=" * 70)
        print("Current Timestamp before Call 1:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        reasoning_prompt = self._build_reasoning_prompt(context, state)
        print(f"ğŸ“Š Call 1 Prompt Length: {len(reasoning_prompt)} chars")
        
        context_json = None
        
        for attempt in range(self.max_retries):
            try:
                reasoning_response = await self.db_client.call_claude_api_endpoint_async(
                    messages=[{"role": "user", "content": reasoning_prompt}],
                    max_tokens=1500,
                    temperature=0.0,
                    top_p=0.1,
                    system_prompt="You are a SQL planning assistant. Analyze questions, validate mappings against metadata, and output structured JSON context. Output ONLY valid JSON, no explanations, no markdown code blocks."
                )
                
                print("Call 1 Raw Response:", reasoning_response[:1000], "..." if len(reasoning_response) > 1000 else "")
                print("Current Timestamp after Call 1:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                
                # Parse JSON response - clean up if needed
                clean_response = reasoning_response.strip()
                
                # Remove markdown code blocks if present
                if clean_response.startswith("```json"):
                    clean_response = clean_response[7:]
                elif clean_response.startswith("```"):
                    clean_response = clean_response[3:]
                if clean_response.endswith("```"):
                    clean_response = clean_response[:-3]
                clean_response = clean_response.strip()
                
                context_json = json.loads(clean_response)
                
                print(f"âœ… Call 1 Parsed Successfully: decision={context_json.get('decision')}")
                
                # Check if follow-up is needed
                if context_json.get('decision') == 'FOLLOWUP_REQUIRED':
                    followup_question = context_json.get('followup_question', 'Could you please clarify your question?')
                    state['is_sql_followup'] = True
                    state['reasoning_context'] = context_json
                    
                    print(f"â“ Follow-up required: {followup_question}")
                    
                    return {
                        'success': True,
                        'needs_followup': True,
                        'sql_followup_questions': followup_question,
                        'used_history_asset': False,
                        'history_sql_used': False,
                        'reasoning_context': context_json
                    }
                
                # Store context for debugging
                state['reasoning_context'] = context_json
                break
                
            except json.JSONDecodeError as e:
                print(f"âŒ Call 1 JSON parse error (attempt {attempt + 1}): {str(e)}")
                print(f"   Raw response: {reasoning_response[:500]}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                else:
                    return {
                        'success': False,
                        'error': f"Reasoning stage failed: Invalid JSON response - {str(e)}",
                        'used_history_asset': False,
                        'history_sql_used': False
                    }
            except Exception as e:
                print(f"âŒ Call 1 error (attempt {attempt + 1}): {str(e)}")
                if attempt < self.max_retries - 1:
                    await asyncio.sleep(2 ** attempt)
                else:
                    return {
                        'success': False,
                        'error': f"Reasoning stage failed: {str(e)}",
                        'used_history_asset': False,
                        'history_sql_used': False
                    }
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # CALL 2: SQL Generation with History Pattern Learning
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        print("=" * 70)
        print("ğŸ”¨ CALL 2: Running SQL generation with pattern learning...")
        print("=" * 70)
        print("Current Timestamp before Call 2:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        sql_writer_prompt = self._build_sql_writer_prompt(context_json, state)
        print(f"ğŸ“Š Call 2 Prompt Length: {len(sql_writer_prompt)} chars")
        
        for attempt in range(self.max_retries):
            try:
                sql_response = await self.db_client.call_claude_api_endpoint_async(
                    messages=[{"role": "user", "content": sql_writer_prompt}],
                    max_tokens=2500,
                    temperature=0.0,
                    top_p=0.1,
                    system_prompt="You are a Databricks SQL generator. Analyze historical SQL patterns and generate SQL code. First analyze the pattern, then decide on enhancement, then generate SQL. Output in the specified XML format with pattern_analysis, sql, sql_story, and history_sql_used tags."
                )
                
                print("Call 2 Raw Response:", sql_response[:1500], "..." if len(sql_response) > 1500 else "")
                print("Current Timestamp after Call 2:", datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
                
                # Extract pattern analysis
                pattern_analysis = ""
                pattern_match = re.search(r'<pattern_analysis>(.*?)</pattern_analysis>', sql_response, re.DOTALL)
                if pattern_match:
                    pattern_analysis = pattern_match.group(1).strip()
                    state['pattern_analysis'] = pattern_analysis
                    print(f"ğŸ“Š Pattern Analysis:\n{pattern_analysis}")
                
                # Extract history_sql_used flag
                history_sql_used = False
                history_used_match = re.search(r'<history_sql_used>\s*(true|false)\s*</history_sql_used>', sql_response, re.IGNORECASE)
                if history_used_match:
                    history_sql_used = history_used_match.group(1).strip().lower() == 'true'
                print(f"ğŸ“Š History SQL Used: {history_sql_used}")
                
                # Extract sql_story
                sql_story = ""
                story_match = re.search(r'<sql_story>(.*?)</sql_story>', sql_response, re.DOTALL)
                if story_match:
                    sql_story = story_match.group(1).strip()
                    print(f"ğŸ“– SQL Story: {sql_story[:200]}...")
                
                # Extract SQL - check for multiple SQL first
                multiple_sql_match = re.search(r'<multiple_sql>(.*?)</multiple_sql>', sql_response, re.DOTALL)
                if multiple_sql_match:
                    multiple_content = multiple_sql_match.group(1).strip()
                    query_matches = re.findall(
                        r'<query(\d+)_title>(.*?)</query\1_title>.*?<query\1>(.*?)</query\1>',
                        multiple_content, re.DOTALL
                    )
                    
                    if query_matches:
                        sql_queries = []
                        query_titles = []
                        for query_num, title, query in query_matches:
                            cleaned_query = query.strip().replace('`', '')
                            cleaned_title = title.strip()
                            if cleaned_query and cleaned_title:
                                sql_queries.append(cleaned_query)
                                query_titles.append(cleaned_title)
                        
                        if sql_queries:
                            print(f"âœ… Generated {len(sql_queries)} SQL queries")
                            return {
                                'success': True,
                                'multiple_sql': True,
                                'sql_queries': sql_queries,
                                'query_titles': query_titles,
                                'query_count': len(sql_queries),
                                'used_history_asset': has_history,
                                'history_sql_used': history_sql_used,
                                'sql_story': sql_story,
                                'pattern_analysis': pattern_analysis,
                                'reasoning_context': context_json
                            }
                
                # Extract single SQL
                sql_match = re.search(r'<sql>(.*?)</sql>', sql_response, re.DOTALL)
                if sql_match:
                    sql_query = sql_match.group(1).strip()
                    # Remove backticks and clean up
                    sql_query = sql_query.replace('`', '')
                    # Remove ```sql and ``` if present
                    if sql_query.startswith('sql'):
                        sql_query = sql_query[3:].strip()
                    
                    if not sql_query:
                        raise ValueError("Empty SQL query in response")
                    
                    print(f"âœ… Generated SQL ({len(sql_query)} chars)")
                    print(f"SQL Preview:\n{sql_query[:500]}...")
                    
                    return {
                        'success': True,
                        'multiple_sql': False,
                        'sql_query': sql_query,
                        'used_history_asset': has_history,
                        'history_sql_used': history_sql_used,
                        'sql_story': sql_story,
                        'pattern_analysis': pattern_analysis,
                        'reasoning_context': context_json
                    }
                
                raise ValueError("No SQL found in response")
                
            except Exception as e:
                print(f"âŒ Call 2 error (attempt {attempt + 1}): {str(e)}")
                if attempt < self.max_retries - 1:
                    print(f"ğŸ”„ Retrying... (attempt {attempt + 2}/{self.max_retries})")
                    await asyncio.sleep(2 ** attempt)
                else:
                    return {
                        'success': False,
                        'error': f"SQL generation failed after {self.max_retries} attempts: {str(e)}",
                        'used_history_asset': has_history,
                        'history_sql_used': False,
                        'reasoning_context': context_json
                    }
        
        return {
            'success': False,
            'error': "SQL generation failed after all retries",
            'used_history_asset': False,
            'history_sql_used': False
        }
