async def _generate_sql_with_followup_async(self, context: Dict, sql_followup_question: str, sql_followup_answer: str, state: Dict) -> Dict[str, Any]:
        """Generate SQL using original question + follow-up Q&A with relevance validation in single call"""
        
        current_question = context.get('current_question', '')
        dataset_metadata = context.get('dataset_metadata', '')
        join_clause = state.get('join_clause', '')
        selected_filter_context = context.get('selected_filter_context')
        filter_metadata_results = state.get('filter_metadata_results', [])
        
        # üÜï RETRIEVE history_section from state
        history_section = state.get('sql_history_section', '')
        if history_section:
            print(f"üìñ Retrieved sql_history_section from state")
        else:
            print(f"‚ö†Ô∏è No sql_history_section found in state - proceeding without history context")
            history_section = """
=== HISTORICAL SQL ===
Not available

"""
        if history_section:
            stage_3_hist_learn="""

STAGE 3: HISTORICAL SQL PATTERN MATCHING

This stage determines HOW to use historical SQL (if available).
Historical SQL is an INTERNAL optimization - never mention it to user.

IF NO HISTORICAL SQL AVAILABLE:
- Skip this stage
- Generate SQL fresh in Stage 5
- Set history_sql_used = false

IF HISTORICAL SQL IS AVAILABLE:

STEP 4.1: SEMANTIC COMPARISON
Compare current question vs historical question:

A. SAME METRIC REQUESTED?
   Current asks for: [identify metric]
   Historical had: [identify metric]
   Match: YES / NO

B. SAME GROUPING DIMENSIONS?
   Current groups by: [identify dimensions]
   Historical grouped by: [identify dimensions]
   Match: YES / NO

C. SAME ANALYSIS TYPE?
   Types: breakdown | top-N | comparison | trend | calculation
   Current: [type]
   Historical: [type]
   Match: YES / NO

STEP 4.2: PATTERN DECISION MATRIX

IF Metric=YES AND Grouping=YES AND Type=YES:
  -> FULL PATTERN REUSE
  -> Copy entire SQL structure
  -> Replace ONLY filter values (dates, entities) with current values
  -> Set history_sql_used = true

IF Metric=YES AND (Grouping=NO OR Type=NO):
  -> PARTIAL PATTERN REUSE
  -> Keep: Metric calculations, CASE WHEN patterns, aggregation methods
  -> Rebuild: GROUP BY from current question
  -> Set history_sql_used = partial

IF Metric=NO:
  -> STRUCTURAL LEARNING ONLY
  -> Learn: UNION patterns, CTE structure, NULLIF safety, ROUND formatting
  -> Build: Fresh SQL for current question using these techniques
  -> Set history_sql_used = false

WHAT TO ALWAYS LEARN (regardless of match level):
- CASE WHEN for side-by-side columns (month comparisons)
- UNION/UNION ALL patterns (detail rows + total row)
- Division safety: NULLIF(denominator, 0)
- Rounding: ROUND(amount, 0), ROUND(percentage, 3)
- Case-insensitive: UPPER(column) = UPPER('value')

WHAT TO NEVER COPY (always from current question):
- Filter values (dates, carrier_id, entity names)
- Specific time periods
- Any <parameter> placeholders - use actual values

CRITICAL VALIDATION:
- Every column in final SQL must exist in CURRENT metadata
- Historical SQL may reference columns not in current dataset - verify before using"""      

        else:
            stage_3_hist_learn="No history sql available"
        
        # Check if we have multiple tables
        selected_datasets = state.get('selected_dataset', [])
        
        # Define mandatory column mapping
        mandatory_column_mapping = {
            "prd_optumrx_orxfdmprdsa.rag.ledger_actual_vs_forecast": [
                "Ledger"
            ]
        }
        
        # Extract mandatory columns based on selected datasets
        mandatory_columns_info = []
        if isinstance(selected_datasets, list):
            for dataset in selected_datasets:
                if dataset in mandatory_column_mapping:
                    mandatory_columns = mandatory_column_mapping[dataset]
                    for col in mandatory_columns:
                        mandatory_columns_info.append(f"Table {dataset}: {col} (MANDATORY)")
                else:
                    mandatory_columns_info.append(f"Table {dataset}: Not Applicable")
        
        # Format mandatory columns for prompt
        mandatory_columns_text = "\n".join(mandatory_columns_info) if mandatory_columns_info else "Not Applicable"
        
        # Format selected filter context for prompt
        filter_context_text = ""
        if selected_filter_context:
            filter_context_text = f"""
    SELECTED FILTER CONTEXT Available for SQL generation based on user follow up answer:
        final selection : {selected_filter_context}
    """
        
        has_multiple_tables = len(selected_datasets) > 1 if isinstance(selected_datasets, list) else False

        followup_sql_prompt = f"""You are a Databricks SQL generator for DANA (Data Analytics & Navigation Assistant).

CONTEXT: This is PHASE 2 of a two-phase process. In Phase 1, you asked a clarifying question. The user has now responded. Your task is to generate SQL using the original question + user's clarification.

CORE PRINCIPLES:
1. USER'S RESPONSE IS THE ANSWER - Treat follow-up answer as HIGH CONFIDENCE override, apply directly
2. NO MORE FOLLOW-UPS - Either generate SQL or return drift flag. Do NOT ask another question.
3. USE ONLY PROVIDED DATA - Only use columns from METADATA, values from EXTRACTED FILTERS
4. GENERATE SQL OR FLAG DRIFT - Only two valid outcomes from this prompt

INPUTS

ORIGINAL USER QUESTION: {current_question}

AVAILABLE METADATA:
{dataset_metadata}

MANDATORY FILTER COLUMNS:
{mandatory_columns_text}

EXTRACTED column contain FILTER VALUES:
{filter_metadata_results}

JOIN INFORMATION:
{join_clause}

{history_section}

FOLLOW-UP CONTEXT

YOUR PREVIOUS QUESTION: {sql_followup_question}

USER'S RESPONSE: {sql_followup_answer}

STAGE 1: VALIDATE FOLLOW-UP RESPONSE

Analyze if the user's response is relevant to your question:

RELEVANT (proceed to SQL generation):
- User directly answered your question
- User provided the clarification you asked for
- User gave additional context that resolves the ambiguity
-> PROCEED to Stage 2

NEW_QUESTION (return flag and stop):
- User asked a completely different question instead of answering
- User changed the topic entirely
-> Return <new_question> flag and STOP

TOPIC_DRIFT (return flag and stop):
- User's response is completely unrelated/off-topic
- User provided gibberish or irrelevant information
-> Return <topic_drift> flag and STOP


STAGE 2: APPLY USER'S CLARIFICATION (Only if RELEVANT)

The user's response resolves the ambiguity from Phase 1.
Apply it as HIGH CONFIDENCE override - no further validation needed.

CRITICAL RULE: One filter value = One column mapping
- User's clarification specifies which ONE column to use
- Do NOT use OR across multiple columns
- Apply the user's choice directly

INTEGRATION RULES:
- If user specified a column: Use that exact column
- If user specified a filter value: Apply to the column they indicated
- If user clarified a calculation: Implement their exact formula
- If user defined a time period: Use their exact dates/ranges
- If user chose between options: Apply their choice directly

Do NOT re-validate or question the user's choice. They have answered - now generate SQL.

{stage_3_hist_learn}

STAGE 4: SQL GENERATION

Generate SQL using:
- Original question as primary requirement
- User's clarification as resolved input
- Historical patterns from Stage 3 (if applicable)

PRIORITY 0: MANDATORY REQUIREMENTS (violation = query failure)

M1. MANDATORY FILTERS - Must be in WHERE clause
Check MANDATORY FILTER COLUMNS input
- If ledger is MANDATORY -> WHERE ledger = 'GAAP' AND ...
- If product_category='PBM' is MANDATORY -> WHERE product_category = 'PBM' AND ...

M2. CASE-INSENSITIVE STRING COMPARISON
- Always use: WHERE UPPER(column) = UPPER('value')
- Never use: WHERE column = 'value'

M3. SAFE DIVISION
- Always use: NULLIF(denominator, 0)
- Never use: bare division that could divide by zero

M4. NUMERIC FORMATTING
- Amounts: ROUND(value, 0) AS column_name
- Percentages: ROUND(value, 3) AS column_pct

PRIORITY 1: METRIC TYPE HANDLING (critical for calculations)

When table has metric_type column (Revenue, COGS, Expenses, etc.):

FOR CALCULATIONS (margin, ratios, differences):
Pivot metric_type into CASE WHEN columns, do NOT group by metric_type:

CORRECT:
SELECT 
    ledger, year, month,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('Revenues') THEN amount ELSE 0 END) AS revenues,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('COGS') THEN amount ELSE 0 END) AS cogs,
    SUM(CASE WHEN UPPER(metric_type) = UPPER('Revenues') THEN amount ELSE 0 END) - 
    SUM(CASE WHEN UPPER(metric_type) = UPPER('COGS') THEN amount ELSE 0 END) AS gross_margin
FROM table
WHERE UPPER(metric_type) IN (UPPER('Revenues'), UPPER('COGS'))
GROUP BY ledger, year, month

WRONG (breaks calculations):
GROUP BY ledger, metric_type  -- Creates separate rows, can't calculate across

FOR LISTING INDIVIDUAL METRICS:
Only GROUP BY metric_type when user explicitly asks to see each metric as separate rows.

PRIORITY 2: COMPONENT DISPLAY RULE

For ANY calculated metric, show source components:

Example for "cost per script by carrier":
SELECT 
  carrier_id,
  SUM(total_cost) AS total_cost,
  COUNT(script_id) AS script_count,
  ROUND(SUM(total_cost) / NULLIF(COUNT(script_id), 0), 2) AS cost_per_script
FROM table
GROUP BY carrier_id

PRIORITY 3: QUERY PATTERNS

PATTERN - TOP N:
SELECT column, SUM(metric) AS metric
FROM table
WHERE [mandatory filters]
GROUP BY column
ORDER BY metric DESC
LIMIT N

PATTERN - TIME COMPARISON (side-by-side periods):
SELECT dimension,
       SUM(CASE WHEN month = 7 THEN metric END) AS jul_value,
       SUM(CASE WHEN month = 8 THEN metric END) AS aug_value
FROM table
WHERE [mandatory filters] AND month IN (7, 8)
GROUP BY dimension

PATTERN - PERCENTAGE OF TOTAL:
SELECT column,
       SUM(metric) AS value,
       ROUND(SUM(metric) * 100.0 / 
             (SELECT SUM(metric) FROM table WHERE [same filters]), 3) AS pct
FROM table
WHERE [mandatory filters]
GROUP BY column

PATTERN - BREAKDOWN BY MULTIPLE VALUES:
SELECT product_category, SUM(revenue) AS revenue
FROM table
WHERE UPPER(product_category) IN (UPPER('HDP'), UPPER('SP'))
GROUP BY product_category

PATTERN - MULTI-TABLE (when JOIN provided):
SELECT t1.dimension, SUM(t1.metric) AS m1, SUM(t2.metric) AS m2
FROM table1 t1
[JOIN clause from input]
WHERE UPPER(t1.mandatory_filter) = UPPER('value')
GROUP BY t1.dimension

OUTPUT FORMAT

Always output <reasoning_summary> first, then ONE of the following: <new_question>, <topic_drift>, <sql>, or <multiple_sql>.

REASONING SUMMARY (always output):
<reasoning_summary>
followup_validation: RELEVANT | NEW_QUESTION | TOPIC_DRIFT
clarification_applied: [what the user clarified and how it was applied]
term_mappings: [term]->[column](Y) based on user clarification
filter_resolution: [column]=[value](Y) based on user clarification
intent: breakdown | aggregate | comparison | top-N | calculation
mandatory_filters: [filter1](Y applied), [filter2](Y applied)
history_pattern: TRUE | FALSE 
decision: SQL_GENERATION | NEW_QUESTION_DETECTED | TOPIC_DRIFT_DETECTED
</reasoning_summary>

IF NEW QUESTION DETECTED:
<new_question>
<detected>true</detected>
<reasoning>[Brief 1-sentence why this is a new question, not an answer to your clarification]</reasoning>
</new_question>

[STOP HERE - Do not output SQL]

IF TOPIC DRIFT DETECTED:
<topic_drift>
<detected>true</detected>
<reasoning>[Brief 1-sentence why this is off-topic/unrelated]</reasoning>
</topic_drift>

[STOP HERE - Do not output SQL]

IF SQL GENERATION (user response was RELEVANT):

For SINGLE query:
<sql>
[Complete Databricks SQL incorporating original question + user's clarification]
</sql>

<sql_story>
[2-3 sentences in business-friendly language explaining:
 - What table/data is being queried
 - What filters are applied
 - What metric/calculation is returned
 - How user's clarification was incorporated]
</sql_story>

<history_sql_used>true | false</history_sql_used>

For MULTIPLE queries:
<multiple_sql>
<query1_title>[Short title - max 8 words]</query1_title>
<query1>[SQL]</query1>
<query2_title>[Short title]</query2_title>
<query2>[SQL]</query2>
</multiple_sql>

<sql_story>
[2-3 sentences explaining the queries and how user's clarification was applied]
</sql_story>

<history_sql_used>true | false</history_sql_used>

HISTORY_SQL_USED VALUES:
- true = Used historical SQL structure with filter replacement
- false = Generated fresh (no history or history not applicable)


EXECUTION INSTRUCTION

Execute stages in order:

1. STAGE 1: Validate follow-up response -> RELEVANT / NEW_QUESTION / TOPIC_DRIFT
2. If NEW_QUESTION or TOPIC_DRIFT -> Output flag and STOP
3. STAGE 2: Apply user's clarification as HIGH CONFIDENCE override
4. STAGE 3: Determine history pattern reuse level (if history available)
5. STAGE 4: Generate SQL with mandatory requirements
6. Output reasoning_summary + SQL

OUTPUT REQUIREMENTS:
- Always output <reasoning_summary> first
- Then output ONE of: <new_question>, <topic_drift>, <sql>, or <multiple_sql>
- NEVER ask another follow-up question - this is the final generation step

CRITICAL REMINDERS:
- User's response resolves the ambiguity - apply it directly
- Every mandatory filter MUST be in WHERE clause
- Use UPPER() for all string comparisons
- Show calculation components (don't just show the result)
- Do NOT ask another follow-up question under any circumstances
"""

        for attempt in range(self.max_retries):
            try:
                # print('follow up sql prompt',followup_sql_prompt)
                llm_response = await self.db_client.call_claude_api_endpoint_async(
                    messages=[{"role": "user", "content": followup_sql_prompt}],
                    max_tokens=3000,
                    temperature=0.0,  # Deterministic for SQL generation
                    top_p=0.1,
                    system_prompt="You are a Databricks SQL code generator processing follow-up clarifications. Your role is to generate SQL queries that incorporate both the original user question and their clarification answers. When users request calculations like 'cost per member' or 'margin per script', you generate SQL code to compute these - you do not perform the calculations yourself. You output SQL code wrapped in XML tags."
                )
                print('follow up sql response',llm_response)
                
                # Log LLM output - actual response truncated to 500 chars
                self._log('info', "LLM response received from SQL followup handler", state,
                         llm_response=llm_response,
                         attempt=attempt + 1)
                
                # Check for new_question flag first
                new_question_match = re.search(r'<new_question>.*?<detected>(.*?)</detected>.*?<reasoning>(.*?)</reasoning>.*?</new_question>', llm_response, re.DOTALL)
                if new_question_match:
                    detected = new_question_match.group(1).strip().lower() == 'true'
                    reasoning = new_question_match.group(2).strip()
                    if detected:
                        return {
                            'success': False,
                            'topic_drift': False,
                            'new_question': True,
                            'message': f"You've asked a new question instead of providing clarification. {reasoning}",
                            'original_followup_question': sql_followup_question,
                            'detected_new_question': sql_followup_answer
                        }

                # Check for topic_drift flag
                topic_drift_match = re.search(r'<topic_drift>.*?<detected>(.*?)</detected>.*?<reasoning>(.*?)</reasoning>.*?</topic_drift>', llm_response, re.DOTALL)
                if topic_drift_match:
                    detected = topic_drift_match.group(1).strip().lower() == 'true'
                    reasoning = topic_drift_match.group(2).strip()
                    if detected:
                        return {
                            'success': False,
                            'topic_drift': True,
                            'new_question': False,
                            'message': f"Your response seems unrelated to the clarification requested. {reasoning}",
                            'original_followup_question': sql_followup_question
                        }

                # Extract sql_story tag
                sql_story = ""
                story_match = re.search(r'<sql_story>(.*?)</sql_story>', llm_response, re.DOTALL)
                if story_match:
                    sql_story = story_match.group(1).strip()
                    print(f"üìñ Captured SQL generation story from followup ({len(sql_story)} chars)")

                # Check for multiple SQL queries
                multiple_sql_match = re.search(r'<multiple_sql>(.*?)</multiple_sql>', llm_response, re.DOTALL)
                if multiple_sql_match:
                    multiple_content = multiple_sql_match.group(1).strip()
                    
                    # Extract individual queries with titles
                    query_matches = re.findall(r'<query(\d+)_title>(.*?)</query\1_title>.*?<query\1>(.*?)</query\1>', multiple_content, re.DOTALL)
                    if query_matches:
                        sql_queries = []
                        query_titles = []
                        for i, (query_num, title, query) in enumerate(query_matches):
                            cleaned_query = query.strip().replace('`', '')
                            cleaned_title = title.strip()
                            if cleaned_query and cleaned_title:
                                sql_queries.append(cleaned_query)
                                query_titles.append(cleaned_title)
                        
                        if sql_queries:
                            # üÜï Extract history_sql_used flag
                            history_sql_used = False
                            history_match = re.search(r'<history_sql_used>\s*(true|false)\s*</history_sql_used>', llm_response, re.IGNORECASE)
                            if history_match:
                                history_sql_used = history_match.group(1).lower() == 'true'
                                print(f"üìä history_sql_used flag from LLM: {history_sql_used}")
                            
                            return {
                                'success': True,
                                'multiple_sql': True,
                                'topic_drift': False,
                                'new_question': False,
                                'sql_queries': sql_queries,
                                'query_titles': query_titles,
                                'query_count': len(sql_queries),
                                'history_sql_used': history_sql_used,  # üÜï NEW FIELD
                                'sql_story': sql_story  # NEW: Business-friendly explanation
                            }
                    
                    raise ValueError("Empty or invalid multiple SQL queries in XML response")
                
                # Check for single SQL query
                match = re.search(r'<sql>(.*?)</sql>', llm_response, re.DOTALL)
                if match:
                    sql_query = match.group(1).strip()
                    sql_query = sql_query.replace('`', '')  # Remove backticks
                    
                    if not sql_query:
                        raise ValueError("Empty SQL query in XML response")
                    
                    # üÜï Extract history_sql_used flag
                    history_sql_used = False
                    history_match = re.search(r'<history_sql_used>\s*(true|false)\s*</history_sql_used>', llm_response, re.IGNORECASE)
                    if history_match:
                        history_sql_used = history_match.group(1).lower() == 'true'
                        print(f"üìä history_sql_used flag from LLM: {history_sql_used}")
                    
                    return {
                        'success': True,
                        'multiple_sql': False,
                        'topic_drift': False,
                        'new_question': False,
                        'sql_query': sql_query,
                        'history_sql_used': history_sql_used,  # üÜï NEW FIELD
                        'sql_story': sql_story  # NEW: Business-friendly explanation
                    }
                else:
                    raise ValueError("No valid XML response found (expected sql, multiple_sql, new_question, or topic_drift)")
            
            except Exception as e:
                print(f"‚ùå SQL generation with follow-up attempt {attempt + 1} failed: {str(e)}")
                
                if attempt < self.max_retries - 1:
                    print(f"üîÑ Retrying SQL generation with follow-up... (Attempt {attempt + 1}/{self.max_retries})")
                    await asyncio.sleep(2 ** attempt)
        
        return {
            'success': False,
            'topic_drift': False,
            'new_question': False,
            'history_sql_used': False,  # üÜï NEW FIELD
            'error': f"SQL generation with follow-up failed after {self.max_retries} attempts due to Model errors"
    }
