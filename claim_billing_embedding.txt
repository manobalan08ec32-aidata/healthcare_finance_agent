# f_claim_billing Table Column Descriptions

## Invoice Identifiers and Dates
- **inv_nbr**: Unique invoice number identifier used to distinguish individual invoices in the billing system. Primary key for invoice-level analysis.

- **invoice_date**: Date when the invoice was generated and issued to the client. Use for invoice timing and aging analysis.

- **invoice_gl_date**: General ledger posting date for the invoice. Use for financial period reporting and GL reconciliation. May differ from invoice_date.

## Entity and Account Identifiers
- **carrier_id**: Insurance carrier identifier in the billing system. Note: This is NOT the client; client_id represents the actual client.

- **account_id**: Account identifier used for account-level grouping and analysis within the billing hierarchy.

- **group_id**: Group identifier for organizing and aggregating accounts into logical groupings.

- **client_id**: Client identifier representing the actual client being billed. Examples include MDOVA, 58290. This is distinct from carrier_id.

- **client_description**: Descriptive name and details of the client. Examples include "MDOVA OVATIONS MAPD/MA ONLY/RDS" and "PDIND PDP INDIVIDUAL". Provides business context for client_id.

## Financial Metrics
- **billed_amount**: Revenue amount billed to the client. Also referred to as revenue amount. Use for all financial calculations, revenue analysis, and billing summaries.

## Product Information
- **oracle_prod_code**: Product code from the Oracle system. Examples include PROD35, PROD57. Use for product-level categorization and analysis.

- **orcl_prod_desc**: Oracle product description providing detailed product names. Examples include "E-Prescribing Admin Fee", "PMPM-VCS", "Prior Auth. Specialty". Use for product identification and reporting.

## Revenue and Activity Classification
- **rev_src_type**: Revenue source type categorization. Values include "claim fee", "claim cost", and "admin fee". Use to segment revenue by type and understand revenue composition.

- **actvty_category_cd**: Activity category code for operational classification. Examples include 02EPRES, 01PCMS. Use for activity-based analysis and categorization.

## Billing Entity Information
- **blng_entty_cd**: Billing entity code identifier. Examples include ORXUHC0036XX, ORXUHC0005XX. Use to identify which entity is performing the billing.

- **blng_entty_name**: Billing entity name providing descriptive entity information. Examples include "UHC INSURANCE COMPANY", "UHCACIS FULLY INSURED". Use for entity-level reporting and analysis.

## General Ledger (GL) String Components
The following fields comprise the GL string used for financial accounting and reporting:

- **fqa_cmpny_cd**: 3-digit company code component of the GL string. Use for company-level financial segmentation.

- **fqa_geo_cd**: 3-digit geography code component of the GL string. Use for geographic financial segmentation and reporting.

- **fqa_aflt_cd**: 3-digit affiliate code component of the GL string. Use for affiliate-level financial tracking.

- **fqa_lob_cd**: 3-digit line of business code component of the GL string. Use for LOB financial segmentation and P&L reporting.

- **fqa_acnt_cd**: 3-digit account code component of the GL string. Use for account-level GL mapping.

- **fqa_dept_cd**: 3-digit department code component of the GL string. Use for departmental cost allocation and reporting.

- **fqa_prod_cd**: 3-digit product code component of the GL string. Use for product-level financial tracking in GL.

- **fqa_sub_acnt_cd**: 3-digit sub-account code component of the GL string. Use for detailed sub-account level GL analysis.


Embedding Descriptions by Column Group
Group 1: Invoice Identifiers and Dates
Invoice identification and timing fields include inv_nbr which is the unique invoice number identifier for each billing record, invoice_date representing when the invoice was generated and issued to the client, and invoice_gl_date which is the general ledger posting date used for financial period reporting. These fields are essential for invoice lookup, tracking invoice timing, aging analysis, and reconciling invoices with the general ledger system.
Group 2: Entity and Account Identifiers
Entity and account hierarchy fields track organizational relationships. The carrier_id represents the insurance carrier identifier and is distinct from the client. The client_id field contains the actual client identifier with examples like MDOVA and 58290, paired with client_description providing detailed client names such as MDOVA OVATIONS MAPD/MA ONLY/RDS and PDIND PDP INDIVIDUAL. The account_id groups clients into accounts, while group_id provides higher-level grouping for account aggregation and hierarchical reporting. Use these fields for client analysis, account-level summaries, and understanding the carrier-client-account relationships.
Group 3: Financial Metrics
The billed_amount field represents the revenue amount or billing amount charged to clients. This is the primary financial metric for revenue analysis, billing summaries, financial calculations, total revenue reporting, and understanding amounts invoiced to clients. Use billed_amount for all monetary calculations, revenue trends, and financial performance analysis.
Group 4: Product Information
Product identification fields include oracle_prod_code containing Oracle system product codes like PROD35 and PROD57, paired with orcl_prod_desc providing detailed product descriptions such as E-Prescribing Admin Fee, PMPM-VCS, and Prior Auth Specialty. These fields enable product-level analysis, product mix reporting, revenue by product calculations, and understanding which services or products are being billed to clients.
Group 5: Revenue and Activity Classification
Revenue and activity categorization fields include rev_src_type which classifies revenue sources as claim fee, claim cost, or admin fee for understanding revenue composition and type-based analysis. The actvty_category_cd field contains activity category codes like 02EPRES and 01PCMS for operational classification and activity-based segmentation. Use these fields to analyze revenue by source type, understand billing composition, and perform activity-based reporting and analysis.
Group 6: Billing Entity Information
Billing entity fields identify who is performing the billing with blng_entty_cd containing billing entity codes such as ORXUHC0036XX and ORXUHC0005XX, and blng_entty_name providing entity names like UHC INSURANCE COMPANY and UHCACIS FULLY INSURED. These fields support entity-level reporting, understanding which legal entity is billing the client, entity performance analysis, and multi-entity billing operations.
Group 7: General Ledger String Components
General ledger string components are 3-digit codes used for financial accounting and reporting in the GL system. Fields include fqa_cmpny_cd for company segmentation, fqa_geo_cd for geographic financial tracking, fqa_aflt_cd for affiliate-level accounting, fqa_lob_cd for line of business P&L reporting, fqa_acnt_cd for account mapping, fqa_dept_cd for departmental cost allocation, fqa_prod_cd for product-level financial tracking, and fqa_sub_acnt_cd for sub-account detail. These GL string components enable financial reporting, cost allocation, departmental budgeting, geographic P&L analysis, and reconciliation between billing data and the general ledger system.


Perfect! Here are both functions with SQL queries for you to test and compare performance:

Function 1: Complex Scoring (Most Accurate)
pythondef search_with_complex_scoring(filter_list, user_segment, spark_session=None):
    """
    Complex relevance scoring - most accurate results
    
    Scoring:
        - 100: Exact match
        - 50: Contains whole phrase  
        - 30: Contains first part
        - 10: Contains second part
    
    Example:
        search_with_complex_scoring(['covid vaccine', 'diabetes'], 'PBM Network')
    """
    
    if spark_session is None:
        spark_session = spark
    
    all_patterns = []
    score_cases = []
    
    for term in filter_list:
        term_clean = term.strip().lower()
        escaped_exact = term_clean.replace("'", "\\'")
        
        # Whole phrase pattern
        whole_phrase = term_clean.replace(' ', '.*')
        escaped_whole = whole_phrase.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)')
        all_patterns.append(escaped_whole)
        
        # Score 1: Exact match (100 points)
        score_cases.append(f"CASE WHEN lower(x) = '{escaped_exact}' THEN 100 ELSE 0 END")
        
        # Score 2: Whole phrase (50 points)
        score_cases.append(f"CASE WHEN lower(x) RLIKE '(?i)({escaped_whole})' THEN 50 ELSE 0 END")
        
        # If multi-word, add scoring for parts
        if ' ' in term_clean:
            first_space_idx = term_clean.index(' ')
            first_part = term_clean[:first_space_idx]
            second_part = term_clean[first_space_idx+1:].replace(' ', '.*')
            
            escaped_first = first_part.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)')
            escaped_second = second_part.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)')
            
            all_patterns.append(escaped_first)
            all_patterns.append(escaped_second)
            
            # Score 3: First part (30 points)
            score_cases.append(f"CASE WHEN lower(x) RLIKE '(?i)({escaped_first})' THEN 30 ELSE 0 END")
            
            # Score 4: Second part (10 points)
            score_cases.append(f"CASE WHEN lower(x) RLIKE '(?i)({escaped_second})' THEN 10 ELSE 0 END")
    
    # Remove duplicates
    unique_patterns = list(set(all_patterns))
    regex_pattern = '|'.join(unique_patterns)
    score_calculation = ' + '.join(score_cases)
    
    query = f"""
    WITH matched_data AS (
        SELECT 
            table_name,
            column_name,
            trim(exploded_value) AS individual_value,
            ({score_calculation}) AS value_score
        FROM distinct_values_metadata
        LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
        WHERE login_user_segment = '{user_segment}'
          AND lower(trim(exploded_value)) RLIKE '(?i)({regex_pattern})'
    )
    SELECT 
        table_name,
        column_name,
        concat_ws(', ', collect_list(individual_value)) AS matched_values,
        SUM(value_score) AS relevance_score
    FROM matched_data
    GROUP BY table_name, column_name
    ORDER BY relevance_score DESC, table_name, column_name
    """
    
    return spark_session.sql(query)

Function 2: Length-Based Scoring (Simpler & Faster)
pythondef search_with_length_scoring(filter_list, user_segment, spark_session=None):
    """
    Length-based scoring - simpler and faster
    
    Logic: Longer matched text = more relevant
    
    Example:
        search_with_length_scoring(['covid vaccine', 'diabetes'], 'PBM Network')
    """
    
    if spark_session is None:
        spark_session = spark
    
    all_patterns = []
    
    for term in filter_list:
        term_clean = term.strip().lower()
        
        # Whole phrase pattern
        whole_phrase = term_clean.replace(' ', '.*')
        escaped_whole = whole_phrase.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)')
        all_patterns.append(escaped_whole)
        
        # If multi-word, add parts
        if ' ' in term_clean:
            first_space_idx = term_clean.index(' ')
            first_part = term_clean[:first_space_idx]
            second_part = term_clean[first_space_idx+1:].replace(' ', '.*')
            
            escaped_first = first_part.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)')
            escaped_second = second_part.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)')
            
            all_patterns.append(escaped_first)
            all_patterns.append(escaped_second)
    
    # Remove duplicates
    unique_patterns = list(set(all_patterns))
    regex_pattern = '|'.join(unique_patterns)
    
    query = f"""
    WITH matched_data AS (
        SELECT 
            table_name,
            column_name,
            trim(exploded_value) AS individual_value,
            length(trim(exploded_value)) AS value_length
        FROM distinct_values_metadata
        LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
        WHERE login_user_segment = '{user_segment}'
          AND lower(trim(exploded_value)) RLIKE '(?i)({regex_pattern})'
    )
    SELECT 
        table_name,
        column_name,
        concat_ws(', ', collect_list(individual_value)) AS matched_values,
        AVG(value_length) AS relevance_score
    FROM matched_data
    GROUP BY table_name, column_name
    ORDER BY relevance_score DESC, table_name, column_name
    """
    
    return spark_session.sql(query)

Standalone SQL Queries for Testing:
SQL 1: Complex Scoring
sql-- Test: Search for "E-Suppressing Admin Fee" with complex scoring
WITH matched_data AS (
    SELECT 
        table_name,
        column_name,
        trim(exploded_value) AS individual_value,
        (
            CASE WHEN lower(trim(exploded_value)) = 'e-suppressing admin fee' THEN 100 ELSE 0 END +
            CASE WHEN lower(trim(exploded_value)) RLIKE '(?i)(e-suppressing.*admin.*fee)' THEN 50 ELSE 0 END +
            CASE WHEN lower(trim(exploded_value)) RLIKE '(?i)(e-suppressing)' THEN 30 ELSE 0 END +
            CASE WHEN lower(trim(exploded_value)) RLIKE '(?i)(admin.*fee)' THEN 10 ELSE 0 END
        ) AS value_score
    FROM distinct_values_metadata
    LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
    WHERE login_user_segment = 'PBM Network'
      AND lower(trim(exploded_value)) RLIKE '(?i)(e-suppressing.*admin.*fee|e-suppressing|admin.*fee)'
)
SELECT 
    table_name,
    column_name,
    concat_ws(', ', collect_list(individual_value)) AS matched_values,
    SUM(value_score) AS relevance_score
FROM matched_data
GROUP BY table_name, column_name
ORDER BY relevance_score DESC, table_name, column_name;
SQL 2: Length-Based Scoring
sql-- Test: Search for "E-Suppressing Admin Fee" with length scoring
WITH matched_data AS (
    SELECT 
        table_name,
        column_name,
        trim(exploded_value) AS individual_value,
        length(trim(exploded_value)) AS value_length
    FROM distinct_values_metadata
    LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
    WHERE login_user_segment = 'PBM Network'
      AND lower(trim(exploded_value)) RLIKE '(?i)(e-suppressing.*admin.*fee|e-suppressing|admin.*fee)'
)
SELECT 
    table_name,
    column_name,
    concat_ws(', ', collect_list(individual_value)) AS matched_values,
    AVG(value_length) AS relevance_score
FROM matched_data
GROUP BY table_name, column_name
ORDER BY relevance_score DESC, table_name, column_name;

Performance Testing Script:
pythonimport time

# Test data
test_filters = ['E-Suppressing Admin Fee', 'covid vaccine', 'diabetes']
test_segment = 'PBM Network'

print("=" * 80)
print("PERFORMANCE COMPARISON TEST")
print("=" * 80)

# Test 1: Complex Scoring
print("\n1. Testing COMPLEX SCORING...")
start_time = time.time()
result_complex = search_with_complex_scoring(test_filters, test_segment)
complex_count = result_complex.count()
complex_time = time.time() - start_time

print(f"   ✓ Results: {complex_count} rows")
print(f"   ✓ Time: {complex_time:.3f} seconds")
print("\n   Top 5 Results:")
result_complex.select('table_name', 'column_name', 'relevance_score').show(5, truncate=False)

# Test 2: Length-Based Scoring
print("\n2. Testing LENGTH-BASED SCORING...")
start_time = time.time()
result_length = search_with_length_scoring(test_filters, test_segment)
length_count = result_length.count()
length_time = time.time() - start_time

print(f"   ✓ Results: {length_count} rows")
print(f"   ✓ Time: {length_time:.3f} seconds")
print("\n   Top 5 Results:")
result_length.select('table_name', 'column_name', 'relevance_score').show(5, truncate=False)

# Comparison
print("\n" + "=" * 80)
print("COMPARISON SUMMARY")
print("=" * 80)
print(f"Complex Scoring: {complex_time:.3f}s")
print(f"Length Scoring:  {length_time:.3f}s")
print(f"Difference:      {abs(complex_time - length_time):.3f}s")

if complex_time < length_time:
    print(f"✓ Complex scoring is {((length_time/complex_time - 1) * 100):.1f}% faster")
else:
    print(f"✓ Length scoring is {((complex_time/length_time - 1) * 100):.1f}% faster")

Quick Performance Test (SQL Only):
sql-- Compare execution plans
EXPLAIN EXTENDED
WITH matched_data AS (
    SELECT 
        table_name,
        column_name,
        trim(exploded_value) AS individual_value,
        (CASE WHEN lower(trim(exploded_value)) = 'test' THEN 100 ELSE 0 END) AS value_score
    FROM distinct_values_metadata
    LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
    WHERE login_user_segment = 'PBM Network'
)
SELECT table_name, column_name, SUM(value_score) AS score
FROM matched_data
GROUP BY table_name, column_name;
