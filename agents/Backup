"""
Enhanced synchronous version with DYNAMIC ranking (NO HARDCODING):
1. Tier 1A/1B split (pure vs mixed exact matches)
2. Tier 3 intelligent ranking based on:
   - Word match count (how many search words in values)
   - Match completeness ratio (% of search words found)
   - Token boundary quality (full word vs substring)
   - Column name relevance (dynamic semantic matching)
"""
from typing import List
import re


def search_metadata_sql(filter_list: List[str]) -> List[str]:
    """
    Search metadata with enhanced cascading priority:
    1A. EXACT MATCH (Pure) - ALL values are exact matches
    1B. EXACT MATCH (Mixed) - SOME values are exact, others partial
    2. STARTS-WITH MATCH - Value starts with the full term
    3. CONTAINS MATCH - Individual words found (with dynamic intelligent ranking)
    """
    try:
        if not filter_list:
            return []
        
        print(f"ðŸ” Starting enhanced search for filters: {filter_list}")
        
        # Build all match conditions for a SINGLE query
        exact_conditions = []
        starts_conditions = []
        contains_conditions = []
        
        for term in filter_list:
            term_clean = term.strip().lower()
            escaped_exact = term_clean.replace("'", "\\'")
            escaped_regex = term_clean.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)').replace('[', '\\[').replace(']', '\\]')
            
            # TIER 1: Exact match condition
            exact_conditions.append(f"lower(trim(exploded_value)) = '{escaped_exact}'")
            
            # TIER 2: Starts-with condition
            starts_conditions.append(f"lower(trim(exploded_value)) RLIKE '^{escaped_regex}\\\\b'")
            
            # TIER 3: Individual words
            words = term_clean.split()
            for word in words:
                if len(word) > 2:
                    escaped_word = word.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)').replace('[', '\\[').replace(']', '\\]')
                    contains_conditions.append(f"lower(trim(exploded_value)) RLIKE '(?i)\\\\b{escaped_word}'")
        
        # Build tier scoring logic
        exact_clause = ' OR '.join(exact_conditions)
        starts_clause = ' OR '.join(starts_conditions)
        contains_clause = ' OR '.join(contains_conditions)
        
        # Combine all conditions for WHERE clause
        all_conditions = f"({exact_clause}) OR ({starts_clause}) OR ({contains_clause})"
        
        # Tier assignment with tier tracking per value
        tier_assignment = f"""
            CASE 
                WHEN {exact_clause} THEN 1
                WHEN {starts_clause} THEN 2
                ELSE 3
            END
        """
        
        query = f"""
        WITH matched_data AS (
            SELECT
                column_name,
                trim(exploded_value) AS individual_value,
                {tier_assignment} AS match_tier
            FROM prd_optumrx_orxfdmprdsa.rag.distinct_values_metadata1
            LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
            WHERE {all_conditions}
        ),
        scored_aggregated AS (
            SELECT
                column_name,
                collect_list(individual_value) AS all_matched_values,
                collect_list(match_tier) AS all_match_tiers,
                MIN(match_tier) AS best_tier
            FROM matched_data
            GROUP BY column_name
        )
        SELECT
            column_name,
            concat_ws(', ', slice(all_matched_values, 1, 5)) AS matched_values,
            all_match_tiers,
            best_tier
        FROM scored_aggregated
        ORDER BY best_tier ASC, column_name
        """
        
        print(f"ðŸ“Š Enhanced Query:")
        print(query)
        print("\n")
        
        # Execute using spark.sql()
        result_df = spark.sql(query)
        print('results_data_filter:', result_df)
        
        # Convert DataFrame to list of dictionaries
        result_list = [row.asDict() for row in result_df.collect()]
        print(f"âœ… Converted DataFrame to list: {len(result_list)} rows")
        
        if not result_list:
            print(f"âŒ No matches found")
            return []
        
        # Python filtering: Return ONLY the highest priority tier
        return filter_by_priority_enhanced(result_list, filter_list)
        
    except Exception as e:
        print(f"âŒ Error in search_metadata_sql: {str(e)}")
        import traceback
        traceback.print_exc()
        return []


def filter_by_priority_enhanced(result_data: list, filter_list: List[str]) -> List[str]:
    """
    Enhanced filtering with:
    - Tier 1A/1B split (purity check)
    - Tier 3 dynamic intelligent ranking (NO HARDCODING)
    """
    if not result_data:
        return []
    
    # Group results by tier with purity check for Tier 1
    tier_1a_results = []  # Pure exact matches
    tier_1b_results = []  # Mixed exact matches
    tier_2_results = []
    tier_3_results = []
    
    for row in result_data:
        best_tier = int(row.get('best_tier', 3))
        column_name = row.get('column_name', '')
        matched_values = row.get('matched_values', '')
        all_match_tiers = row.get('all_match_tiers', [])
        
        result_entry = {
            'column_name': column_name,
            'matched_values': matched_values,
            'tier': best_tier,
            'all_tiers': all_match_tiers
        }
        
        if best_tier == 1:
            # Check purity: Are ALL matched values exact matches?
            if all(tier == 1 for tier in all_match_tiers):
                result_entry['sub_tier'] = '1A'
                tier_1a_results.append(result_entry)
            else:
                result_entry['sub_tier'] = '1B'
                tier_1b_results.append(result_entry)
        elif best_tier == 2:
            tier_2_results.append(result_entry)
        else:
            tier_3_results.append(result_entry)
    
    print(f"\nðŸ“Š Results breakdown:")
    print(f"   Tier 1A (PURE EXACT): {len(tier_1a_results)} columns")
    print(f"   Tier 1B (MIXED EXACT): {len(tier_1b_results)} columns")
    print(f"   Tier 2 (STARTS-WITH): {len(tier_2_results)} columns")
    print(f"   Tier 3 (CONTAINS): {len(tier_3_results)} columns")
    
    # Return ONLY highest priority tier with results
    if tier_1a_results:
        print(f"\nâœ… TIER 1A (PURE EXACT): Found {len(tier_1a_results)} matches - Returning only these")
        return format_results(tier_1a_results[:7], "EXACT-PURE")
    
    if tier_1b_results:
        print(f"\nâœ… TIER 1B (MIXED EXACT): Found {len(tier_1b_results)} matches - Returning only these")
        return format_results(tier_1b_results[:7], "EXACT-MIXED")
    
    if tier_2_results:
        print(f"\nâœ… TIER 2 (STARTS-WITH): Found {len(tier_2_results)} matches - Returning only these")
        return format_results(tier_2_results[:7], "STARTS-WITH")
    
    if tier_3_results:
        print(f"\nâœ… TIER 3 (CONTAINS): Found {len(tier_3_results)} matches - Applying dynamic intelligent ranking...")
        # Apply dynamic intelligent ranking for Tier 3
        ranked_tier_3 = rank_tier_3_dynamic(tier_3_results, filter_list)
        return format_results(ranked_tier_3[:7], "CONTAINS")
    
    print(f"\nâŒ No results after filtering")
    return []


def rank_tier_3_dynamic(tier_3_results: list, filter_list: List[str]) -> list:
    """
    Dynamic intelligent ranking for Tier 3 results (NO HARDCODING)
    
    Scoring factors:
    1. Word match count (50 points per word) - How many search words appear in values
    2. Match completeness ratio (30 points) - % of search words found
    3. Token boundary bonus (20 points) - Full word vs substring match
    4. Column name relevance (15 points) - Column name semantic matching
    """
    # Extract all search words
    search_words = []
    for term in filter_list:
        words = term.strip().lower().split()
        search_words.extend([w for w in words if len(w) > 2])
    
    total_search_words = len(search_words)
    print(f"   ðŸ” Search words for dynamic ranking: {search_words} (total: {total_search_words})")
    
    # Calculate dynamic composite score for each result
    for result in tier_3_results:
        column_name = result['column_name']
        matched_values = result['matched_values'].lower()
        
        # SCORE 1: Word match count (50 points per unique word found)
        words_found = set()
        for word in search_words:
            if word in matched_values:
                words_found.add(word)
        word_match_count = len(words_found)
        word_match_score = word_match_count * 50
        
        # SCORE 2: Match completeness ratio (30 points max)
        if total_search_words > 0:
            completeness_ratio = word_match_count / total_search_words
            completeness_score = completeness_ratio * 30
        else:
            completeness_score = 0
        
        # SCORE 3: Token boundary quality (20 points max)
        token_boundary_score = 0
        for word in words_found:
            # Check if word appears as full token (with word boundaries)
            if re.search(r'\b' + re.escape(word) + r'\b', matched_values):
                token_boundary_score += 20 / len(words_found) if words_found else 0
        
        # SCORE 4: Column name relevance (15 points max)
        column_name_lower = column_name.lower()
        column_relevance_score = 0
        
        # Check if any search word appears in column name
        for word in search_words:
            if word in column_name_lower:
                column_relevance_score += 5
        
        # Semantic column name matching (medical/pharma related terms)
        medical_terms = ['therapy', 'drug', 'medication', 'treatment', 'disease', 'diagnosis', 
                        'class', 'category', 'type', 'vaccine', 'pharmaceutical']
        for med_term in medical_terms:
            if med_term in column_name_lower and any(word in matched_values for word in search_words):
                column_relevance_score += 10
                break
        
        # Cap at 15 points
        column_relevance_score = min(column_relevance_score, 15)
        
        # COMPOSITE SCORE
        composite_score = (
            word_match_score + 
            completeness_score + 
            token_boundary_score + 
            column_relevance_score
        )
        
        # Store all scoring details
        result['word_match_count'] = word_match_count
        result['completeness_ratio'] = round(completeness_ratio * 100, 1) if total_search_words > 0 else 0
        result['token_boundary_score'] = round(token_boundary_score, 1)
        result['column_relevance_score'] = round(column_relevance_score, 1)
        result['composite_score'] = round(composite_score, 1)
        
        print(f"   ðŸ“Š {column_name}:")
        print(f"      - Words matched: {word_match_count}/{total_search_words} = {word_match_score} pts")
        print(f"      - Completeness: {result['completeness_ratio']}% = {round(completeness_score, 1)} pts")
        print(f"      - Token quality: {result['token_boundary_score']} pts")
        print(f"      - Column relevance: {result['column_relevance_score']} pts")
        print(f"      - TOTAL SCORE: {result['composite_score']}")
    
    # Sort by composite score (descending)
    tier_3_results.sort(key=lambda x: x['composite_score'], reverse=True)
    
    print(f"\n   âœ… Dynamically ranked {len(tier_3_results)} Tier 3 results")
    return tier_3_results


def format_results(result_data: list, match_type: str) -> List[str]:
    """
    Format the query results into a list of strings
    """
    concatenated_results = []
    
    for row in result_data:
        column_name = row.get('column_name', '')
        matched_values = row.get('matched_values', '')
        tier = row.get('tier', '')
        sub_tier = row.get('sub_tier', '')
        
        # Additional info for Tier 3
        extra_info = ""
        if 'composite_score' in row:
            extra_info = (f", Score:{row['composite_score']}"
                         f"[Words:{row['word_match_count']}, "
                         f"Complete:{row['completeness_ratio']}%, "
                         f"Token:{row['token_boundary_score']}, "
                         f"ColRel:{row['column_relevance_score']}]")
        
        tier_label = sub_tier if sub_tier else tier
        table_summary = f"Column: {column_name} (Tier: {tier_label}, Type: {match_type}{extra_info})\n  - Values: {matched_values}"
        concatenated_results.append(table_summary)
    
    print(f"\nðŸ“‹ Formatted {len(concatenated_results)} results for {match_type} matches")
    return concatenated_results


# ===========================================
# TEST USAGE IN DATABRICKS
# ===========================================

# Test 1: Single word filter - Should show Tier 1A vs 1B
print("=" * 100)
print("TEST 1: Single word filter - 'External'")
print("Expected: line_of_business in Tier 1A (pure), client_name in Tier 1B (mixed)")
print("=" * 100)
results1 = search_metadata_sql(['External'])
print("\nðŸŽ¯ FINAL RESULTS:")
for result in results1:
    print(result)

print("\n\n")

# Test 2: Multi-word filter - Should show dynamic intelligent Tier 3 ranking
print("=" * 100)
print("TEST 2: Multi-word filter - 'covid vaccine'")
print("Expected: therapy_class_name and drug_name should rank higher (NO HARDCODING)")
print("=" * 100)
results2 = search_metadata_sql(['covid vaccine'])
print("\nðŸŽ¯ FINAL RESULTS:")
for result in results2:
    print(result)

print("\n\n")

# Test 3: Another multi-word test
print("=" * 100)
print("TEST 3: Multi-word filter - 'diabetes treatment'")
print("=" * 100)
results3 = search_metadata_sql(['diabetes treatment'])
print("\nðŸŽ¯ FINAL RESULTS:")
for result in results3:
    print(result)


"""
Enhanced synchronous version with DYNAMIC ranking (NO HARDCODING):
1. Tier 1A/1B split (pure vs mixed exact matches)
2. Tier 3 intelligent ranking based on:
   - Word match count (how many search words in values)
   - Match completeness ratio (% of search words found)
   - Token boundary quality (full word vs substring)
   - Column name relevance (dynamic semantic matching)
"""
from typing import List
import re


def search_metadata_sql(filter_list: List[str]) -> List[str]:
    """
    Search metadata with enhanced cascading priority:
    1A. EXACT MATCH (Pure) - ALL values are exact matches
    1B. EXACT MATCH (Mixed) - SOME values are exact, others partial
    2. STARTS-WITH MATCH - Value starts with the full term
    3. CONTAINS MATCH - Individual words found (with dynamic intelligent ranking)
    """
    try:
        if not filter_list:
            return []
        
        print(f"ðŸ” Starting enhanced search for filters: {filter_list}")
        
        # Build all match conditions for a SINGLE query
        exact_conditions = []
        starts_conditions = []
        contains_conditions = []
        
        for term in filter_list:
            term_clean = term.strip().lower()
            escaped_exact = term_clean.replace("'", "\\'")
            escaped_regex = term_clean.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)').replace('[', '\\[').replace(']', '\\]')
            
            # TIER 1: Exact match condition
            exact_conditions.append(f"lower(trim(exploded_value)) = '{escaped_exact}'")
            
            # TIER 2: Starts-with condition
            starts_conditions.append(f"lower(trim(exploded_value)) RLIKE '^{escaped_regex}\\\\b'")
            
            # TIER 3: Individual words
            words = term_clean.split()
            for word in words:
                if len(word) > 2:
                    escaped_word = word.replace('\\', '\\\\').replace('(', '\\(').replace(')', '\\)').replace('[', '\\[').replace(']', '\\]')
                    contains_conditions.append(f"lower(trim(exploded_value)) RLIKE '(?i)\\\\b{escaped_word}'")
        
        # Build tier scoring logic
        exact_clause = ' OR '.join(exact_conditions)
        starts_clause = ' OR '.join(starts_conditions)
        contains_clause = ' OR '.join(contains_conditions)
        
        # Combine all conditions for WHERE clause
        all_conditions = f"({exact_clause}) OR ({starts_clause}) OR ({contains_clause})"
        
        # Tier assignment with tier tracking per value
        tier_assignment = f"""
            CASE 
                WHEN {exact_clause} THEN 1
                WHEN {starts_clause} THEN 2
                ELSE 3
            END
        """
        
        query = f"""
        WITH matched_data AS (
            SELECT
                column_name,
                trim(exploded_value) AS individual_value,
                {tier_assignment} AS match_tier
            FROM prd_optumrx_orxfdmprdsa.rag.distinct_values_metadata1
            LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
            WHERE {all_conditions}
        ),
        scored_aggregated AS (
            SELECT
                column_name,
                collect_list(individual_value) AS all_matched_values,
                collect_list(match_tier) AS all_match_tiers,
                MIN(match_tier) AS best_tier
            FROM matched_data
            GROUP BY column_name
        )
        SELECT
            column_name,
            concat_ws(', ', slice(all_matched_values, 1, 5)) AS matched_values,
            all_match_tiers,
            best_tier
        FROM scored_aggregated
        ORDER BY best_tier ASC, column_name
        """
        
        print(f"ðŸ“Š Enhanced Query:")
        print(query)
        print("\n")
        
        # Execute using spark.sql()
        result_df = spark.sql(query)
        print('results_data_filter:', result_df)
        
        # Convert DataFrame to list of dictionaries
        result_list = [row.asDict() for row in result_df.collect()]
        print(f"âœ… Converted DataFrame to list: {len(result_list)} rows")
        
        if not result_list:
            print(f"âŒ No matches found")
            return []
        
        # Python filtering: Return ONLY the highest priority tier
        return filter_by_priority_enhanced(result_list, filter_list)
        
    except Exception as e:
        print(f"âŒ Error in search_metadata_sql: {str(e)}")
        import traceback
        traceback.print_exc()
        return []


def filter_by_priority_enhanced(result_data: list, filter_list: List[str]) -> List[str]:
    """
    Enhanced filtering with:
    - Tier 1A/1B split (purity check)
    - Tier 3 dynamic intelligent ranking (NO HARDCODING)
    """
    if not result_data:
        return []
    
    # Group results by tier with purity check for Tier 1
    tier_1a_results = []  # Pure exact matches
    tier_1b_results = []  # Mixed exact matches
    tier_2_results = []
    tier_3_results = []
    
    for row in result_data:
        best_tier = int(row.get('best_tier', 3))
        column_name = row.get('column_name', '')
        matched_values = row.get('matched_values', '')
        all_match_tiers = row.get('all_match_tiers', [])
        
        result_entry = {
            'column_name': column_name,
            'matched_values': matched_values,
            'tier': best_tier,
            'all_tiers': all_match_tiers
        }
        
        if best_tier == 1:
            # Check purity: Are ALL matched values exact matches?
            if all(tier == 1 for tier in all_match_tiers):
                result_entry['sub_tier'] = '1A'
                tier_1a_results.append(result_entry)
            else:
                result_entry['sub_tier'] = '1B'
                tier_1b_results.append(result_entry)
        elif best_tier == 2:
            tier_2_results.append(result_entry)
        else:
            tier_3_results.append(result_entry)
    
    print(f"\nðŸ“Š Results breakdown:")
    print(f"   Tier 1A (PURE EXACT): {len(tier_1a_results)} columns")
    print(f"   Tier 1B (MIXED EXACT): {len(tier_1b_results)} columns")
    print(f"   Tier 2 (STARTS-WITH): {len(tier_2_results)} columns")
    print(f"   Tier 3 (CONTAINS): {len(tier_3_results)} columns")
    
    # Return ONLY highest priority tier with results
    if tier_1a_results:
        print(f"\nâœ… TIER 1A (PURE EXACT): Found {len(tier_1a_results)} matches - Returning only these")
        return format_results(tier_1a_results[:7], "EXACT-PURE")
    
    if tier_1b_results:
        print(f"\nâœ… TIER 1B (MIXED EXACT): Found {len(tier_1b_results)} matches - Returning only these")
        return format_results(tier_1b_results[:7], "EXACT-MIXED")
    
    if tier_2_results:
        print(f"\nâœ… TIER 2 (STARTS-WITH): Found {len(tier_2_results)} matches - Returning only these")
        return format_results(tier_2_results[:7], "STARTS-WITH")
    
    if tier_3_results:
        print(f"\nâœ… TIER 3 (CONTAINS): Found {len(tier_3_results)} matches - Applying dynamic intelligent ranking...")
        # Apply dynamic intelligent ranking for Tier 3
        ranked_tier_3 = rank_tier_3_dynamic(tier_3_results, filter_list)
        return format_results(ranked_tier_3[:7], "CONTAINS")
    
    print(f"\nâŒ No results after filtering")
    return []


def rank_tier_3_dynamic(tier_3_results: list, filter_list: List[str]) -> list:
    """
    Dynamic intelligent ranking for Tier 3 results (NO HARDCODING)
    
    Scoring factors:
    1. Word match count (50 points per word) - How many search words appear in values
    2. Match completeness ratio (30 points) - % of search words found
    3. Token boundary bonus (20 points) - Full word vs substring match
    4. Column name relevance (15 points) - Column name semantic matching
    """
    # Extract all search words
    search_words = []
    for term in filter_list:
        words = term.strip().lower().split()
        search_words.extend([w for w in words if len(w) > 2])
    
    total_search_words = len(search_words)
    print(f"   ðŸ” Search words for dynamic ranking: {search_words} (total: {total_search_words})")
    
    # Calculate dynamic composite score for each result
    for result in tier_3_results:
        column_name = result['column_name']
        matched_values = result['matched_values'].lower()
        
        # SCORE 1: Word match count (50 points per unique word found)
        words_found = set()
        for word in search_words:
            if word in matched_values:
                words_found.add(word)
        word_match_count = len(words_found)
        word_match_score = word_match_count * 50
        
        # SCORE 2: Match completeness ratio (30 points max)
        if total_search_words > 0:
            completeness_ratio = word_match_count / total_search_words
            completeness_score = completeness_ratio * 30
        else:
            completeness_score = 0
        
        # SCORE 3: Token boundary quality (20 points max)
        token_boundary_score = 0
        for word in words_found:
            # Check if word appears as full token (with word boundaries)
            if re.search(r'\b' + re.escape(word) + r'\b', matched_values):
                token_boundary_score += 20 / len(words_found) if words_found else 0
        
        # SCORE 4: Column name relevance (15 points max)
        column_name_lower = column_name.lower()
        column_relevance_score = 0
        
        # Check if any search word appears in column name
        for word in search_words:
            if word in column_name_lower:
                column_relevance_score += 5
        
        # Semantic column name matching (medical/pharma related terms)
        medical_terms = ['therapy', 'drug', 'medication', 'treatment', 'disease', 'diagnosis', 
                        'class', 'category', 'type', 'vaccine', 'pharmaceutical']
        for med_term in medical_terms:
            if med_term in column_name_lower and any(word in matched_values for word in search_words):
                column_relevance_score += 10
                break
        
        # Cap at 15 points
        column_relevance_score = min(column_relevance_score, 15)
        
        # COMPOSITE SCORE
        composite_score = (
            word_match_score + 
            completeness_score + 
            token_boundary_score + 
            column_relevance_score
        )
        
        # Store all scoring details
        result['word_match_count'] = word_match_count
        result['completeness_ratio'] = round(completeness_ratio * 100, 1) if total_search_words > 0 else 0
        result['token_boundary_score'] = round(token_boundary_score, 1)
        result['column_relevance_score'] = round(column_relevance_score, 1)
        result['composite_score'] = round(composite_score, 1)
        
        print(f"   ðŸ“Š {column_name}:")
        print(f"      - Words matched: {word_match_count}/{total_search_words} = {word_match_score} pts")
        print(f"      - Completeness: {result['completeness_ratio']}% = {round(completeness_score, 1)} pts")
        print(f"      - Token quality: {result['token_boundary_score']} pts")
        print(f"      - Column relevance: {result['column_relevance_score']} pts")
        print(f"      - TOTAL SCORE: {result['composite_score']}")
    
    # Sort by composite score (descending)
    tier_3_results.sort(key=lambda x: x['composite_score'], reverse=True)
    
    print(f"\n   âœ… Dynamically ranked {len(tier_3_results)} Tier 3 results")
    return tier_3_results


def format_results(result_data: list, match_type: str) -> List[str]:
    """
    Format the query results into a list of strings
    """
    concatenated_results = []
    
    for row in result_data:
        column_name = row.get('column_name', '')
        matched_values = row.get('matched_values', '')
        tier = row.get('tier', '')
        sub_tier = row.get('sub_tier', '')
        
        # Additional info for Tier 3
        extra_info = ""
        if 'composite_score' in row:
            extra_info = (f", Score:{row['composite_score']}"
                         f"[Words:{row['word_match_count']}, "
                         f"Complete:{row['completeness_ratio']}%, "
                         f"Token:{row['token_boundary_score']}, "
                         f"ColRel:{row['column_relevance_score']}]")
        
        tier_label = sub_tier if sub_tier else tier
        table_summary = f"Column: {column_name} (Tier: {tier_label}, Type: {match_type}{extra_info})\n  - Values: {matched_values}"
        concatenated_results.append(table_summary)
    
    print(f"\nðŸ“‹ Formatted {len(concatenated_results)} results for {match_type} matches")
    return concatenated_results


# ===========================================
# TEST USAGE IN DATABRICKS
# ===========================================

# Test 1: Single word filter - Should show Tier 1A vs 1B
print("=" * 100)
print("TEST 1: Single word filter - 'External'")
print("Expected: line_of_business in Tier 1A (pure), client_name in Tier 1B (mixed)")
print("=" * 100)
results1 = search_metadata_sql(['External'])
print("\nðŸŽ¯ FINAL RESULTS:")
for result in results1:
    print(result)

print("\n\n")

# Test 2: Multi-word filter - Should show dynamic intelligent Tier 3 ranking
print("=" * 100)
print("TEST 2: Multi-word filter - 'covid vaccine'")
print("Expected: therapy_class_name and drug_name should rank higher (NO HARDCODING)")
print("=" * 100)
results2 = search_metadata_sql(['covid vaccine'])
print("\nðŸŽ¯ FINAL RESULTS:")
for result in results2:
    print(result)

print("\n\n")

# Test 3: Another multi-word test
print("=" * 100)
print("TEST 3: Multi-word filter - 'diabetes treatment'")
print("=" * 100)
results3 = search_metadata_sql(['diabetes treatment'])
print("\nðŸŽ¯ FINAL RESULTS:")
for result in results3:
    print(result)
