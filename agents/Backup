Hi [Gateway Team],

We're testing AWS Bedrock prompt caching for our OptumRx healthcare 
finance analytics chatbot. We've confirmed our code is correct, but 
caching metrics are showing zero.

EVIDENCE FROM OUR TESTING:

1. Gateway Response Structure (we can see cache fields):
   - cacheReadInputTokenCount: 0
   - cacheReadInputTokens: 0
   - cacheWriteInputTokenCount: 0
   - cacheWriteInputTokens: 0

2. Our Configuration:
   - System prompt size: 5,713 tokens (above 1,024 minimum)
   - Model: us.anthropic.claude-sonnet-4-20250514-v1:0
   - Parameter sent: cacheControl: {type: "ephemeral"}
   - No errors returned

3. Test Results:
   - Query 1: 7.5 sec, cache write = 0 (expected ~5,500)
   - Query 2: 9.0 sec, cache read = 0 (expected ~5,500)
   
QUESTIONS:

1. Is prompt caching enabled for our Bedrock endpoint?
2. Is the cacheControl parameter being passed through to Bedrock?
3. Are there subscription/permission requirements for caching?
4. Can you check gateway logs to see if cacheControl is present?
5. What configuration changes are needed to enable caching?

BUSINESS IMPACT:

Current latency: 7-10 seconds per query
Expected with caching: 2-3 seconds (70% faster)
Query volume: High (finance team uses system extensively)

We have clear evidence caching should work but metrics show zero.
Can you help us understand what's blocking it?

Attached: Debug logs showing cache field structure

Thanks,
[Your Name]
