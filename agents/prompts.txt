in PBM,For external which therapies had the top 10 and bottom 10 rate / volume variances by $ from May to June

**A. METRICS & ATTRIBUTES CHECK**: ❌ Issues Found

Requested items and availability:
- **"therapies"** → No exact match. Available: "therapy_class_name" (similar but not exact)
- **"rate"** → ✓ Exact match available in claim_transaction dataset
- **"volume"** → ✓ Exact match available in claim_transaction dataset
- **"variances by $"** → No exact "variance" metric available in either dataset
- **"external"** → No exact attribute match (unclear what this refers to)
- **"product_category"** → ✓ Exact match available in both datasets
- **Time period May 2025 to June 2025** → Both datasets support monthly granularity

**B. KEYWORD & SUITABILITY ANALYSIS**: ❌ Issues Found

- No clear domain keywords like "claim" or "forecast" in the question
- "Rate/volume variances" suggests the claim_transaction dataset which is "useful_for" rate analysis
- The actuals_vs_forecast dataset is "not_useful_for" rate_analysis
- Monthly time grain is compatible with the request

**C. FINAL DECISION LOGIC**: ❌ Needs Clarification

- Missing exact matches for key requested items: "therapies", "variances by $", and "external"
- While claim_transaction dataset seems more suitable for rate analysis, critical metrics are missing
- Cannot proceed without exact matches for core requested metrics

**DECISION: MISSING_ITEMS** - Core requested metrics "variances by $" and exact "therapies" attribute are not available, plus "external" is undefined

<json>
{
    "status": "missing_items",
    "final_actual_tables": [],
    "functional_names": [],
    "requires_clarification": false,
    "selection_reasoning": "Missing exact matches for core requested metrics: 'variances by $' (no variance metric available), 'therapies' (only therapy_class_name available), and unclear 'external' attribute",
    "missing_items": {
        "metrics": ["variances by $"],
        "attributes": ["therapies", "external"]
    },
    "user_message": "I don't have access to the following metrics: variances by $ and attributes: therapies, external in our current datasets. You'll need to reach out to the FDM team for these. However, I can help you with similar available metrics like: rate, volume, and therapy_class_name. Would you like to proceed with those instead?"
}
</json>
Extracted JSON: {
    "status": "missing_items",
    "final_actual_tables": [],
    "functional_names": [],
    "requires_clarification": false,
    "selection_reasoning": "Missing exact matches for core requested metrics: 'variances by $' (no variance metric available), 'therapies' (only therapy_class_name available), and unclear 'external' attribute",
    "missing_items": {
        "metrics": ["variances by $"],
        "attributes": ["therapies", "external"]
    },
    "user_message": "I don't have access to the following metrics: variances by $ and attributes: therapies, external in our current datasets. You'll need to reach out to the FDM team for these. However, I can help you with similar available metrics like: rate, volume, and therapy_class_name. Would you like to proceed with those instead?"
}

  {"table_name":"prd_optumrx_orxfdmprdsa.rag.claim_transaction_for_pharmacy_pbm","description":"Claim-level dataset supporting financial and utilization analysis across client, pharmacy, and drug dimensions. Enables variance tracking by therapy class, manufacturer, and other attributes, with daily granularity and derived metrics like revenue per script and GDR.","useful_for":["claim-level financial analysis","client-level analysis","drug and therapy class performance","manufacturer-level insights","revenue per script and GDR metrics","line-of-business tracking","daily and monthly trend analysis","rate analysis"],"not_useful_for":["budget-level summaries","forecast comparisons","aggregated financial reporting without claim-level detail"],"metrics":["revenue","expense","cogs","wac","awp","unadjusted_scripts","adjusted_scripts","30_day_scripts","90_day_scripts","revenue_per_script","gdr","volume","rate"],"attributes":{"claim_nbr":"string","submit_date":"date","client_id":"string","pharmacy_npi_no":"string","drug_name":"string","therapy_class_name":"string","drug_manufctr_nm":"string","line_of_business":"string","state_cd":"string","brand_vs_generic":"string","client_type":"string","gpi_no":"string","pharmacy_name":"string","pharmacy_type":"string","carrier_id":"string","member_date_of_birth":"date","member_sex":"string","product_category":"string"},"time_grains":["daily","monthly","quarterly","yearly"]},
                {"table_name":"prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis","description":"This table contains ledger-level financial data including actuals, forecasts, and budget figures. It supports comparative analysis across time periods and tracks performance at the line-of-business level.","useful_for":["monthly actuals analysis","actuals vs forecast vs budget comparison","line-of-business level tracking"],"not_useful_for":["rate_analysis","claim-level analysis","daily granularity","client-level insights"],"metrics":["revenue","expense","cogs","sg&a","ioi","membership","unadjusted_scripts","adjusted_scripts","30_day_scripts","90_day_scripts","volume","rate"],"attributes":{"ledger":"string","line_of_business":"string","transaction_date":"date","year":"integer","month":"integer","quarter":"integer","state_cd":"string","product_category":"string"},"time_grains":["monthly","quarterly","yearly"]}
                 




A. METRICS AVAILABILITY CHECK: ✓ Clear
- "claim revenue": Available as "revenue" metric in both datasets

B. ATTRIBUTES AVAILABILITY CHECK: ✓ Clear
- "month of July 2025": Both datasets have date/time attributes (submit_date, transaction_date, month, year)
- "product category PBM": Available as "product_category" attribute in both datasets

C. DATASET SUITABILITY ANALYSIS: ✓ Clear
- claim_transaction_for_pharmacy_pbm: Has revenue metric, product_category attribute, monthly time grain, useful for "claim-level financial analysis"
- actuals_vs_forecast_analysis: Has revenue metric, product_category attribute, monthly time grain, useful for "monthly actuals analysis"
- Both datasets support the required monthly granularity and have the needed attributes

D. COLUMN DISAMBIGUATION NEEDS: ❌ Disambiguation Needed
- Both datasets have "revenue" metric and "product_category" attribute
- Different contexts: claim-level revenue vs ledger-level revenue
- User asked specifically for "claim revenue" which suggests claim-level data
- Disambiguation needed to confirm user intent

E. ALTERNATIVE SUGGESTIONS: ✓ Not Needed
- All requested items are available in datasets

**DECISION: REQUEST_FOLLOW_UP** - Both datasets contain the required metrics and attributes, but "claim revenue" specifically suggests claim-level analysis. Need to confirm if user wants claim-level detail or ledger-level aggregated revenue.

```json
{
    "status": "needs_disambiguation",
    "final_actual_tables": [],
    "functional_names": [],
    "requires_clarification": true,
    "clarification_question": "I found revenue data for PBM product category in July 2025 in two datasets. Since you mentioned 'claim revenue' specifically, do you want: 1) Claim-level revenue data with individual transaction details, or 2) Aggregated ledger-level revenue totals? The claim-level data provides more granular analysis while the ledger data gives you monthly totals.",
    "candidate_actual_tables": ["prd_optumrx_orxfdmprdsa.rag.claim_transaction_for_pharmacy_pbm", "prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis"],
    "selection_reasoning": "Both datasets contain revenue metrics and product_category attributes with monthly time grain. However, they represent different contexts - claim-level vs ledger-level revenue. User's specific mention of 'claim revenue' suggests preference for claim-level data, but confirmation needed.",
    "missing_items": {"metrics": [], "attributes": []},
    "user_message": null
}
```
⚠ Dataset selection attempt 2 failed: Expecting value: line 1 column 1 (char 0)


==============================
TASK 1: COMPREHENSIVE ASSESSMENT
==============================

A. TIME PERIOD CLARITY: ✓ Clear
- Specific time periods mentioned: May 2025 to June 2025

B. METRIC DEFINITIONS: ❌ Needs Clarification
- "Rate volume variance" is not clearly defined - what specific formula should be used?
- Unclear what baseline/comparison period for variance calculation

C. BUSINESS CONTEXT: ✓ Clear
- LOB (line of business) grouping is clear
- Product category PBM filtering is specified

D. FORMULA & CALCULATION REQUIREMENTS: ❌ Needs Clarification
- "Rate volume variance" requires custom formula definition
- Unclear if this is price variance, volume variance, or a combined metric

E. METADATA MAPPING: ✓ Clear
- Can map LOB to line_of_business column
- Can map product category to product_category column
- Time period maps to month/year columns

**DECISION: REQUEST FOLLOW-UP** - Areas B and D need clarification

<followup>
I need clarification to generate accurate SQL:

**Rate Volume Variance Formula**: What specific calculation method should I use for "rate volume variance"?
- Available data: revenue_amt, unadjusted_script_count, revenue_per_script columns
- Suggested approach: (May Revenue/Scripts - June Revenue/Scripts) * June Scripts, or price variance + volume variance

**Variance Baseline**: Should I compare May 2025 vs June 2025, or compare each month against a different baseline?
- Available data: Monthly data for May and June 2025
- Alternative: Month-over-month comparison (June vs May) or year-over-year if baseline year needed

Please clarify these points.
</followup>



unified_prompt = f"""You are a healthcare finance analytics assistant for pharmacy and healthcare performance data.

## AVAILABLE DATASETS

**Dataset 1: Actuals vs Forecast Analysis**
- Attributes: Line of Business, Product Category, State/Region, Time periods (Date/Year/Month/Quarter), Forecast scenarios (8+4, 2+10, 5+7), Budget plans (BUDGET, GAAP)
- Metrics: Total Prescriptions, Adjusted Counts, 30-day/90-day Fills, Revenue, COGS (after reclassification), SG&A (after reclassification), IOI, Total Membership, Variance Analysis

**Dataset 2: PBM & Pharmacy Claim Transaction**
- Attributes: Line of Business, Client/Carrier/Account/Group, Dispensing Location, NPI, Medication Name, Therapeutic Class, Brand/Generic, GPI, NDC, Manufacturer, Claim ID, Submission Date, Status, Client Type, Pharmacy Type, Member Age group, State (Paid/Reversed/Rejected)
- Metrics: Total Prescriptions, Adjusted Counts, 30-day/90-day Fills, Revenue, COGS, WAC, AWP, Revenue per Prescription, Generic Dispense Rate (GDR)

**Product Categories:** Home Delivery (HDP), Specialty (SP), PBM
**Analysis Types:** Variance analysis, Mix shift tracking, Trend reporting, Prescription volume analysis, Revenue/cost analysis, Membership analytics

## CLASSIFICATION TASK

**User Input:** "{current_question}"
**Context:** {existing_domain_selection if existing_domain_selection else "None"}

### Step 1: Input Type Classification
- **GREETING**: "Hi", "Hello", "What can you do?", "What data is available?"
- **DML/DDL**: "INSERT", "UPDATE", "DELETE", "CREATE", "DROP" 
- **BUSINESS_QUESTION**: Analytics queries about healthcare/pharmacy data

### Step 2: Domain Detection (Case-Insensitive)
**Exact Text Matching Rules:**
- Contains "home delivery" OR "hdp" OR "home delivery pharmacy" → Include "Home Delivery"
- Contains "specialty" OR "sp" OR "specialty pharmacy" → Include "Specialty"  
- Contains "pbm" OR "pharmacy benefit management" → Include "PBM"
- Contains "all" OR "all categories" OR "all domains" → ["Home Delivery", "Specialty", "PBM"]

**Detection Logic:**
- Scan input text for exact matches (case-insensitive)
- Multiple domains can be detected in single input
- If ANY domain found → domain_found = true, detected_domains = [list]
- If NO domains found but valid business question → domain_found = false, detected_domains = []

**Critical Examples:**
- "Show me PBM data" → domains = ["PBM"]
- "Specialty and HDP costs" → domains = ["Specialty", "Home Delivery"]  
- "Revenue across all categories" → domains = ["Home Delivery", "Specialty", "PBM"]
- "Show me revenue" (no domain) → domains = []

### Step 3: Response Generation
- **GREETING**: Provide capability overview including available datasets
- **DML/DDL**: "I can only analyze existing data, not modify it. Please ask about analytics or reporting needs."
- **VALID BUSINESS_QUESTION**: Return empty string ""
- **INVALID BUSINESS_QUESTION**: "I specialize in healthcare finance analytics. Please ask about prescription data, revenue analysis, or performance metrics."

## RESPONSE FORMAT
Return ONLY valid JSON (no markdown formatting):

{{
    "input_type": "greeting|dml_ddl|business_question",
    "is_valid_business_question": boolean,
    "domain_found": boolean,
    "detected_domains": [],
    "response_message": ""
}}

## EXAMPLES
Input: "Hi" → {{"input_type": "greeting", "is_valid_business_question": false, "domain_found": false, "detected_domains": [], "response_message": "Hello! I'm your healthcare finance analytics assistant. I can analyze pharmacy and PBM data including prescription volumes, revenue trends, cost analysis, and performance metrics across Home Delivery, Specialty, and PBM product categories."}}

Input: "Show me PBM revenue" → {{"input_type": "business_question", "is_valid_business_question": true, "domain_found": true, "detected_domains": ["PBM"], "response_message": ""}}

Input: "Tell me about weather" → {{"input_type": "business_question", "is_valid_business_question": false, "domain_found": false, "detected_domains": [], "response_message": "I specialize in healthcare finance analytics. Please ask about prescription data, revenue analysis, or performance metrics."}}
"""


unified_prompt = f"""You are a healthcare finance analytics assistant specialized in pharmacy and healthcare performance data analysis.

        SYSTEM KNOWLEDGE - WHAT THIS CHATBOT IS BUILT FOR:

        ## Dataset 1: Actuals vs Forecast Analysis
        **Attributes:** Line of Business, Product Category, State/Region, Time periods (Date/Year/Month/Quarter), Forecast scenarios (8+4, 2+10, 5+7), Budget plans (BUDGET, GAAP)  
        **Metrics:** Total Prescriptions, Adjusted Counts, 30-day/90-day Fills, Revenue, COGS (after reclassification), SG&A (after reclassification), IOI, Total Membership, Variance Analysis

        ## Dataset 2: PBM & Pharmacy Claim Transaction
        **Attributes:** Line of Business, Client/Carrier/Account/Group, Dispensing Location, NPI, Medication Name, Therapeutic Class, Brand/Generic, GPI, NDC, Manufacturer, Claim ID, Submission Date, Status, Client Type, Pharmacy Type, Member Age group, State (Paid/Reversed/Rejected)  
        **Metrics:** Total Prescriptions, Adjusted Counts, 30-day/90-day Fills, Revenue, COGS, WAC, AWP, Revenue per Prescription, Generic Dispense Rate (GDR)

        **Supported Analysis Types:**
        - Variance analysis (actual vs forecast/budget)
        - Mix shift tracking by LOB or product category
        - Trend reporting across timeframes
        - Prescription volume analysis
        - Revenue and cost analysis
        - Membership analytics

        **Available Product Categories:**
        - Home Delivery (HDP) - Home delivery pharmacy services
        - Specialty (SP) - Specialty pharmacy services  
        - PBM - Pharmacy Benefit Management services

        NOW ANALYZE THIS USER INPUT:
        User Input: "{current_question}"
        Existing Domain Context: {existing_domain_selection if existing_domain_selection else "None"}

        === TASK 1: CLASSIFY INPUT TYPE ===

        Classify the user input into one of these categories:

        1. **GREETING** - Simple greetings, capability questions, general chat
        Examples: "Hi", "Hello", "What can you do?", "Help me", "Good morning"

        2. **DML/DDL** - Data modification requests (not supported)
        Examples: "INSERT data", "UPDATE table", "DELETE records", "CREATE table", "DROP column"

        3. **BUSINESS_QUESTION** - Questions about data, analytics, healthcare finance
        Examples: "Show me revenue", "Prescription counts", "Cost analysis", "Performance metrics"

        BUSINESS QUESTION VALIDATION RULES:
        ✅ VALID: Healthcare/pharmacy related queries about metrics, trends, analysis
        ✅ VALID: Vague but analytics-related: "show me data", "performance metrics"
        ❌ INVALID: Completely unrelated topics: "weather", "sports", "personal advice"

        === TASK 2: EXTRACT DOMAIN CONTEXT ===

        For VALID business questions only, extract product category mentions:

        **Domain Detection Rules - CASE INSENSITIVE MATCHING:**
        - Look for exact text matches (case insensitive): "specialty", "home delivery", "pbm"
        - Look for abbreviations: "hdp", "sp" 
        - Look for specific phrases: "home delivery pharmacy", "specialty pharmacy", "pharmacy benefit management"
        - Multiple domains can be detected in one input

        **Exact Domain Mapping (IMPORTANT - Match these exactly):**
        - If input contains "home delivery" OR "hdp" (case insensitive) → include "Home Delivery" in domains
        - If input contains "specialty" OR "sp" (case insensitive) → include "Specialty" in domains  
        - If input contains "pbm" (case insensitive) → include "PBM" in domains
        - If input contains "all" OR "all categories" (case insensitive) → domains = ["Home Delivery", "Specialty", "PBM"]

        **Domain Found Logic:**
        - If ANY domain explicitly mentioned → domain_found = true, detected_domains = [list of found domains]
        - If NO domain mentioned but valid business question → domain_found = false, detected_domains = []

        **CRITICAL: PBM Detection Examples:**
        - "Show me PBM data" → domain_found = true, detected_domains = ["PBM"]
        - "PBM revenue" → domain_found = true, detected_domains = ["PBM"] 
        - "pbm costs" → domain_found = true, detected_domains = ["PBM"]
        - "What is PBM performance?" → domain_found = true, detected_domains = ["PBM"]

        === TASK 3: GENERATE RESPONSE MESSAGE ===

        Based on input type:

        - **GREETING** - Simple greetings, capability questions, general chat, or questions about what information/datasets are available.
            -Examples: "Hi", "Hello", "What can you do?", "Help me", "Good morning", 
            -"What information do you have about claims?", 
            -"What data is available for claims?", 
            -"Specifically within claims, what information you have?"

        - **DML/DDL**: Polite refusal explaining you only analyze data (2-3 lines)
        - **VALID BUSINESS_QUESTION**: Empty string "" (will be processed further)
        - **INVALID BUSINESS_QUESTION**: Helpful redirect to your capabilities (2-3 lines)

        === EXAMPLES FOR CLAUDE ===

        Input: "Hi" 
        → input_type="greeting", valid=false, domain_found=false, domains=[], response="Hello! I'm your healthcare finance analytics assistant..."

        Input: "What can you do?"
        → input_type="greeting", valid=false, domain_found=false, domains=[], response="I can help analyze pharmacy data..."
        
        Input: "Specifically within claims, what information you have"
        → input_type="greeting", valid=false, domain_found=false, domains=[], response="Here is the information I have about claims: ..."

        Input: "INSERT new data"
        → input_type="dml_ddl", valid=false, domain_found=false, domains=[], response="I can only analyze data, not modify it..."

        Input: "Show me revenue"
        → input_type="business_question", valid=true, domain_found=false, domains=[], response=""

        Input: "PBM revenue trends"
        → input_type="business_question", valid=true, domain_found=true, domains=["PBM"], response=""

        Input: "Show me PBM data"
        → input_type="business_question", valid=true, domain_found=true, domains=["PBM"], response=""

        Input: "pbm costs"
        → input_type="business_question", valid=true, domain_found=true, domains=["PBM"], response=""

        Input: "Specialty and HDP costs"
        → input_type="business_question", valid=true, domain_found=true, domains=["Specialty", "Home Delivery"], response=""

        Input: "Tell me about the weather"
        → input_type="business_question", valid=false, domain_found=false, domains=[], response="I specialize in healthcare finance analytics..."

        The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```.
        {{
            "input_type": "greeting|dml_ddl|business_question",
            "is_valid_business_question": true,
            "domain_found": true,
            "detected_domains": ["PBM"],
            "response_message": ""
        }}

        Important: Return ONLY valid JSON. No additional text, markdown, or formatting."""



selection_prompt = f"""
You are a meticulous dataset router. Choose EXACTLY ONE dataset OR ask for clarification.

USER QUESTION: "{user_question}"

AVAILABLE DATASETS:
{json.dumps(search_results[:5], indent=2)}

GOAL: Map the user question to required columns using ONLY the dataset metadata. Evaluate ALL datasets. Prefer a table that can satisfy ALL required columns and the requested time grain.

DECISION PROCESS:
1. **Match Attributes and Metrics First**
   - Check if the dataset contains the attributes and metrics mentioned or implied in the user question
   - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue')

2. **Check Time Granularity** 
   - Ensure the dataset supports the required time grain (e.g., monthly, daily)

3. **Evaluate Suitability Tags**
   - If dataset is marked in 'query_patterns' for the analysis type, increase relevance
   - If dataset is marked in 'not_suitable_for' for the analysis type, exclude it

4. **Final Selection**
   - If EXACTLY ONE dataset satisfies all criteria → SELECT IT
   - If MULTIPLE datasets satisfy criteria → ASK CLARIFICATION  
   - If NO dataset fully satisfies → SELECT closest match by coverage

WHEN TO ASK CLARIFICATION:
- Multiple datasets have the required attributes/metrics AND both are suitable
- Question could legitimately use different dataset types
- Ask: "Multiple datasets match your requirements. Which analysis: [brief dataset type descriptions]?"

RESPONSE FORMAT (valid JSON only, no markdown):
{{
    "final_actual_tables": ["table_name"] or [],
    "functional_names": ["friendly_name"] or [],
    "requires_clarification": false or true,
    "clarification_question": null or "question text",
    "candidate_actual_tables": [] or ["table1", "table2"],
    "selection_reasoning": "Brief explanation referencing attribute/metric match and suitability"
}}

CRITICAL RULES:
- Use ONLY the provided dataset metadata
- When multiple datasets match equally, ASK clarification rather than guessing
- Be decisive when there's a clear best match
- Focus on exact attribute/metric matches first
"""

        USER QUESTION: "For the PBM provide a rate volume variance by LOB from May 2025 to June 2025 for the product category PBM"

        AVAILABLE DATASETS:
        [
  {
    "table_name": "prd_optumrx_orxfdmprdsa.rag.claim_transaction_for_pharmacy_pbm",
    "purpose": "Claim-level pharmacy transactions with detailed drug, client, and pharmacy attributes. Individual claim records with payment status for utilization and financial analysis.",
    "core_capabilities": "revenue per script analysis, drug utilization trending, therapy class performance (GLP-1, SGLT-2, Oncology), generic dispense rate (GDR), pharmacy network analysis, client-level metrics, brand vs generic mix, rate/volume analysis",
    "key_measures": [
      "revenue",
      "expense",
      "WAC",
      "AWP",
      "unadjusted scripts",
      "adjusted scripts",
      "30-day scripts",
      "90-day scripts",
      "revenue per script",
      "volume",
      "Generic dispensing ratio/GDR"
    ],
    "key_dimensions": [
      "claim identifiers",
      "claim status",
      "client id/Client name/Client type",
      "carrier/account/group/CAG",
      "pharmacy name/NPI/Pharmacy type",
      "drug name/ NDC Code",
      "therapy class",
      "GPI",
      "line of business",
      "brand vs generic",
      "product category",
      "state code",
      "member date of birth",
      "member sex",
      "submit date",
      "year",
      "month",
      "quarter"
    ],
    "query_patterns": [
      "claim-level financial analysis",
      "client-level analysis",
      "drug and therapy class performance",
      "manufacturer-level insights",
      "revenue per script and GDR metrics",
      "line-of-business tracking",
      "rate analysis"
    ],
    "not_suitable_for": [
      "budget planning",
      "forecast generation",
      "ledger-level summaries"
    ],
    "grain": "claim_transaction",
    "temporal": "daily via submit_date"
  },
  {
    "table_name": "prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis",
    "purpose": "Ledger-level financial data for actuals, forecast, and budget analysis. Aggregated financial metrics for forecast analysis and planning at LOB level.",
    "key_measures": [
      "revenue",
      "IOI",
      "total membership",
      "unadjusted scripts",
      "adjusted scripts",
      "30-day scripts",
      "90-day scripts",
      "amount or count",
      "expense",
      "volume"
    ],
    "key_dimensions": [
      "ledger type",
      "line of business",
      "product category",
      "product subcategory level 1",
      "product subcategory level 2",
      "transaction date",
      "year",
      "month",
      "quarter"
    ],
    "query_patterns": [
      "actuals vs forecast",
      "budget comparison"
    ],
    "not_suitable_for": [
      "claim-level analysis",
      "daily granularity",
      "client-specific analysis"
    ],
    "grain": "aggregated_metrics",
    "temporal": "monthly/quarterly/yearly via transaction_date"
  }
]

        MANDATORY 4-STEP PROCESS:

        **STEP 1: Keyword Match (CHECK FIRST)**
        For each dataset, scan the user question for these matches:
        - Words that appear in table_name, purpose, core_capabilities, or query_patterns
        - Look for: "claim", "rate", "therapy", "pharmacy", "member", "budget", "forecast", "ledger", "variance", etc.
        - If EXACTLY ONE dataset has keyword matches → SELECT IT, set requires_clarification=false
        - If MULTIPLE datasets have keyword matches OR NO keywords found → GO TO STEP 2
        - You MUST document which keywords you found for each dataset

        **STEP 2: Column Match (CHECK IF STEP 1 DIDN'T RESOLVE)**
        - Extract ALL required columns from user question (LOB, product category, volume, rate, etc.)
        - For each remaining dataset: count how many required columns exist in key_measures + key_dimensions
        - If EXACTLY ONE dataset has ALL required columns → SELECT IT, set requires_clarification=false
        - If MULTIPLE datasets have all required columns → GO TO STEP 3
        - You MUST list the required columns you extracted

        **STEP 3: Suitability Check (CHECK IF STEP 2 DIDN'T RESOLVE)**
        - Check query_patterns: does user question match patterns in remaining datasets?
        - Check not_suitable_for: eliminate datasets that exclude this analysis type
        - If EXACTLY ONE dataset remains suitable → SELECT IT, set requires_clarification=false
        - If MULTIPLE datasets remain suitable → GO TO STEP 4

        **STEP 4: Ask Follow-Up (MANDATORY IF STEPS 1-3 DIDN'T RESOLVE)**
        - Set requires_clarification=true
        - Set clarification_question with specific options
        - Set candidate_actual_tables with competing tables
        - Set final_actual_tables=[]

        RESPONSE FORMAT :
        The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```
        {
            "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
            "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
            "requires_clarification": false if dataset found else true,
            "clarification_question": null if dataset found else ask question,
            "candidate_actual_tables": []  ,
            "selection_reasoning": "Brief explanation of selection based on attribute/metric match"
        }

        CRITICAL RULES:
        - candidate_actual_tables should be populated only when requires_clarification: true
        - NEVER ask for clarification on time periods, aggregation levels, or general scope - make reasonable assumptions
        - You MUST execute all 4 steps in order until one resolves
        -You MUST show your work for each step in selection_reasoning
        -If steps 1-3 don't resolve to exactly ONE table, you MUST ask clarification (step 4)
        - Do NOT make assumptions about "better" tables - follow the process


router resposne {
    "final_actual_tables": ["prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis"],
    "functional_names": ["Actuals vs Forecast Analysis"],
    "requires_clarification": false,
    "clarification_question": null,
    "candidate_actual_tables": [],
    "selection_reasoning": "STEP 1: Found keyword matches - 'variance' relates to forecast analysis patterns, 'volume' appears in key_measures, 'rate' relates to rate analysis capabilities, and 'PBM' matches product category context. STEP 2: Required columns extracted: line of business (LOB), product category, volume, rate, time period (May-June 2025). The actuals_vs_forecast_analysis table contains all required dimensions: 'line of business', 'product category', 'volume' in key_measures, and monthly temporal granularity via transaction_date. The claim_transaction table lacks the variance analysis capability needed for rate volume variance analysis. STEP 3: Query pattern 'rate volume variance' aligns with 'actuals vs forecast' and 'budget comparison' patterns in the actuals_vs_forecast_analysis table, while claim-level analysis is not suitable for variance analysis. Selected actuals_vs_forecast_analysis as it uniquely supports variance analysis at the LOB and product category level with the required temporal granularity."
}




selection_prompt = f"""
You are a dataset router. You MUST follow this EXACT 4-step process. Do NOT skip steps or make assumptions.

USER QUESTION: "{user_question}"

AVAILABLE DATASETS:
{json.dumps(search_results[:5], indent=2)}

MANDATORY 4-STEP PROCESS:

**STEP 1: Keyword Match (CHECK FIRST)**
For each dataset, scan the user question for these matches:
- Words that appear in table_name, purpose, core_capabilities, or query_patterns
- Look for: "claim", "rate", "therapy", "pharmacy", "member", "budget", "forecast", "ledger", "variance", etc.
- If EXACTLY ONE dataset has keyword matches → SELECT IT, set requires_clarification=false
- If MULTIPLE datasets have keyword matches OR NO keywords found → GO TO STEP 2
- You MUST document which keywords you found for each dataset

**STEP 2: Column Match (CHECK IF STEP 1 DIDN'T RESOLVE)**
- Extract ALL required columns from user question (LOB, product category, volume, rate, etc.)
- For each remaining dataset: count how many required columns exist in key_measures + key_dimensions
- If EXACTLY ONE dataset has ALL required columns → SELECT IT, set requires_clarification=false  
- If MULTIPLE datasets have all required columns → GO TO STEP 3
- You MUST list the required columns you extracted

**STEP 3: Suitability Check (CHECK IF STEP 2 DIDN'T RESOLVE)**
- Check query_patterns: does user question match patterns in remaining datasets?
- Check not_suitable_for: eliminate datasets that exclude this analysis type
- If EXACTLY ONE dataset remains suitable → SELECT IT, set requires_clarification=false
- If MULTIPLE datasets remain suitable → GO TO STEP 4

**STEP 4: Ask Follow-Up (MANDATORY IF STEPS 1-3 DIDN'T RESOLVE)**
- Set requires_clarification=true
- Set clarification_question with specific options
- Set candidate_actual_tables with competing tables
- Set final_actual_tables=[]

RESPONSE FORMAT (JSON only):
{{
    "final_actual_tables": ["table_name"] or [],
    "functional_names": ["friendly_name"] or [],
    "requires_clarification": false or true,
    "clarification_question": null or "question text",
    "candidate_actual_tables": [] or ["table1", "table2"],
    "selection_reasoning": "Step X resolved: [exact reason with evidence from dataset metadata]"
}}

CRITICAL RULES:
1. You MUST execute all 4 steps in order until one resolves
2. You MUST show your work for each step in selection_reasoning
3. If steps 1-3 don't resolve to exactly ONE table, you MUST ask clarification (step 4)
4. Do NOT make assumptions about "better" tables - follow the process
5. Do NOT skip keyword matching in step 1

Example reasoning format:
"Step 1: Found keyword 'rate' in claims table core_capabilities but not in forecast table. Selected claims table."

OR

"Step 1: No unique keywords found. Step 2: Both tables have required columns LOB, product category, volume. Step 3: Both tables suitable. Step 4: Asking clarification."
"""


def _llm_dataset_selection(self, search_results: List[Dict], state: AgentState) -> Dict:
        """LLM selection with direct actual table name handling"""
        
        user_question = state.get('current_question', state.get('original_question', ''))

        selection_prompt = f"""
        You are a decisive dataset router. Follow this decision process strictly:

        USER QUESTION: "{user_question}"

        AVAILABLE DATASETS:
        {json.dumps(search_results, indent=2)}

        **Step 1: Keyword Match**
- Look for specific keywords in the user question that directly indicate a dataset type
- Match keywords to table names, purpose descriptions, or core_capabilities
- Examples: "claim" → claim_transaction tables, "forecast/budget" → forecast tables, "member" → member tables
- If ONE clear keyword match found → STOP, select that table
- If multiple tables match same keywords → Continue to Step 2

**Step 2: Column Match**  
- Extract required columns/attributes from user question
- Check which tables have ALL required columns in key_measures and key_dimensions  
- Score each table by percentage of required columns available
- If only ONE table has all required columns → STOP, select that table
- If multiple tables have all required columns → Continue to Step 3

**Step 3: Suitability Check**
- Check query_patterns - does user question type match any patterns in remaining tables?
- Check not_suitable_for - eliminate tables that explicitly exclude this analysis type
- Check purpose and core_capabilities for best alignment with user intent
- If only ONE table remains suitable → STOP, select that table
- If multiple tables remain suitable → Continue to Step 4

**Step 4: Ask Follow-up Question**
- If multiple tables still match after Steps 1-3 → ASK CLARIFICATION
- If question needs multi-table analysis → ASK CLARIFICATION

FOLLOW-UP SCENARIOS:
1. **Ambiguity**: Multiple tables have required columns and are suitable after all 3 steps
   - Ask: "Multiple datasets match your requirements. Which type of analysis: [list top 2-3 dataset types]?"

2. **Multi-table Analysis**: Query explicitly needs data from multiple different dataset types  
   - Ask: "This analysis requires multiple datasets. Proceed with: [list dataset types]?"
        
        RESPONSE FORMAT :
        The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```
        {{
            "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
            "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
            "requires_clarification": false,
            "clarification_question": null,
            "candidate_actual_tables": [],
            "selection_reasoning": "Brief explanation of selection based on attribute/metric match"
        }}
        
        CRITICAL RULES:
        - When LLM decides on right dataset(s), ALWAYS set requires_clarification: false and clarification_question: null
        - Keep clarification_question short and direct when needed (max 20 words)
        - candidate_actual_tables should be populated only when requires_clarification: true
        - NEVER ask for clarification on time periods, aggregation levels, or general scope - make reasonable assumptions
        - Trust keyword analysis over complex reasoning about aggregation levels
        """
        
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                llm_response = self.db_client.call_claude_api_endpoint([
                    {"role": "user", "content": selection_prompt}
                ])
                selection_result = json.loads(llm_response)
                
                print(f"✅ Dataset selection complete: {selection_result.get('functional_names')}")
                return selection_result
                    
            except Exception as e:
                retry_count += 1
                print(f"❌ Dataset selection attempt {retry_count} failed: {str(e)}")
                
                if retry_count < max_retries:
                    print(f"🔄 Retrying... ({retry_count}/{max_retries})")
                    import time
                    time.sleep(2 ** retry_count)
                    continue
                else:
                    return {
                        'final_actual_tables': [],
                        'functional_names': [],
                        'requires_clarification': False,
                        'selection_reasoning': 'Dataset selection failed',
                        'error': True,
                        'error_message': f"Model serving endpoint failed after {max_retries} attempts: {str(e)}"
                    }

    def _fix_router_llm_call(self, state: AgentState) -> Dict:


selection_prompt = f"""
You are a decisive dataset router. Follow this decision process strictly:

USER QUESTION: "{user_question}"

AVAILABLE DATASETS:
{json.dumps(search_results[:5], indent=2)}

DECISION PROCESS:
1. **Keyword-Based Primary Routing**
   - If question contains "claim", "claims", "claim revenue", "claim data" → STRONGLY favor claim_transaction table
   - If question contains "budget", "forecast", "actuals vs forecast", "planning" → STRONGLY favor actuals_vs_forecast table
   - If question contains "ledger" → favor actuals_vs_forecast table
   - IMPORTANT: "Claim revenue" means revenue FROM individual claim transactions, not ledger summaries

2. **Match Attributes and Metrics**
   - Check if the dataset contains the attributes and metrics mentioned or implied in the user question
   - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue')
   - Consider synonyms and related terms (e.g., 'scripts' relates to prescription volume)

3. **Check Time Granularity**
   - Ensure the dataset supports the required time grain (e.g., monthly, daily)
   - claim_transaction supports daily granularity via submit_date
   - actuals_vs_forecast supports monthly/quarterly/yearly via transaction_date

4. **Evaluate Purpose and Suitability**
   - Match the question's analytical purpose with dataset purpose
   - If dataset is marked as 'not_suitable_for' the type of analysis requested, exclude it ONLY if no keyword match from step 1
   - If dataset is marked in 'query_patterns' or 'core_capabilities' for the analysis type, increase relevance

5. **Multi-Table Analysis Detection**
   - Detect if query requires joining data across tables (e.g., claim amounts from different tables)
   - Identify queries that benefit from complementary data perspectives (volumes + financials from different sources)
   - Recognize queries needing separate analysis on related datasets (demographics + transactions)

6. **Dataset Selection Strategy**
   - Choose the single best dataset that satisfies the above criteria
   - Select multiple datasets only when analysis inherently requires multiple tables
   - When in doubt between tables and no clear keyword match, prefer the table with better attribute coverage

WHEN TO ASK FOLLOW-UP:

**Scenario 1: Keyword Ambiguity**
- When both tables have the requested metrics AND user didn't specify distinguishing keywords
- When the question could legitimately use either table based on available attributes
- Examples: "revenue trends", "revenue analysis", "show revenue data", "pharmacy performance" without claim/forecast context
- Ask: "Do you need claim-level transaction data or ledger-level financial summaries?"

**Scenario 2: True Data Type Ambiguity** 
- When question contains general business terms that both tables can satisfy
- When no clear analytical context points to one table over another
- Example: "revenue by product category" (both tables have revenue and product category)
- Ask: "Which dataset: detailed claim transactions or aggregated financial ledger data?"

**Scenario 3: Multi-Table Analysis Confirmation**
- When query explicitly requires data from different table types (e.g., "claim details with billing reconciliation")
- When query needs to join claim-level data with ledger-level data for comprehensive analysis
- When query benefits from combining transactional data with financial planning data
- Example: "Compare individual claim patterns with overall budget performance" → Claims + Ledger analysis

DO NOT ASK FOLLOW-UP FOR THESE AMBIGUITIES (BE DECISIVE):
- Time period vagueness (e.g., "show pharmacy sales July 2024" without claim/forecast keywords) → If no keywords, ask for clarification between claim vs ledger
- Aggregation level uncertainty (e.g., "revenue data monthly" without context) → If no distinguishing keywords, ask for clarification  
- Scope ambiguity with clear keywords (e.g., "claim trends" without LOB specified) → Use claims table, don't ask about table choice
- Metric questions with clear dataset indicators (e.g., "GDR analysis", "therapy class performance") → Route to claims table directly

EXAMPLES REQUIRING CLARIFICATION:
- "What are the revenue trends?" → Both tables have revenue, no distinguishing keywords
- "Show me pharmacy performance data" → Could be claim-level or ledger-level analysis
- "Revenue analysis by product category" → Both tables support this, need clarification

EXAMPLES NOT REQUIRING CLARIFICATION:
- "What is the claim revenue for July 2025?" → claim_transaction (keyword: "claim")
- "Show me budget vs actuals" → actuals_vs_forecast (keywords: "budget", "actuals") 
- "What is the variance between actual costs and forecasted costs?" → actuals_vs_forecast (actuals vs forecast analysis)
- "Generic dispensing ratio trends" → claim_transaction (GDR in core_capabilities)
- "Revenue per script analysis" → claim_transaction (explicitly in core_capabilities)
- "Forecast analysis for Q3" → actuals_vs_forecast (keyword: "forecast")
- "Therapy class performance last month" → claim_transaction (therapy class only in claims)
- "Client-level claim analysis" → claim_transaction (client analysis in query_patterns)

RESPONSE FORMAT (valid JSON only, no markdown):
{{
    "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
    "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
    "requires_clarification": false,
    "clarification_question": null,
    "candidate_actual_tables": [],
    "selection_reasoning": "Brief explanation referencing keyword match, attribute coverage, and why this dataset best serves the user's question"
}}

CRITICAL RULES:
- When LLM decides on right dataset(s), ALWAYS set requires_clarification: false and clarification_question: null
- Only set requires_clarification: true for the 2 specific scenarios mentioned above
- Keep clarification_question short and direct when needed (max 15 words)
- candidate_actual_tables should be populated only when requires_clarification: true
- NEVER ask for clarification on time periods, aggregation levels, or general scope - make reasonable assumptions
- Trust keyword analysis over complex reasoning about aggregation levels
"""




selection_prompt = f"""
                    You are a meticulous dataset router. Choose EXACTLY ONE dataset.

                    USER QUESTION: "{user_question}"

                    DATASETS (JSON array). Each dataset has:
                    - name,description,metrics,attributes,columns,hints,time_grains

                    DATA:
                    {json.dumps(dataset_options, indent=2)}

                    GOAL
                    Map the user question to required columns using ONLY the dataset metadata and order of meta data is random. Evaluate BOTH datasets. Prefer a table that can satisfy ALL required columns and the requested time grain. If no table can fully satisfy, return the closest table by coverage.

                    Follow this decision process strictly:

                    1. **Match Attributes and Metrics First**
                    - Check if the dataset contains the attributes and metrics mentioned or implied in the user question.
                    - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue').

                    2. **Check Time Granularity**
                    - Ensure the dataset supports the required time grain (e.g., monthly, daily).

                    3. **Evaluate Usefulness Tags**
                    - If the dataset is marked as 'useful_for' the type of analysis requested, that increases its relevance.
                    - If the dataset is marked as 'not_useful_for' the type of analysis requested, it should be excluded.

                    4. **Select Only One Dataset**
                    - Choose the single best dataset that satisfies the above criteria.

                    RESPONSE FORMAT:
                    The response MUST be valid JSON. Do NOT include any extra text, markdown, or formatting. The response MUST not start with ```json and end with ```.

                    {{ "clear_selection": true, "selected_dataset": "<one of the dataset 'table_name' values>", "selection_reasoning": "One concise sentence referencing why the dataset is best match (e.g., therapy_class_name + month required; only claims has therapy_class_name and supports month/day)." }}

                    """


selection_prompt = f"""
        You are a decisive dataset router. Follow this decision process strictly:

        USER QUESTION: "{user_question}"

        AVAILABLE DATASETS:
        {json.dumps(search_results[:5], indent=2)}

        DECISION PROCESS:
        1. **Match Attributes and Metrics First**
        - Check if the dataset contains the attributes and metrics mentioned or implied in the user question
        - Prioritize exact matches (e.g., 'line_of_business', 'month', 'revenue')
        
        2. **Check Time Granularity**
        - Ensure the dataset supports the required time grain (e.g., monthly, daily)
        
        3. **Evaluate Usefulness Tags**
        - If dataset is marked as 'useful_for' the type of analysis requested, increase relevance
        - If dataset is marked as 'not_useful_for' the type of analysis requested, exclude it
        
        4. **Multi-Table Analysis Detection**
        - Detect if query requires joining data across tables (e.g., claim amounts from different tables)
        - Identify queries that benefit from complementary data perspectives (volumes + financials)
        - Recognize queries needing separate analysis on related datasets (demographics + transactions)
        
        5. **Dataset Selection Strategy**
        - Choose the single best dataset that satisfies the above criteria
        - Select multiple datasets only when analysis inherently requires multiple tables
        
        WHEN TO ASK FOLLOW-UP (RARE CASES ONLY):
        
        **Scenario 1: Data Type Ambiguity**
        - ONLY when both tables have same LOB and user didn't specify "ledger" vs "claims" keywords
        - Example: "Which dataset: claims transactions or financial ledger data?"
        
        **Scenario 2: Multi-Table Analysis Confirmation**
        - When query requires joining data across tables (e.g., billed amount from Table A + paid amount from Table B)
        - When query benefits from complementary perspectives (transaction volumes + financial metrics)
        - When query needs separate analysis on related datasets then combining insights
        - Example: "This analysis requires both Claims Details and Payment Records tables. Proceed with both?"
        
        DO NOT ASK FOLLOW-UP FOR GENERAL AMBIGUITIES:
        - Time period vagueness (e.g., "show pharmacy sales" without specifying when) → Pick most recent complete period
        - Aggregation level uncertainty (e.g., "revenue data" without daily/monthly) → Use most appropriate grain available
        - Scope ambiguity (e.g., "claim trends" without LOB specified) → Use broadest/most complete dataset
        - Metric preference vagueness (e.g., "pharmacy performance" unclear on volume vs financial) → Pick best match based on context
        - BE DECISIVE: Make reasonable choices for these ambiguities rather than asking clarification
        
        MULTI-TABLE EXAMPLES:
        - "What is the claim paid and billed amount?" → Need claims table + payments table (JOIN required)
        - "Show pharmacy performance trends" → Transaction data + Financial metrics (Complementary analysis)
        - "Compare member demographics with claim patterns" → Demographics table + Claims table (Separate analysis)
        
        RESPONSE FORMAT (valid JSON only, no markdown):
        {{
            "final_actual_tables": ["actual_table_name1"] or ["table1", "table2"] if multiple needed,
            "functional_names": ["user-friendly name 1"] or ["name1", "name2"] if multiple,
            "requires_clarification": false,
            "clarification_question": null,
            "candidate_actual_tables": [],
            "selection_reasoning": "Brief explanation of selection based on attribute/metric match"
        }}
        
        IMPORTANT: 
        - When LLM decides on right dataset(s), ALWAYS set requires_clarification: false and clarification_question: null
        - Only set requires_clarification: true and populate clarification_question for the 2 scenarios mentioned above
        - Keep clarification_question short and direct when needed
        - candidate_actual_tables should be populated only when requires_clarification: true
        """

llm response router {
    "final_actual_tables": ["prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis"],
    "functional_names": ["Actuals vs Forecast Analysis"],
    "requires_clarification": false,
    "clarification_question": null,
    "candidate_actual_tables": [],
    "selection_reasoning": "Query asks for claim revenue by month and product category PBM. The actuals_vs_forecast_analysis table has exact matches for 'revenue', 'month', and 'product category' dimensions with monthly temporal granularity. The claim_transaction table, while having revenue data, is designed for claim-level analysis and marked as 'not suitable for ledger-level summaries', whereas this query appears to need aggregated revenue metrics by time period and product category."
}

      [
  {
    "llm_context": "{\"table_name\":\"prd_optumrx_orxfdmprdsa.rag.claim_transaction_for_pharmacy_pbm\",\"purpose\":\"Claim-level pharmacy transactions with detailed drug, client, and pharmacy attributes. Individual claim records with payment status for utilization and financial analysis.\",\"core_capabilities\":\"revenue per script analysis, drug utilization trending, therapy class performance (GLP-1, SGLT-2, Oncology), generic dispense rate (GDR), pharmacy network analysis, client-level metrics, brand vs generic mix, claim status tracking\",\"key_measures\":[\"revenue\",\"expense\",\"WAC\",\"AWP\",\"unadjusted scripts\",\"adjusted scripts\",\"30-day scripts\",\"90-day scripts\",\"revenue per script\",\"volume\",\"Generic dispensing ratio/GDR\"],\"key_dimensions\":[\"claim identifiers\",\"claim status\",\"client id/Client name/Client type\",\"carrier/account/group/CAG\",\"pharmacy name/NPI/Pharmacy type\",\"drug name/ NDC Code\",\"therapy class\",\"GPI\",\"line of business\",\"brand vs generic\",\"product category\",\"state code\",\"member date of birth\",\"member sex\",\"submit date\",\"year\",\"month\",\"quarter\"],\"query_patterns\":[\"claim-level financial analysis\",\"client-level analysis\",\"drug and therapy class performance\",\"manufacturer-level insights\",\"revenue per script and GDR metrics\",\"line-of-business tracking\",\"daily and monthly trend analysis\",\"rate analysis\",\"pharmacy performance\",\"member usage analysis\"],\"not_suitable_for\":[\"budget planning\",\"forecast generation\",\"ledger-level summaries\"],\"grain\":\"claim_transaction\",\"temporal\":\"daily via submit_date\"}"
  },
  {
    "llm_context": "{\"table_name\":\"prd_optumrx_orxfdmprdsa.rag.actuals_vs_forecast_analysis\",\"purpose\":\"Ledger-level financial data for actuals, forecast, and budget analysis. Aggregated financial metrics for forecast analysis and planning at LOB level.\",\"key_measures\":[\"revenue\",\"IOI\",\"total membership\",\"unadjusted scripts\",\"adjusted scripts\",\"30-day scripts\",\"90-day scripts\",\"amount or count\",\"expense\",\"volume\"],\"key_dimensions\":[\"ledger type\",\"line of business\",\"product category\",\"product subcategory level 1\",\"product subcategory level 2\",\"transaction date\",\"year\",\"month\",\"quarter\"],\"query_patterns\":[\"actuals vs forecast\",\"budget comparison\"],\"not_suitable_for\":[\"claim-level analysis\",\"daily granularity\",\"client-specific analysis\"],\"grain\":\"aggregated_metrics\",\"temporal\":\"monthly/quarterly/yearly via transaction_date\"}"
  }
]
