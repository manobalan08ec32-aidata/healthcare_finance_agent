import re
import json
from typing import List, Dict, Any

class MetadataSearcher:
    async def search_metadata_sql(self, filter_list: List[str]) -> List[str]:
        """
        End-to-end optimized search for mapping values to columns.
        """
        try:
            if not filter_list:
                return []

            # 1. SQL Preparation
            exact_conditions = []
            starts_conditions = []
            contains_conditions = []
            
            for term in filter_list:
                term_clean = term.strip().lower()
                escaped_exact = term_clean.replace("'", "\\'")
                escaped_regex = re.escape(term_clean)
                
                exact_conditions.append(f"lower(trim(exploded_value)) = '{escaped_exact}'")
                starts_conditions.append(f"lower(trim(exploded_value)) RLIKE '^{escaped_regex}'")
                
                words = [w for w in term_clean.split() if len(w) > 2]
                for word in words:
                    contains_conditions.append(f"lower(trim(exploded_value)) RLIKE '\\\\b{re.escape(word)}'")

            all_conditions = f"({ ' OR '.join(exact_conditions) }) OR ({ ' OR '.join(starts_conditions) }) OR ({ ' OR '.join(contains_conditions) })"
            
            tier_assignment = f"""
                CASE 
                    WHEN { ' OR '.join(exact_conditions) } THEN 1
                    WHEN { ' OR '.join(starts_conditions) } THEN 2
                    ELSE 3
                END
            """

            # 2. Optimized SQL Query
            query = f"""
            WITH matched_data AS (
                SELECT
                    column_name,
                    trim(exploded_value) AS individual_value,
                    {tier_assignment} AS match_tier
                FROM prd_optumrx_orxfdmprdsa.rag.distinct_values_metadata1
                LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
                WHERE {all_conditions}
            )
            SELECT
                column_name,
                collect_set(individual_value) AS all_matched_values,
                collect_list(match_tier) AS all_match_tiers,
                MIN(match_tier) AS best_tier
            FROM matched_data
            GROUP BY column_name
            ORDER BY best_tier ASC
            LIMIT 10
            """
            
            result_data = await self.execute_sql_async_audit(query)
            
            # Convert Spark DataFrame if necessary
            if hasattr(result_data, 'collect'):
                result_list = [row.asDict() for row in result_data.collect()]
            else:
                result_list = result_data if isinstance(result_data, list) else []

            if not result_list:
                return []

            return self._process_and_rank_results(result_list, filter_list)

        except Exception as e:
            print(f"âŒ Search Error: {str(e)}")
            return []

    def _process_and_rank_results(self, result_list: List[Dict], filter_list: List[str]) -> List[str]:
        """
        Ranks results using sequence matching and formats the output.
        """
        tier_1a, tier_1b, tier_2, tier_3 = [], [], [], []
        search_phrases = [t.strip().lower() for t in filter_list]
        
        for row in result_list:
            col_name = row['column_name']
            best_tier = int(row['best_tier'])
            matched_vals = row['all_matched_values']
            all_tiers = [int(t) for t in row['all_match_tiers']]
            
            # Sub-categorize Tier 1
            if best_tier == 1:
                is_pure = all(t == 1 for t in all_tiers)
                target_list = tier_1a if is_pure else tier_1b
            elif best_tier == 2:
                target_list = tier_2
            else:
                target_list = tier_3

            target_list.append({
                'column': col_name,
                'values': matched_vals,
                'score': self._calculate_score(col_name, matched_vals, search_phrases)
            })

        # Priority return
        if tier_1a: return self._format(tier_1a, "EXACT-PURE")
        if tier_1b: return self._format(tier_1b, "EXACT-MIXED")
        if tier_2: return self._format(tier_2, "STARTS-WITH")
        
        # Sort Tier 3 by the new composite score
        tier_3.sort(key=lambda x: x['score'], reverse=True)
        return self._format(tier_3[:5], "CONTAINS")

    def _calculate_score(self, col_name: str, values: List[str], search_phrases: List[str]) -> float:
        """
        Calculates a relevance score based on sequence and word matching.
        """
        score = 0
        all_vals_str = " ".join(values).lower()
        col_name_lower = col_name.lower()
        
        # 1. Sequence Bonus (Massive boost if phrase is intact)
        for phrase in search_phrases:
            if phrase in all_vals_str:
                score += 150 
        
        # 2. Word Match (Set-based for speed)
        search_words = set()
        for p in search_phrases:
            search_words.update([w for w in p.split() if len(w) > 2])
        
        val_words = set(re.findall(r'\w+', all_vals_str))
        matches = search_words.intersection(val_words)
        score += len(matches) * 40
        
        # 3. Column Relevance
        med_context = ['drug', 'med', 'therapy', 'clss', 'type', 'name', 'nm']
        if any(ctx in col_name_lower for ctx in med_context):
            score += 25
            
        return score

    def _format(self, results: List[Dict], match_type: str) -> List[str]:
        """
        Structures output as: column_name - value1, value2
        """
        formatted = []
        for res in results:
            # Join the first 2 matched values for brevity
            val_str = ", ".join(res['values'][:2])
            formatted.append(f"{res['column']} - {val_str}")
        return formatted



-----------------------


import re
from typing import List, Dict, Any

class MetadataSearchTester:
    def __init__(self, table_name: str):
        self.table_name = table_name

    def search(self, filter_list: List[str]):
        """
        Main search entry point for Databricks testing.
        """
        if not filter_list:
            print("No filters provided.")
            return []

        # 1. Generate SQL Conditions [cite: 3, 4, 5, 6]
        exact_conditions = []
        starts_conditions = []
        contains_conditions = []
        
        for term in filter_list:
            term_clean = term.strip().lower()
            escaped_exact = term_clean.replace("'", "\\'")
            escaped_regex = re.escape(term_clean)
            
            # Tier 1 & 2 logic [cite: 4, 5]
            exact_conditions.append(f"lower(trim(exploded_value)) = '{escaped_exact}'")
            starts_conditions.append(f"lower(trim(exploded_value)) RLIKE '^{escaped_regex}'")
            
            # Tier 3 word splitting [cite: 6]
            words = [w for w in term_clean.split() if len(w) > 2]
            for word in words:
                contains_conditions.append(f"lower(trim(exploded_value)) RLIKE '\\\\b{re.escape(word)}'")

        all_conditions = f"({ ' OR '.join(exact_conditions) }) OR ({ ' OR '.join(starts_conditions) }) OR ({ ' OR '.join(contains_conditions) })"
        
        tier_assignment = f"""
            CASE 
                WHEN { ' OR '.join(exact_conditions) } THEN 1
                WHEN { ' OR '.join(starts_conditions) } THEN 2
                ELSE 3
            END
        """

        # 2. Execute SQL via spark.sql [cite: 10, 11]
        query = f"""
        WITH matched_data AS (
            SELECT
                column_name,
                trim(exploded_value) AS individual_value,
                {tier_assignment} AS match_tier
            FROM {self.table_name}
            LATERAL VIEW explode(split(distinct_values, ',')) AS exploded_value
            WHERE {all_conditions}
        )
        SELECT
            column_name,
            collect_set(individual_value) AS all_matched_values,
            collect_list(match_tier) AS all_match_tiers,
            MIN(match_tier) AS best_tier
        FROM matched_data
        GROUP BY column_name
        ORDER BY best_tier ASC
        LIMIT 10
        """
        
        print(f"Executing query on {self.table_name}...")
        df = spark.sql(query)
        result_list = [row.asDict() for row in df.collect()]

        if not result_list:
            print("No matches found in database.")
            return []

        # 3. Process Tiers and Rank [cite: 20, 31]
        return self._rank_and_format(result_list, filter_list)

    def _rank_and_format(self, result_list: List[Dict], filter_list: List[str]) -> List[str]:
        tier_1a, tier_1b, tier_2, tier_3 = [], [], [], []
        search_phrases = [t.strip().lower() for t in filter_list]
        
        for row in result_list:
            col_name = row['column_name']
            best_tier = int(row['best_tier'])
            matched_vals = row['all_matched_values']
            all_match_tiers = [int(t) for t in row['all_match_tiers']]
            
            # Purity check for Tier 1 [cite: 26, 27]
            if best_tier == 1:
                is_pure = all(t == 1 for t in all_match_tiers)
                target = tier_1a if is_pure else tier_1b
            elif best_tier == 2:
                target = tier_2
            else:
                target = tier_3

            target.append({
                'column': col_name,
                'values': matched_vals,
                'score': self._calculate_score(col_name, matched_vals, search_phrases)
            })

        # Return only the highest priority tier found [cite: 28, 29, 30]
        if tier_1a: return self._format(tier_1a, "EXACT-PURE")
        if tier_1b: return self._format(tier_1b, "EXACT-MIXED")
        if tier_2: return self._format(tier_2, "STARTS-WITH")
        
        # Sort Tier 3 by custom score
        tier_3.sort(key=lambda x: x['score'], reverse=True)
        return self._format(tier_3[:7], "CONTAINS")

    def _calculate_score(self, col_name: str, values: List[str], search_phrases: List[str]) -> float:
        score = 0
        all_vals_str = " ".join(values).lower()
        col_name_lower = col_name.lower()
        
        # Improvement: Sequence Bonus (Phrase matching)
        for phrase in search_phrases:
            if phrase in all_vals_str:
                score += 150 
        
        # Improvement: Set Intersection (Fast word matching)
        search_words = set()
        for p in search_phrases:
            search_words.update([w for w in p.split() if len(w) > 2])
        
        val_words = set(re.findall(r'\w+', all_vals_str))
        matches = search_words.intersection(val_words)
        score += len(matches) * 40
        
        # Improvement: Medical Context weight [cite: 40]
        med_context = ['drug', 'med', 'therapy', 'clss', 'type', 'name', 'nm']
        if any(ctx in col_name_lower for ctx in med_context):
            score += 25
            
        return score

    def _format(self, results: List[Dict], match_type: str) -> List[str]:
        print(f"Found {len(results)} matches of type: {match_type}")
        # Structures output as: column_name - first_matched_value
        return [f"{res['column']} - {res['values'][0]}" for res in results]

# --- TEST EXECUTION ---
# Update with your actual table path if different
TABLE_PATH = "prd_optumrx_orxfdmprdsa.rag.distinct_values_metadata1" 

tester = MetadataSearchTester(TABLE_PATH)

# Example Search
user_input = ["mounjaro 50mg"] 
final_results = tester.search(user_input)

for r in final_results:
    print(r)
