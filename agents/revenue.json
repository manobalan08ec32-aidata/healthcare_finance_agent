async def get_metadata(self, state: Dict, selected_dataset: list) -> Dict:
    """Extract metadata with mandatory embeddings - simplified direct merge"""
    try:
        current_question = state.get('rewritten_question', state.get('current_question', ''))
        embedding_idx = "prd_optumrx_orxfdmprdsa.rag.column_embeddings_pbm_idx"
        
        tables_list = selected_dataset if isinstance(selected_dataset, list) else [selected_dataset] if selected_dataset else []
        print(f'üìä Tables selected: {tables_list}')
        
        # ===== STEP 1: Load Mandatory Embeddings (Cached - Fast!) =====
        mandatory_contexts = get_mandatory_embeddings_for_tables(tables_list)
        print(f'‚úÖ Mandatory contexts loaded: {len(mandatory_contexts)} tables')
        
        # ===== STEP 2: Get Vector Search Results =====
        print(f'üîç Searching: {current_question!r} across {len(tables_list)} table(s)')
        vector_results = await self.db_client.sp_vector_search_columns(
            query_text=current_question,
            tables_list=tables_list,
            num_results_per_table=10,
            index_name=embedding_idx
        )
        
        # ===== STEP 3: Group Vector Results by Table =====
        vector_contexts_by_table = {}
        for result in vector_results:
            table = result['table_name']
            if table not in vector_contexts_by_table:
                vector_contexts_by_table[table] = []
            # Collect all llm_context strings for this table
            vector_contexts_by_table[table].append(result['llm_context'])
        
        # Log what we got
        for table, contexts in vector_contexts_by_table.items():
            print(f'  ‚úÖ {table}: {len(contexts)} vector contexts')
        
        # ===== STEP 4: Build Metadata (Simple Merge - No Deduplication) =====
        metadata = ""
        
        for table in tables_list:
            metadata += f"\n## Table: {table}\n\n"
            
            # Add mandatory contexts first (if any)
            if table in mandatory_contexts:
                for ctx in mandatory_contexts[table]:
                    metadata += ctx + "\n"
            
            # Add vector contexts (if any)
            if table in vector_contexts_by_table:
                for ctx in vector_contexts_by_table[table]:
                    # Clean up the context (remove leading/trailing whitespace and newlines)
                    clean_ctx = ctx.strip()
                    if clean_ctx:  # Only add non-empty contexts
                        metadata += clean_ctx + "\n"
            
            metadata += "\n"  # Extra line between tables
        
        # Count total contexts
        total_mandatory = sum(len(v) for v in mandatory_contexts.values())
        total_vector = sum(len(v) for v in vector_contexts_by_table.values())
        
        print(f'üìã Final metadata: {total_mandatory} mandatory + {total_vector} vector = {total_mandatory + total_vector} total contexts')
        
        return {
            'status': 'success',
            'metadata': metadata,
            'error': False
        }
        
    except Exception as e:
        print(f"‚ùå Metadata extraction failed: {str(e)}")
        import traceback
        traceback.print_exc()
        
        return {
            'status': 'error',
            'metadata': '',
            'error': True,
            'error_message': f"Metadata extraction failed: {str(e)}"
        }
